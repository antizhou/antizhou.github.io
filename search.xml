<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ES6的7个实用技巧]]></title>
    <url>%2Fes6%2FES6%E7%9A%847%E4%B8%AA%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[Hack #1 交换元素利用数组解构来实现值的互换 1234let a = 'world', b = 'hello'[a, b] = [b, a]console.log(a) // -&gt; helloconsole.log(b) // -&gt; world Hack #2 调试我们经常使用console.log()来进行调试，试试console.table()也无妨。 123const a = 5, b = 6, c = 7console.log(&#123; a, b, c &#125;);console.table(&#123;a, b, c, m: &#123;name: 'xixi', age: 27&#125;&#125;); Hack #3 单条语句ES6时代，操作数组的语句将会更加的紧凑 123456// 寻找数组中的最大值const max = (arr) =&gt; Math.max(...arr);max([123, 321, 32]) // outputs: 321// 计算数组的总和const sum = (arr) =&gt; arr.reduce((a, b) =&gt; (a + b), 0)sum([1, 2, 3, 4]) // output: 10 Hack #4 数组拼接展开运算符可以取代concat的地位了 12345const one = ['a', 'b', 'c']const two = ['d', 'e', 'f']const three = ['g', 'h', 'i']const result = [...one, ...two, ...three] Hack #5 制作副本我们可以很容易的实现数组和对象的浅拷贝拷贝 12const obj = &#123; ...oldObj &#125;const arr = [ ...oldArr ] 拷贝 = 深拷贝 ? 浅拷贝 ？好像有些朋友对这里我说的浅拷贝有些质疑，我也能理解大家所说的。下面数组为例： 123456789101112// 数组元素为简单数据类型非引用类型const arr = [1, 2, 3, 4];const newArr = [...arr];// 数组元素为引用类型const person01 = &#123;name: 'name01', age: 1&#125;;const person02 = &#123;name: 'name01', age: 2&#125;;const person03 = &#123;name: 'name03', age: 3&#125;;const arr = [person01, person02, person03];const newArr = [...arr];console.log(newArr[0] === person01);// true 第二个 demo 就是我想表达的浅拷贝，若有不同意见欢迎讨论~ Hack #6 命名参数???解构使得函数声明和函数的调用更加可读 12345678910111213// 我们尝尝使用的写法const getStuffNotBad = (id, force, verbose) =&gt; &#123; ...do stuff&#125;// 当我们调用函数时， 明天再看，尼玛 150是啥，true是啥getStuffNotBad(150, true, true)// 看完本文你啥都可以忘记, 希望够记住下面的就可以了const getStuffAwesome = (&#123;id, name, force, verbose&#125;) =&gt; &#123; ...do stuff&#125;// 完美getStuffAwesome(&#123; id: 150, force: true, verbose: true &#125;) Hack #7 Async/Await结合数组解构数组解构非常赞!结合Promise.all和解构和await会使代码变得更加的简洁 1234const [user, account] = await Promise.all([ fetch('/user'), fetch('/account')])]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>es6</tag>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[es6]]></title>
    <url>%2Fes6%2Fes6%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[1. 强制要求参数 ES6提供了默认参数值机制，允许你为参数设置默认值，防止在函数被调用时没有传入这些参数。 在下面的例子中，我们写了一个required()函数作为参数a和b的默认值。这意味着如果a或b其中有一个参数没有在调用时传值，会默认required()函数，然后抛出错误。 1234567const required = () =&gt; &#123;throw new Error('Missing parameter')&#125;;const add = (a = required(), b = required()) =&gt; a + b;add(1, 2) //3add(1) // Error: Missing parameter. 2. 强大的reduce 数组的reduce方法用途很广。它一般被用来把数组中每一项规约到单个值。但是你可以利用它做更多的事。 2.1 使用reduce同时实现map和filter 假设现在有一个数列，你希望更新它的每一项（map的功能）然后筛选出一部分（filter的功能）。如果是先使用map然后filter的话，你需要遍历这个数组两次。 在下面的代码中，我们将数列中的值翻倍，然后挑选出那些大于50的数。有注意到我们是如何非常高效地使用reduce来同时完成map和filter方法的吗？ 1234567891011121314151617const numbers = [10, 20, 30, 40];const doubledOver50 = numbers.reduce((finalList, num) =&gt; &#123; num = num * 2; if (num &gt; 50) &#123; finalList.push(num); &#125; return finalList;&#125;, []);doubledOver50; // [60, 80] 2.2 使用reduce取代map和filter 如果你认真阅读了上面的代码，你应该能理解reduce是可以取代map和filter的。 2.3 使用reduce匹配圆括号 reduce的另外一个用途是能够匹配给定字符串中的圆括号。对于一个含有圆括号的字符串，我们需要知道(和)的数量是否一致，并且(是否出现在)之前。 下面的代码中我们使用reduce可以轻松地解决这个问题。我们只需要先声明一个counter变量，初值为0。在遇到(时counter加一，遇到)时counter减一。如果左右括号数目匹配，那最终结果为0。 123456789101112131415161718//Returns 0 if balanced.const isParensBalanced = (str) =&gt; &#123; return str.split('').reduce((counter, char) =&gt; &#123; if(counter &lt; 0) &#123; //matched ")" before "(" return counter; &#125; else if(char === '(') &#123; return ++counter; &#125; else if(char === ')') &#123; return --counter; &#125; else &#123; //matched some other char return counter; &#125; &#125;, 0); //&lt;-- starting value of the counter&#125;isParensBalanced('(())') // 0 &lt;-- balancedisParensBalanced('(asdfds)') //0 &lt;-- balancedisParensBalanced('(()') // 1 &lt;-- not balancedisParensBalanced(')(') // -1 &lt;-- not balanced 2.4 统计数组中相同项的个数 很多时候，你希望统计数组中重复出现项的个数然后用一个对象表示。那么你可以使用reduce方法处理这个数组。 下面的代码将统计每一种车的数目然后把总数用一个对象表示。 123456var cars = ['BMW','Benz', 'Benz', 'Tesla', 'BMW', 'Toyota'];var carsObj = cars.reduce(function (obj, name) &#123; obj[name] = obj[name] ? ++obj[name] : 1; return obj;&#125;, &#123;&#125;);carsObj; // =&gt; &#123; BMW: 2, Benz: 2, Tesla: 1, Toyota: 1 &#125; reduce的其他用处实在是太多了，我建议你阅读MDN的相关代码示例。 3. 对象解构 3.1 删除不需要的属性 有时候你不希望保留某些对象属性，也许是因为它们包含敏感信息或仅仅是太大了（just too big）。你可能会枚举整个对象然后删除它们，但实际上只需要简单的将这些无用属性赋值给变量，然后把想要保留的有用部分作为剩余参数就可以了。 下面的代码里，我们希望删除_internal和tooBig参数。我们可以把它们赋值给internal和tooBig变量，然后在cleanObject中存储剩下的属性以备后用。 1234let &#123;_internal, tooBig, ...cleanObject&#125; = &#123; el1: '1', _internal:"secret", tooBig:&#123;&#125;, el2: '2', el3: '3'&#125;;console.log(cleanObject); // &#123;el1: '1', el2: '2', el3: '3'&#125; 3.2 在函数参数中解构嵌套对象 在下面的代码中，engine是对象car中嵌套的一个对象。如果我们对engine的vin属性感兴趣，使用解构赋值可以很轻松地得到它。 123456789101112var car = &#123; model: 'bmw 2018', engine: &#123; v6: true, turbo: true, vin: 12345 &#125;&#125;const modelAndVIN = (&#123;model, engine: &#123;vin&#125;&#125;) =&gt; &#123; console.log(model: $&#123;model&#125; vin: $&#123;vin&#125;);&#125;modelAndVIN(car); // =&gt; model: bmw 2018 vin: 12345 3.3 合并对象 ES6带来了扩展运算符（…）。它一般被用来解构数组，但你也可以用它处理对象。 接下来，我们使用扩展运算符来展开一个新的对象，第二个对象中的属性值会改写第一个对象的属性值。比如object2的b和c就会改写object1的同名属性。 1234let object1 = &#123; a:1, b:2,c:3 &#125;let object2 = &#123; b:30, c:40, d:50&#125;let merged = &#123;…object1, …object2&#125; //spread and re-add into mergedconsole.log(merged) // &#123;a:1, b:30, c:40, d:50&#125; 4. Sets 4.1 使用Set实现数组去重 在ES6中，因为Set只存储唯一值，所以你可以使用Set删除重复项。 12let arr = [1, 1, 2, 2, 3, 3];let deduped = [...new Set(arr)] // [1, 2, 3] 4.2 对Set使用数组方法 使用扩展运算符就可以简单的将Set转换为数组。所以你可以对Set使用Array的所有原生方法。 比如我们想要对下面的Set进行filter操作，获取大于3的项。 12let mySet = new Set([1,2, 3, 4, 5]);var filtered = [...mySet].filter((x) =&gt; x &gt; 3) // [4, 5] 5. 数组解构 有时候你会将函数返回的多个值放在一个数组里。我们可以使用数组解构来获取其中每一个值。 5.1 数值交换 123456let param1 = 1;let param2 = 2;//swap and assign param1 &amp; param2 each others values[param1, param2] = [param2, param1];console.log(param1) // 2console.log(param2) // 1 5.2 接收函数返回的多个结果 在下面的代码中，我们从/post中获取一个帖子，然后在/comments中获取相关评论。由于我们使用的是async/await，函数把返回值放在一个数组中。而我们使用数组解构后就可以把返回值直接赋给相应的变量。]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>es6</tag>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[报警规则类型]]></title>
    <url>%2Falarm%2F%E6%8A%A5%E8%AD%A6%E8%A7%84%E5%88%99%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[单数据源简单规则。简单规则通过对每次最新的监控数据进行阈值比较，来获得报警，比如： 上下限阈值比较。这种是最简单的，定义好上限和下限，就可以发现异常值 数据存活性比较。当发现某一监控项的数据存在（或消失）时，即报警，用来检查错误指标（或存活指标） 单数据源组合规则。简单规则产生的报警有可能非常多，我们可以通过对简单规则产生的结果进行进一步的处理，来减少报警量，比如： 多次报警。当简单规则触发的内部报警在一段时间内超过一定的次数时，才进行真正的报警。 报警cooldown。当同一报警不停出现时，此规则会进行相应的抑制。 断崖式报警。当监控数据出现断崖式特征时，才进行报警。 多数据源组合规则。有时候，单一的数据源还不够，需要对多个数据源进行计算后获得，比如： 同环比报警。对同一监控项可以拉取不同时间段的两条数据，就可以进行相应的报警。 组合运算报警。比如说nginx 2xx状态比例的监控，可以通过对2xx次数和总访问次数的计算来获取。]]></content>
  </entry>
  <entry>
    <title><![CDATA[select]]></title>
    <url>%2Fgolang%2Fselect%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930var a []intvar c, c1, c2, c3, c4 chan intvar i1, i2 intselect &#123;case i1 = &lt;-c1: print("received ", i1, " from c1\n")case c2 &lt;- i2: print("sent ", i2, " to c2\n")case i3, ok := (&lt;-c3): // same as: i3, ok := &lt;-c3 if ok &#123; print("received ", i3, " from c3\n") &#125; else &#123; print("c3 is closed\n") &#125;case a[f()] = &lt;-c4: // same as: // case t := &lt;-c4 // a[f()] = tdefault: print("no communication\n")&#125;for &#123; // 向 channel c 发送随机 bit 串 select &#123; case c &lt;- 0: // note: no statement, no fallthrough, no folding of cases case c &lt;- 1: &#125;&#125;select &#123;&#125; // 永久阻塞]]></content>
  </entry>
  <entry>
    <title><![CDATA[import详解]]></title>
    <url>%2Fgolang%2Fimport%2F</url>
    <content type="text"><![CDATA[语法：12ImportDeclaration = "import" ImportSpecImportSpec = [ "." | "_" | Identifier ] ImportPath 12345678910111213import . "fmt"import _ "io"import log "github.com/sirupsen/logrus"import m "math"import "io"import "bufio"import ( "io" "bufio")]]></content>
  </entry>
  <entry>
    <title><![CDATA[golang字符串]]></title>
    <url>%2Fgolang%2Fgolang%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[12s := "123123"s = s[0:len(s)-1]]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[goalng类型转换]]></title>
    <url>%2Fgolang%2Fgoalng%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[int 转 string123456789101112131415161718192021package main import ( "fmt" "strconv") var i int = 10 func main() &#123; // 通过Itoa方法转换 str1 := strconv.Itoa(i) // 通过Sprintf方法转换 str2 := fmt.Sprintf("%d", i) // 打印str1 fmt.Println(str1) // 打印str2 fmt.Println(str2)&#125; []T 转 []interface{}Can I convert a []T to an []interface{}?Not directly, because they do not have the same representation in memory. It is necessary to copy the elements individually to the destination slice. This example converts a slice of int to a slice of interface{}:12345t := []int&#123;1, 2, 3, 4&#125;s := make([]interface&#123;&#125;, len(t))for i, v := range t &#123; s[i] = v&#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[golang类型断言(Type Assertion)的应用]]></title>
    <url>%2Ftypeassertion%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526package mainimport "fmt"func main() &#123; add(1, 2) add(int16(1), int16(2)) add(float32(1.1), float32(2.2)) add(float64(1.1), float64(2.2)) add(true, false)&#125;func add(a, b interface&#123;&#125;) &#123; switch t := a.(type) &#123; case int: fmt.Printf("type [%T] add res[%d]\n", t, a.(int)+b.(int)) case int16: fmt.Printf("type [%T] add res[%d]\n", t, a.(int16)+b.(int16)) case float32: fmt.Printf("type [%T] add res[%f]\n", t, a.(float32)+b.(float32)) case float64: fmt.Printf("type [%T] add res[%f]\n", t, a.(float64)+b.(float64)) default: fmt.Printf("type [%T] not support!\n", t) &#125;&#125; 输出结果： type [int] add res[3]type [int16] add res[3]type [float32] add res[3.300000]type [float64] add res[3.300000]type [bool] not support! 用interface{}作参数，是不是很像C++的模板函数,而类型断言是不是很像C++的类层次间的下行转换(也是不一定成功的)。需要注意的是，a.(type)只能和switch搭配使用。在使用前得用断言指明变量的类型，如果断言错误就会触发panic。 如果不想触发panic，先做判断再使用。 1234567891011121314151617package mainimport "fmt"func main() &#123; a := int16(2) b := int32(3) add(a, b)&#125;func add(a, b interface&#123;&#125;) &#123; _, ok := a.(int32) if !ok &#123; fmt.Println("error type assertion!") &#125; b = b&#125; 运行结果：error type assertion!2.用于转换结构体的interface{}类型字段例如，我们写handler去接收消息，不可能每个发来的消息都写个函数去handle。利用空接口和类型断言的特性，就可以将业务抽象出来:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package main import "fmt" import "time" type NetMsg struct &#123; MsgID int16 Data interface&#123;&#125; &#125; type Cat struct &#123; name string age int16 &#125; type Dog struct &#123; name string age int32 &#125; type human struct &#123; name string age int64 &#125; func main() &#123; msg1 := NetMsg&#123;1, Cat&#123;"Qian", 1&#125;&#125; msg2 := NetMsg&#123;2, Dog&#123;"doge", 8&#125;&#125; msg3 := NetMsg&#123;3, Dog&#123;"allu", 18&#125;&#125; msg_handler(msg1) time.Sleep(2000 * time.Millisecond) msg_handler(msg2) time.Sleep(2000 * time.Millisecond) msg_handler(msg3) &#125; func msg_handler(msg NetMsg) &#123; switch msg.MsgID &#123; case 1: cat := msg.Data.(Cat) fmt.Printf("Do Something with Msg 1 %v \n", cat) case 2: dog := msg.Data.(Dog) fmt.Printf("Do Something with Msg 2 %v \n", dog) default: fmt.Printf("Error MsgID [%d] \n", msg.MsgID) &#125; &#125; 运行结果:Do Something with Msg 1 {Qian 1}Do Something with Msg 2 {doge 8}Error MsgID [3] https://segmentfault.com/a/1190000012495480]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[binlog]]></title>
    <url>%2Fbinlog%2F</url>
    <content type="text"><![CDATA[操作binglog 1234567891011121314查看是否启用了日志mysql&gt; show variables like &apos;log_%&apos;; 查看所有binlog日志列表mysql&gt; show master logs;查看master状态，即最后(最新)一个binlog日志的编号名称，及其最后一个操作事件pos结束点(Position)值mysql&gt; show master status;刷新log日志，自此刻开始产生一个新编号的binlog日志文件mysql&gt; flush logs;重置(清空)所有binlog日志mysql&gt; reset master; MySQLbinlog模式 12345查看MySQLbinlog模式show global variables like &quot;binlog%&quot;;MySQL中设置binlog模式set global binlog_format=&apos;ROW&apos;;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>binlog</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[homebrew 安装 mysql 以及配置]]></title>
    <url>%2Fmysqlinstall%2F</url>
    <content type="text"><![CDATA[brew install mysql (安装) 添加修改mysql配置 mysqld --help --verbose | more (查看帮助, 按空格下翻) 你会看到开始的这一行(表示配置文件默认读取顺序) Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/local/etc/my.cnf ~/.my.cnf 通常这些位置是没有配置文件的, 所以要自己建一个 ls $(brew --prefix mysql)/support-files/my-* (用这个可以找到样例.cnf) cp /usr/local/opt/mysql/support-files/my-default.cnf /etc/my.cnf (拷贝到第一个默认读取目录) 按需修改my.cnf brew services start mysql (启动) brew services stop mysql (停止) https://segmentfault.com/q/1010000000475470]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>install</tag>
        <tag>config</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建应用服务的监控报警系统]]></title>
    <url>%2Falarm%2F%E6%9E%84%E5%BB%BA%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E7%9A%84%E7%9B%91%E6%8E%A7%E6%8A%A5%E8%AD%A6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[昨晚做了个技术分享, 今天整理一下发上来. Be unknown, hard to survive对于我们应用开发团队来说, 上层应用开发每天要面对最多的就是业务逻辑.而我们都知道, 业务逻辑的最大特点就是 量大,复杂,多变.三天两头变动的需求以及突发的任务都会很大程度的影响业务逻辑, 导致它们状态很难控制. 也正因如此, 特别是创业团队, 在开发之初往往着重于功能的实现上, 很可能就降低了对代码质量, 算法性能以及架构设计的要求.这种情况下对某些环节的监控基本上就被遗漏了, 于是导致潜在的问题不易发现, 突发问题不易排查.所以最开始产出的代码质量很难保证, 即便是上线了后能否稳定运行心里也不敢打保票. 当线上服务出现问题时…当有人告诉你服务挂了时, 怎么办呢, 你可能会很淡定的先去服务器上查查日志来看看他究竟怎么了: 123tail -n500 /.../service/output.log | grep ...tail -n500 /.../service/error.log | grep ...... 然后呢, 你发现那个错误并不能按照以往的经验来准确判断, 或者 errorlog 里啥都没有,再有可能 error log 里面一大堆, 你慢慢找吧. 好吧, 那就再等等, 看看他能不能重现: 1tail -F ... 然后再看看 Kibana 的 dashboard. 然而折腾半天之前的问题就是没出现… 有的人说: 那个错误至今没有复现, 应该不算啥大的问题吧..?也有人说: 是不是发生遵循什么规律但我们没发现..? 不过眼前还有其他好多要紧的任务呢, 这个问题反正不常出现, 日后再说.. 好吧, 那就日后再说… 直到某一天, “卧槽, 怎么又莫名其妙的出现了 ?!” 开发有点慌了, 这时候才真正开始重视这个问题… 他在想, “要是能尽早的得知问题就好了”, “要是突发问题有提醒就好了, 不用自己盯着日志一行行看…” 别担心, 交给自动化工具完成其实不用慌, 看来他只是缺少一个自动化的工具嘛~ 那么这个自动化工具是做什么的? 其实就是解决上面两个问题的: 在真正更严重的问题出现之前预防它. 当出现了未知问题时及时得知. 什么值得去监控和报警?那么, 怎么做? 换句话说, 什么 值得 我们去监控和报警?要回答这个问题, 首先我们要明确一点:公司中的每个技术团队都有其存在的价值与意义, 他们的工作作用于不同层面,对于我们应用开发来说, 没必要越疱代俎去重复底层运维的任务. 我们要做什么呢? 我们面对的是大量复杂的 业务逻辑, 这才是关注的重点.就我们的团队而言, 比如说: 哪些接口的平均/瞬时访问量比较大? 一个微服务架构的调用链中, 哪些环节的耗时比较长? 各自对应了哪些业务? 一个服务/接口的可用性有多少? 哪些接口的吞吐率较低? … 好了, 基于以上分析, 我们就可以明确到底要监测哪些指标, 也能够清楚每个监测指标的报警条件了.接下来, 就谈谈我们的报警系统的构架. Alarm System我们把整个系统分为四大环节: 指标数据的 采集 传输 &amp; 处理 分析计算 (有问题的话) 通知 收集代理数据源首先来看一下采集环, 这是所有工作的第一个环节.最基本的数据来源无非是以下三个: 代码埋点 日志 数据库 因为数据源特点的不同, 我们在采集时也面临一些问题. 有些项目可能由于历史原因, 对其代码中插入埋点十分不便, 并且容易牵连到很多其他组件.数据库如 elasticsearch 并没有(也不可能)提供 changefeed 能力, 此外 elasticsearch 侧重于读优化而不是快速写入,也就是说通过它采集数据的方式可能并不适合某些对实时性要求严格的分析过程.而日志呢, 它们的收集以及格式处理又需要额外的工具(比如 logstash). 为了解决数据来源的不确定性, 统一数据格式, 我们在采集这个环节中增加了一个 collect agent: Portal.它除了用于收集实时的指标, 还用于数据的广播, 解耦系统以及快速持久化. 现在, 待检测的指标都可以发送到 Portal 了. 传输那么从数据源到 portal 这段过程, 指标是以什么形式传输的? 使用了什么协议?这部分就讲一下从 日志/埋点 收集的指标数据的传输处理过程. 我们收集的数据是什么?这是在设计前要考虑的问题, 与其说是什么, 不如说是什么性质的.既然是用于检测的指标, 那么它应该与业务数据隔离开, 也就是说它们是非业务数据,属于样本性质, 那么也就容忍了部分丢失的可能. 最佳选择既然这样, 那么我们的选择显而易见: UDP 数据报.它的特点大家都清楚: 速度快, 不用维护连接开销. 设计原则理论上来说, 应该是直接从数据源发送到分析系统, 这是最快捷的方式,但是现在中间多了一层 agent,为了把效率的影响降低到最小, 必须要求数据的传输足够快, 转发上消耗的时间足够少.因此, 我们的设计遵循了 KISS 原则: 格式简单容易解析 无分片 为了在 MTU 不确定的链路环境下尽量不产生分片, 我们将 UDP 数据报的大小限制在 508 byte 之内. min MTU (576 byte) - max IP Header (60 byte) - UDP Header (8byte) 在这种限制下, 数据报的格式是这样的: 虽然保证了效率, 但这一做法严格限制了数据的使用, 这就要求指标只携带那些绝对有价值的信息. Portal 架构如下: 规则引擎当 portal 拿到指标之后, 下一步就通过一个 TCP 长连接将数据交给整个系统的核心组件进行处理了.在设计部分组件之前, 我考虑的问题一直是如何让它更容易使用.因为规则引擎是这个系统与使用者(维护者)交互的唯一入口: 由使用者配置报警规则.如何 对开发者友好?我觉得用简单的描述性语言写一个配置文件, 然后告诉系统你想要配置的报警规则是再简单不过了. 比如说… 一个 YAML 语法的配置: 受到 Ansible 的启发, 我就选择了 YAML 描述语言作为规则的基础语法. 下面介绍一下研发的这个规则引擎 Luna. 它是由三部分构成: 翻译引擎(YAML 语法) 异常分析 报警器 其工作原理就是: 将规则语法翻译成一个上下文对象 (你可以理解为 SDT 语法制导翻译的过程),异常分析通过这个上下文对象初始化一个探测器, 并作用于符合条件的监控指标,一旦检测到异常, 那么就调用报警器生成一个警报对象, 并将其格式化后发送给通知系统. Luna 架构如下: 检测指标类型对于异常分析来说, 他要做的就是对所有指标做分析, 计算, 观察他们是否符合既定的报警条件.那么这些指标都有什么意义呢? 或者说那些维度可以衡量? 早在 2008 年, flicker 的工程师在一片技术博客里提到了 counting &amp; timing 的计量思路, 就是计数和计时. Luna 为了提供更多的便捷分析途径, 在此基础上衍生出了更多的测量维度: count time value (例如: 满足值为 xx 的指标) rate (例如: 成功率) binary (只要拿到这个指标就满足条件) complex condition 周期分析 or 实时计算?就拿 count 计量维度来讲, 数量肯定说的是一个时间区间内的, 这就产生了一个问题: 时间区间怎么定,是滑动窗口还是跃迁窗口? 那为什么要划分实时和周期计量呢? 要回答这个问题, 得清楚几点: 不同类型(测量维度)指标的获取方式可能不同. 同类(维度)指标的获取方式也可能不同. 指标的监视粒度粗细不同. 因此两种方案都有意义, 并且 Luna 都提供了, 但应用哪种取决于很多因素.Luna 中由以下因素决定使用哪种时间窗口: 数据源类型(elasticsearch, stream) 时间区间标识(in, each) 指标维度 通常, 从 elasticsearch 取出的数据应该使用 in 作为时间区间, 这种就属于周期性计算.而来自实时流 stream 中的数据应该使用 each 作为时间区间, 这种情况则是实时计算.另外, binary, value, time 只能用于实时计算, 而 count, rate 以及复杂规则既能用于实时又能进行周期计算. 使用案例 这里拿出几个应用开发中常见需求, 整理几个常用的报警规则示例: 从实时流中获取接口 a 的耗时指标, 如果耗时超过 200ms, 那么触发 warn 等级警报. 从 elasticsearch 里获取接口 a 的访问计数指标, 如果每分钟的访问量低于 10 或高于 10_000, 触发 warn 等级警报. 从 elasticsearch 里获取接口 a 的可用性指标, 如果每分钟访问成功率(指标携带的数据中包含 state 字段为 200 的比率)低于 60%, 报 crash 警报. 从实时流中获取项目 A 的错误日志, 一旦有, 则触发 error 警报. SMMR上面演示的四个例子中, 每个都只是对单个测量指标数据应用了单个规则, 那么若果我想要施加多份规则呢?没关系, Luna 提供了 S(ingle)M(easure)M(utiple)R(rules), 你可以这么写: 更灵活的规则设置但是尽管可以 SMMR, 上面的规则都太简单了, 如果我的需求很古怪, 很复杂怎么办?在设计之初就考虑到了这点, 在基本规则不够使用时, 允许你根据自己的需求灵活的定义规则. 这就要提到另外的两个计量维度: fit/bulk. 分别表示: 对每个实时指标的自定义处理, 对一个时间窗口内的数据集合自定义处理. 当指定 for 指令为 fit 或 bulk 时, Luna 就启用了规则自定义: 那么我要如何生成自己的规则检测逻辑呢? 这里要使用一个新的指令: handle,你可以通过在 handle 中编写 Ruby 代码来自定义数据处理过程: 其中 handle 里可以使用两个重要变量: data, vars. data 依据 for 的不同可能是一个实时数据或者是一个时间区间内的数据集.vars 是通过 vars 指令设置的预定义变量列表. 那么何时报警呢? 在自定义过程中, Luna 默认不会触发任何警报, 除非 handle 的代码中返回一个 Hash,其中可以包含 :reason (报警理由), :timestamp 等字段. 通知系统当 Luna 得出了产生异常的结论, 就可以告知通知系统去通知相关人员了.这一环节我们基于 GitHub 的开源项目 Hubot 完成. Hubot 算是一种 ChatOps 思想的产物(交互式 DevOps), 我们团队中好多管理工作都交给 Hubot 完成,当然报警系统也不例外. 通过与 Slack 的高度整合, 可以很容易的完成按项目分群组通知的功能. 数据流见下图: 即由 Hubot 决定是发送邮件给对应项目成员还是广播到 Slack 相应的 channel. 扩展性接下来谈谈系统的扩展能力.我们知道, 当应用规模/数据规模达到一定程度时, 单一节点的处理能力是远远不够的, 这时候需要横向扩展.那么 Luna 能否水平扩展? 很幸运, 这非常简单, 因为 Luna 本身是一个无状态系统. 扩展方案有很多, 给出两个最简单的场景: 人工将测量指标划分成槽, 每个 Luna 实例负责一个槽的计算. 借助 Portal 的分布式特性完成自动化负载均衡. 这样便可以达到分散单一节点的计算压力以及降低资源开销的目的了. What and Not因为有些问题并不是单单从错误就能看出来的,所以我们这个报警系统的目的只是 尽早的自动化告知可能存在的隐患.所以它并不是为了取缔目前的监控工具链存在, 像 ELK 全家桶之类的工具依然在后续的分析过程中扮演了重要角色. 未来发展最后谈谈今后的计划, 首先会从以下几点完善整个系统: 适配更多数据源. 目前仅仅支持两个, 未来可能会加入 script 源, 允许更灵活的配置. 支持更丰富的规则语法. 比如现在 which 指令只允许写入固定值, 无法模糊匹配. 提供智能化异常检测(动态范围阈值). 因为当前的规则设定都需要人为写死的, 某些场景可能需要大量历史数据来判断当前区域内是否有异常出现, 这个目前最简单的方案就是用统计学中的 3-sigma 标准来判断, 或者使用更高级的手段如 Airbnb 内部使用的快速傅里叶变换等数学方法. 持久化报警事件. 比如可以根据报警事件的产生频率做进一步的统计分析. 规则热加载(开发中). 现在 Luna 只支持冷加载, 启动时将所有规则文件读入内存解析, 要想更新或加入其它规则文件必须要重启. 命令行管理工具(开发中). 每次都去修改规则文件可能并不合适, 提供一个轻便的配置工具以 RPC 形式控制 Luna 应该会更方便. 更多内容关于 Luna 的规则语法以及使用方案还有很多, 但目前只在内部使用阶段, 未来会考虑开源相关项目同时开放详细文档. Referencehttps://github.com/abbshr/abbshr.github.io/issues/59]]></content>
  </entry>
  <entry>
    <title><![CDATA[秒级监控]]></title>
    <url>%2F%E7%A7%92%E7%BA%A7%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[阿里数据库进入全网秒级实时监控时代]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql加锁处理分析]]></title>
    <url>%2Fmysql%E5%8A%A0%E9%94%81%E5%A4%84%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[背景MySQL/InnoDB的加锁分析，一直是一个比较困难的话题。我在工作过程中，经常会有同事咨询这方面的问题。同时，微博上也经常会收到MySQL锁相关的私信，让我帮助解决一些死锁的问题。本文，准备就MySQL/InnoDB的加锁问题，展开较为深入的分析与讨论，主要是介绍一种思路，运用此思路，拿到任何一条SQL语句，都能完整的分析出这条语句会加什么锁？会有什么样的使用风险？甚至是分析线上的一个死锁场景，了解死锁产生的原因。 注：MySQL是一个支持插件式存储引擎的数据库系统。本文下面的所有介绍，都是基于InnoDB存储引擎，其他引擎的表现，会有较大的区别。 MVCC：Snapshot Read vs Current ReadMySQL InnoDB存储引擎，实现的是基于多版本的并发控制协议——MVCC (Multi-Version Concurrency Control) (注：与MVCC相对的，是基于锁的并发控制，Lock-Based Concurrency Control)。MVCC最大的好处，相信也是耳熟能详：读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能，这也是为什么现阶段，几乎所有的RDBMS，都支持了MVCC。 在MVCC并发控制中，读操作可以分成两类：快照读 (snapshot read)与当前读 (current read)。快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。当前读，读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。 在一个支持MVCC并发控制的系统中，哪些读操作是快照读？哪些操作又是当前读呢？以MySQL InnoDB为例： 快照读：简单的select操作，属于快照读，不加锁。(当然，也有例外，下面会分析) select * from table where ?; 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。 select * from table where ? lock in share mode; select * from table where ? for update; insert into table values (…); update table set ? where ?; delete from table where ?; 所有以上的语句，都属于当前读，读取记录的最新版本。并且，读取之后，还需要保证其他并发事务不能修改当前记录，对读取记录加锁。其中，除了第一条语句，对读取记录加S锁 (共享锁)外，其他的操作，都加的是X锁 (排它锁)。 为什么将 插入/更新/删除 操作，都归为当前读？可以看看下面这个 更新 操作，在数据库中的执行流程： 从图中，可以看到，一个Update操作的具体流程。当Update SQL被发给MySQL后，MySQL Server会根据where条件，读取第一条满足条件的记录，然后InnoDB引擎会将第一条记录返回，并加锁 (current read)。待MySQL Server收到这条加锁的记录之后，会再发起一个Update请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有满足条件的记录为止。因此，Update操作内部，就包含了一个当前读。同理，Delete操作也一样。Insert操作会稍微有些不同，简单来说，就是Insert操作可能会触发Unique Key的冲突检查，也会进行一个当前读。 注：根据上图的交互，针对一条当前读的SQL语句，InnoDB与MySQL Server的交互，是一条一条进行的，因此，加锁也是一条一条进行的。先对一条满足条件的记录加锁，返回给MySQL Server，做一些DML操作；然后在读取下一条加锁，直至读取完毕。 Cluster Index：聚簇索引InnoDB存储引擎的数据组织方式，是聚簇索引表：完整的记录，存储在主键索引中，通过主键索引，就可以获取记录所有的列。关于聚簇索引表的组织方式，可以参考MySQL的官方文档：Clustered and Secondary Indexes 。本文假设读者对这个，已经有了一定的认识，就不再做具体的介绍。接下来的部分，主键索引/聚簇索引 两个名称，会有一些混用，望读者知晓。 2PL：Two-Phase Locking传统RDBMS加锁的一个原则，就是2PL (二阶段锁)：Two-Phase Locking。相对而言，2PL比较容易理解，说的是锁操作分为两个阶段：加锁阶段与解锁阶段，并且保证加锁阶段与解锁阶段不相交。下面，仍旧以MySQL为例，来简单看看2PL在MySQL中的实现。 从上图可以看出，2PL就是将加锁/解锁分为两个完全不相交的阶段。加锁阶段：只加锁，不放锁。解锁阶段：只放锁，不加锁。 Isolation Level隔离级别：Isolation Level)，也是RDBMS的一个关键特性。相信对数据库有所了解的朋友，对于4种隔离级别：Read Uncommited，Read Committed，Repeatable Read，Serializable，都有了深入的认识。本文不打算讨论数据库理论中，是如何定义这4种隔离级别的含义的，而是跟大家介绍一下MySQL/InnoDB是如何定义这4种隔离级别的。 MySQL/InnoDB定义的4种隔离级别： Read Uncommited 可以读取未提交记录。此隔离级别，不会使用，忽略。 Read Committed (RC) 快照读忽略，本文不考虑。 针对当前读，RC隔离级别保证对读取到的记录加锁 (记录锁)，存在幻读现象。 Repeatable Read (RR) 快照读忽略，本文不考虑。 针对当前读，RR隔离级别保证对读取到的记录加锁 (记录锁)，同时保证对读取的范围加锁，新的满足查询条件的记录不能够插入 (间隙锁)，不存在幻读现象。 Serializable 从MVCC并发控制退化为基于锁的并发控制。不区别快照读与当前读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。 Serializable隔离级别下，读写冲突，因此并发度急剧下降，在MySQL/InnoDB下不建议使用。 一条简单SQL的加锁实现分析 在介绍完一些背景知识之后，本文接下来将选择几个有代表性的例子，来详细分析MySQL的加锁处理。当然，还是从最简单的例子说起。经常有朋友发给我一个SQL，然后问我，这个SQL加什么锁？就如同下面两条简单的SQL，他们加什么锁？ SQL1：select * from t1 where id = 10; SQL2：delete from t1 where id = 10; 针对这个问题，该怎么回答？我能想象到的一个答案是： SQL1：不加锁。因为MySQL是使用多版本并发控制的，读不加锁。 SQL2：对id = 10的记录加写锁 (走主键索引)。 这个答案对吗？说不上来。即可能是正确的，也有可能是错误的，已知条件不足，这个问题没有答案。如果让我来回答这个问题，我必须还要知道以下的一些前提，前提不同，我能给出的答案也就不同。要回答这个问题，还缺少哪些前提条件？ 前提一：id列是不是主键？ 前提二：当前系统的隔离级别是什么？ 前提三：id列如果不是主键，那么id列上有索引吗？ 前提四：id列上如果有二级索引，那么这个索引是唯一索引吗？ 前提五：两个SQL的执行计划是什么？索引扫描？全表扫描？ 没有这些前提，直接就给定一条SQL，然后问这个SQL会加什么锁，都是很业余的表现。而当这些问题有了明确的答案之后，给定的SQL会加什么锁，也就一目了然。下面，我将这些问题的答案进行组合，然后按照从易到难的顺序，逐个分析每种组合下，对应的SQL会加哪些锁？ 注：下面的这些组合，我做了一个前提假设，也就是有索引时，执行计划一定会选择使用索引进行过滤 (索引扫描)。但实际情况会复杂很多，真正的执行计划，还是需要根据MySQL输出的为准。 组合一：id列是主键，RC隔离级别 组合二：id列是二级唯一索引，RC隔离级别 组合三：id列是二级非唯一索引，RC隔离级别 组合四：id列上没有索引，RC隔离级别 组合五：id列是主键，RR隔离级别 组合六：id列是二级唯一索引，RR隔离级别 组合七：id列是二级非唯一索引，RR隔离级别 组合八：id列上没有索引，RR隔离级别 组合九：Serializable隔离级别 排列组合还没有列举完全，但是看起来，已经很多了。真的有必要这么复杂吗？事实上，要分析加锁，就是需要这么复杂。但是从另一个角度来说，只要你选定了一种组合，SQL需要加哪些锁，其实也就确定了。接下来，就让我们来逐个分析这9种组合下的SQL加锁策略。 注：在前面八种组合下，也就是RC，RR隔离级别下，SQL1：select操作均不加锁，采用的是快照读，因此在下面的讨论中就忽略了，主要讨论SQL2：delete操作的加锁。 组合一：id主键+RC这个组合，是最简单，最容易分析的组合。id是主键，Read Committed隔离级别，给定SQL：delete from t1 where id = 10; 只需要将主键上，id = 10的记录加上X锁即可。如下图所示： 结论：id是主键时，此SQL只需要在id=10这条记录上加X锁即可。 组合二：id唯一索引+RC这个组合，id不是主键，而是一个Unique的二级索引键值。那么在RC隔离级别下，delete from t1 where id = 10; 需要加什么锁呢？见下图： 此组合中，id是unique索引，而主键是name列。此时，加锁的情况由于组合一有所不同。由于id是unique索引，因此delete语句会选择走id列的索引进行where条件的过滤，在找到id=10的记录后，首先会将unique索引上的id=10索引记录加上X锁，同时，会根据读取到的name列，回主键索引(聚簇索引)，然后将聚簇索引上的name = ‘d’ 对应的主键索引项加X锁。为什么聚簇索引上的记录也要加锁？试想一下，如果并发的一个SQL，是通过主键索引来更新：update t1 set id = 100 where name = ‘d’; 此时，如果delete语句没有将主键索引上的记录加锁，那么并发的update就会感知不到delete语句的存在，违背了同一记录上的更新/删除需要串行执行的约束。 结论：若id列是unique列，其上有unique索引。那么SQL需要加两个X锁，一个对应于id unique索引上的id = 10的记录，另一把锁对应于聚簇索引上的[name=’d’,id=10]的记录。 组合三：id非唯一索引+RC 相对于组合一、二，组合三又发生了变化，隔离级别仍旧是RC不变，但是id列上的约束又降低了，id列不再唯一，只有一个普通的索引。假设delete from t1 where id = 10; 语句，仍旧选择id列上的索引进行过滤where条件，那么此时会持有哪些锁？同样见下图： 根据此图，可以看到，首先，id列索引上，满足id = 10查询条件的记录，均已加锁。同时，这些记录对应的主键索引上的记录也都加上了锁。与组合二唯一的区别在于，组合二最多只有一个满足等值查询的记录，而组合三会将所有满足查询条件的记录都加锁。 结论：若id列上有非唯一索引，那么对应的所有满足SQL查询条件的记录，都会被加锁。同时，这些记录在主键索引上的记录，也会被加锁。 组合四：id无索引+RC相对于前面三个组合，这是一个比较特殊的情况。id列上没有索引，where id = 10;这个过滤条件，没法通过索引进行过滤，那么只能走全表扫描做过滤。对应于这个组合，SQL会加什么锁？或者是换句话说，全表扫描时，会加什么锁？这个答案也有很多：有人说会在表上加X锁；有人说会将聚簇索引上，选择出来的id = 10;的记录加上X锁。那么实际情况呢？请看下图： 由于id列上没有索引，因此只能走聚簇索引，进行全部扫描。从图中可以看到，满足删除条件的记录有两条，但是，聚簇索引上所有的记录，都被加上了X锁。无论记录是否满足条件，全部被加上X锁。既不是加表锁，也不是在满足条件的记录上加行锁。 有人可能会问？为什么不是只在满足条件的记录上加锁呢？这是由于MySQL的实现决定的。如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由MySQL Server层进行过滤。因此也就把所有的记录，都锁上了。 注：在实际的实现中，MySQL有一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录放锁 (违背了2PL的约束)。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。 结论：若id列上没有索引，SQL会走聚簇索引的全扫描进行过滤，由于过滤是由MySQL Server层面进行的。因此每条记录，无论是否满足条件，都会被加上X锁。但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后放锁，最终持有的，是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不会省略。同时，优化也违背了2PL的约束。 组合五：id主键+RR上面的四个组合，都是在Read Committed隔离级别下的加锁行为，接下来的四个组合，是在Repeatable Read隔离级别下的加锁行为。 组合五，id列是主键列，Repeatable Read隔离级别，针对delete from t1 where id = 10; 这条SQL，加锁与组合一：[id主键，Read Committed]一致。 组合六：id唯一索引+RR与组合五类似，组合六的加锁，与组合二：[id唯一索引，Read Committed]一致。两个X锁，id唯一索引满足条件的记录上一个，对应的聚簇索引上的记录一个。 组合七：id非唯一索引+RR还记得前面提到的MySQL的四种隔离级别的区别吗？RC隔离级别允许幻读，而RR隔离级别，不允许存在幻读。但是在组合五、组合六中，加锁行为又是与RC下的加锁行为完全一致。那么RR隔离级别下，如何防止幻读呢？问题的答案，就在组合七中揭晓。 组合七，Repeatable Read隔离级别，id上有一个非唯一索引，执行delete from t1 where id = 10; 假设选择id列上的索引进行条件过滤，最后的加锁行为，是怎么样的呢？同样看下面这幅图： 此图，相对于组合三：[id列上非唯一锁，Read Committed]看似相同，其实却有很大的区别。最大的区别在于，这幅图中多了一个GAP锁，而且GAP锁看起来也不是加在记录上的，倒像是加载两条记录之间的位置，GAP锁有何用？ 其实这个多出来的GAP锁，就是RR隔离级别，相对于RC隔离级别，不会出现幻读的关键。确实，GAP锁锁住的位置，也不是记录本身，而是两条记录之间的GAP。所谓幻读，就是同一个事务，连续做两次当前读 (例如：select * from t1 where id = 10 for update;)，那么这两次当前读返回的是完全相同的记录 (记录数量一致，记录本身也一致)，第二次的当前读，不会比第一次返回更多的记录 (幻象)。 如何保证两次当前读返回一致的记录，那就需要在第一次当前读与第二次当前读之间，其他的事务不会插入新的满足条件的记录并提交。为了实现这个功能，GAP锁应运而生。 如图中所示，有哪些位置可以插入新的满足条件的项 (id = 10)，考虑到B+树索引的有序性，满足条件的项一定是连续存放的。记录[6,c]之前，不会插入id=10的记录；[6,c]与[10,b]间可以插入[10, aa]；[10,b]与[10,d]间，可以插入新的[10,bb],[10,c]等；[10,d]与[11,f]间可以插入满足条件的[10,e],[10,z]等；而[11,f]之后也不会插入满足条件的记录。因此，为了保证[6,c]与[10,b]间，[10,b]与[10,d]间，[10,d]与[11,f]不会插入新的满足条件的记录，MySQL选择了用GAP锁，将这三个GAP给锁起来。 Insert操作，如insert [10,aa]，首先会定位到[6,c]与[10,b]间，然后在插入前，会检查这个GAP是否已经被锁上，如果被锁上，则Insert不能插入记录。因此，通过第一遍的当前读，不仅将满足条件的记录锁上 (X锁)，与组合三类似。同时还是增加3把GAP锁，将可能插入满足条件记录的3个GAP给锁上，保证后续的Insert不能插入新的id=10的记录，也就杜绝了同一事务的第二次当前读，出现幻象的情况。 有心的朋友看到这儿，可以会问：既然防止幻读，需要靠GAP锁的保护，为什么组合五、组合六，也是RR隔离级别，却不需要加GAP锁呢？ 首先，这是一个好问题。其次，回答这个问题，也很简单。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。而组合五，id是主键；组合六，id是unique键，都能够保证唯一性。一个等值查询，最多只能返回一条记录，而且新的相同取值的记录，一定不会在新插入进来，因此也就避免了GAP锁的使用。其实，针对此问题，还有一个更深入的问题：如果组合五、组合六下，针对SQL：select * from t1 where id = 10 for update; 第一次查询，没有找到满足查询条件的记录，那么GAP锁是否还能够省略？此问题留给大家思考。 结论：Repeatable Read隔离级别下，id列上有一个非唯一索引，对应SQL：delete from t1 where id = 10; 首先，通过id索引定位到第一条满足查询条件的记录，加记录上的X锁，加GAP上的GAP锁，然后加主键聚簇索引上的记录X锁，然后返回；然后读取下一条，重复进行。直至进行到第一条不满足条件的记录[11,f]，此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。 组合八：id无索引+RR组合八，Repeatable Read隔离级别下的最后一种情况，id列上没有索引。此时SQL：delete from t1 where id = 10; 没有其他的路径可以选择，只能进行全表扫描。最终的加锁情况，如下图所示： 如图，这是一个很恐怖的现象。首先，聚簇索引上的所有记录，都被加上了X锁。其次，聚簇索引每条记录间的间隙(GAP)，也同时被加上了GAP锁。这个示例表，只有6条记录，一共需要6个记录锁，7个GAP锁。试想，如果表上有1000万条记录呢？ 在这种情况下，这个表上，除了不加锁的快照度，其他任何加锁的并发SQL，均不能执行，不能更新，不能删除，不能插入，全表被锁死。 当然，跟组合四：[id无索引, Read Committed]类似，这个情况下，MySQL也做了一些优化，就是所谓的semi-consistent read。semi-consistent read开启的情况下，对于不满足查询条件的记录，MySQL会提前放锁。针对上面的这个用例，就是除了记录[d,10]，[g,10]之外，所有的记录锁都会被释放，同时不加GAP锁。semi-consistent read如何触发：要么是read committed隔离级别；要么是Repeatable Read隔离级别，同时设置了 innodb_locks_unsafe_for_binlog 参数。更详细的关于semi-consistent read的介绍，可参考我之前的一篇博客：MySQL+InnoDB semi-consitent read原理及实现分析 。 结论：在Repeatable Read隔离级别下，如果进行全表扫描的当前读，那么会锁上表中的所有记录，同时会锁上聚簇索引内的所有GAP，杜绝所有的并发 更新/删除/插入 操作。当然，也可以通过触发semi-consistent read，来缓解加锁开销与并发影响，但是semi-consistent read本身也会带来其他问题，不建议使用。 组合九：Serializable针对前面提到的简单的SQL，最后一个情况：Serializable隔离级别。对于SQL2：delete from t1 where id = 10; 来说，Serializable隔离级别与Repeatable Read隔离级别完全一致，因此不做介绍。 Serializable隔离级别，影响的是SQL1：select * from t1 where id = 10; 这条SQL，在RC，RR隔离级别下，都是快照读，不加锁。但是在Serializable隔离级别，SQL1会加读锁，也就是说快照读不复存在，MVCC并发控制降级为Lock-Based CC。 结论：在MySQL/InnoDB中，所谓的读不加锁，并不适用于所有的情况，而是隔离级别相关的。Serializable隔离级别，读不加锁就不再成立，所有的读操作，都是当前读。 一条复杂的SQL写到这里，其实MySQL的加锁实现也已经介绍的八八九九。只要将本文上面的分析思路，大部分的SQL，都能分析出其会加哪些锁。而这里，再来看一个稍微复杂点的SQL，用于说明MySQL加锁的另外一个逻辑。SQL用例如下： 如图中的SQL，会加什么锁？假定在Repeatable Read隔离级别下 (Read Committed隔离级别下的加锁情况，留给读者分析。)，同时，假设SQL走的是idx_t1_pu索引。 在详细分析这条SQL的加锁情况前，还需要有一个知识储备，那就是一个SQL中的where条件如何拆分？具体的介绍，建议阅读我之前的一篇文章：SQL中的where条件，在数据库中提取与应用浅析 。在这里，我直接给出分析后的结果： Index key：pubtime &gt; 1 and puptime &lt; 20。此条件，用于确定SQL在idx_t1_pu索引上的查询范围。 Index Filter：userid = ‘hdc’ 。此条件，可以在idx_t1_pu索引上进行过滤，但不属于Index Key。 Table Filter：comment is not NULL。此条件，在idx_t1_pu索引上无法过滤，只能在聚簇索引上过滤。 在分析出SQL where条件的构成之后，再来看看这条SQL的加锁情况 (RR隔离级别)，如下图所示： 从图中可以看出，在Repeatable Read隔离级别下，由Index Key所确定的范围，被加上了GAP锁；Index Filter锁给定的条件 (userid = ‘hdc’)何时过滤，视MySQL的版本而定，在MySQL 5.6版本之前，不支持Index Condition Pushdown(ICP)，因此Index Filter在MySQL Server层过滤，在5.6后支持了Index Condition Pushdown，则在index上过滤。若不支持ICP，不满足Index Filter的记录，也需要加上记录X锁，若支持ICP，则不满足Index Filter的记录，无需加记录X锁 (图中，用红色箭头标出的X锁，是否要加，视是否支持ICP而定)；而Table Filter对应的过滤条件，则在聚簇索引中读取后，在MySQL Server层面过滤，因此聚簇索引上也需要X锁。最后，选取出了一条满足条件的记录[8,hdc,d,5,good]，但是加锁的数量，要远远大于满足条件的记录数量。 结论：在Repeatable Read隔离级别下，针对一个复杂的SQL，首先需要提取其where条件。Index Key确定的范围，需要加上GAP锁；Index Filter过滤条件，视MySQL版本是否支持ICP，若支持ICP，则不满足Index Filter的记录，不加X锁，否则需要X锁；Table Filter过滤条件，无论是否满足，都需要加X锁。 死锁原理与分析本文前面的部分，基本上已经涵盖了MySQL/InnoDB所有的加锁规则。深入理解MySQL如何加锁，有两个比较重要的作用： 可以根据MySQL的加锁规则，写出不会发生死锁的SQL； 可以根据MySQL的加锁规则，定位出线上产生死锁的原因； 下面，来看看两个死锁的例子 (一个是两个Session的两条SQL产生死锁；另一个是两个Session的一条SQL，产生死锁)： 上面的两个死锁用例。第一个非常好理解，也是最常见的死锁，每个事务执行两条SQL，分别持有了一把锁，然后加另一把锁，产生死锁。 第二个用例，虽然每个Session都只有一条语句，仍旧会产生死锁。要分析这个死锁，首先必须用到本文前面提到的MySQL加锁的规则。针对Session 1，从name索引出发，读到的[hdc, 1]，[hdc, 6]均满足条件，不仅会加name索引上的记录X锁，而且会加聚簇索引上的记录X锁，加锁顺序为先[1,hdc,100]，后[6,hdc,10]。而Session 2，从pubtime索引出发，[10,6],[100,1]均满足过滤条件，同样也会加聚簇索引上的记录X锁，加锁顺序为[6,hdc,10]，后[1,hdc,100]。发现没有，跟Session 1的加锁顺序正好相反，如果两个Session恰好都持有了第一把锁，请求加第二把锁，死锁就发生了。 结论：死锁的发生与否，并不在于事务中有多少条SQL语句，死锁的关键在于：两个(或以上)的Session加锁的顺序不一致。而使用本文上面提到的，分析MySQL每条SQL语句的加锁规则，分析出每条语句的加锁顺序，然后检查多个并发SQL间是否存在以相反的顺序加锁的情况，就可以分析出各种潜在的死锁情况，也可以分析出线上死锁发生的原因。 总结写到这儿，本文也告一段落，做一个简单的总结，要做的完全掌握MySQL/InnoDB的加锁规则，甚至是其他任何数据库的加锁规则，需要具备以下的一些知识点： 了解数据库的一些基本理论知识：数据的存储格式 (堆组织表 vs 聚簇索引表)；并发控制协议 (MVCC vs Lock-Based CC)；Two-Phase Locking；数据库的隔离级别定义 (Isolation Level)； 了解SQL本身的执行计划 (主键扫描 vs 唯一键扫描 vs 范围扫描 vs 全表扫描)； 了解数据库本身的一些实现细节 (过滤条件提取；Index Condition Pushdown；Semi-Consistent Read)； 了解死锁产生的原因及分析的方法 (加锁顺序不一致；分析每个SQL的加锁顺序) 有了这些知识点，再加上适当的实战经验，全面掌控MySQL/InnoDB的加锁规则，当不在话下。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka为什么快]]></title>
    <url>%2Fkafka%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BF%AB%2F</url>
    <content type="text"><![CDATA[为什么Kafka那么快Kafka为什么如此的快KAFKA：如何做到1秒发布百万级条消息磁盘及网络IO工作方式解析零拷贝的实现机制Kafka副本同步机制理解]]></content>
  </entry>
  <entry>
    <title><![CDATA[intern]]></title>
    <url>%2Fintern%2F</url>
    <content type="text"><![CDATA[12345String str1 = new StringBuilder("ni ").append("hao").toString();System.out.println(str1.intern() == str1);String str2 = new StringBuilder("ja").append("va").toString();System.out.println(str2.intern() == str2); 这段代码在jdk1.6中运行，会得到两个false，而在jdk1.7中运行会得到一个true一个false。产生差异的原因是：在jdk1.6中，intern()方法会把首次遇到的字符串实例复制到永久代中，返回的也是永久代中这个字符串实例的引用，而用StringBuilder创建的字符串实例在Java堆上，所以必然不是同一个引用，将返回false。而jdk1.7中的intern()实现不会再复制实例，只是在常量池中记录首次出现的实例引用，因此intern()返回的引用和由StringBuilder创建的那个字符串实例是同一个。对str2比较返回false是因为“java”这个字符串在执行StringBuilder.toString()之前已经出现过，字符串常量池中已经有它的引用了，不符合首次出现的原则，而“ni hao”这个字符串则是首次出现的，因此返回true。 123456String s1 = "Programming";String s2 = new String("Programming");String s3 = "Program" + "ming";System.out.println(s1 == s2);System.out.println(s1 == s3);System.out.println(s1 == s1.intern()); 12345678910111213141516171819202122232425//s1常量池中String s1 = "ab123" ;//s2在堆中String s2 = new String( "ab123" ) ;System.out.println( s1 == s2 );//s3到常量池中取s1的引用String s3 = s2.intern() ;System.out.println( s1 == s3 ) ;//而s2在堆中，并没有在常量池中System.out.println(s2 == s3);//new会创建两个对象，两个1在堆上，而另两个1在常量池中，// intern指向常量池,寻找11并没有，就在常量池中新建11，s4就指向s6，而s6==s5String s5 = new String("1") + new String("1");s5.intern();String s4 = "11";System.out.println(s5 == s4);//new会创建两个对象，一个9在堆上，而另一个在常量池中，// intern指向常量池，并没有在常量池中新建9,ss指向常量池,String s = new String("9");s.intern();String ss = "9";//s在堆上，而ss在常量池中System.out.println(s == ss);]]></content>
  </entry>
  <entry>
    <title><![CDATA[cassandra]]></title>
    <url>%2Fcassandra%2F</url>
    <content type="text"><![CDATA[深入理解Cassandra中的数据建模]]></content>
  </entry>
  <entry>
    <title><![CDATA[es合集]]></title>
    <url>%2Fes%2F</url>
    <content type="text"><![CDATA[分布式 ES 操作流程解析Elasticsearch 权威指南（中文版）]]></content>
      <categories>
        <category>es</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Lucene]]></title>
    <url>%2FLucene%2F</url>
    <content type="text"><![CDATA[Lucene底层原理和优化经验分享(1)-Lucene简介和索引原理跳跃表SkipList跳表基本原理跳跃表 复杂度分析]]></content>
  </entry>
  <entry>
    <title><![CDATA[storm]]></title>
    <url>%2Fstorm%2F</url>
    <content type="text"><![CDATA[Storm介绍及原理storm源码之理解Storm中Worker、Executor、Task关系]]></content>
  </entry>
  <entry>
    <title><![CDATA[时序数据库]]></title>
    <url>%2F%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[时序数据库深入浅出之存储篇Cassandra预聚合方案设计基于ES的时序数据库服务 - Elastic中文社区时间序列数据的存储和计算 - 开源时序数据库解析KairosDB Cassandra Schema]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式事务以及解决方案]]></title>
    <url>%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[聊聊分布式事务，再说说解决方案分布式系统的事务处理分布式系统事务一致性解决方案分布式开放消息系统(RocketMQ)的原h理与实践]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper Leader选举算法]]></title>
    <url>%2Fzookeeper%2Fleader-election%2F</url>
    <content type="text"><![CDATA[当Leader崩溃或者Leader失去大多数的Follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的Leader，让所有的Server都恢复到一个正确的状态。Zookeeper中Leader的选举采用了三种算法： LeaderElection FastLeaderElection AuthFastLeaderElection 并且在配置文件中是可配置的，对应的配置项为electionAlg。 背景知识Zookeeper Server的状态可分为四种： LOOKING：寻找Leader LEADING：Leader状态，对应的节点为Leader。 FOLLOWING：Follower状态，对应的节点为Follower。 OBSERVING：Observer状态，对应节点为Observer，该节点不参与Leader选举。 成为Leader的必要条件： Leader要具有最高的zxid；当集群的规模是n时，集群中大多数的机器（至少n/2+1）得到响应并follow选出的Leader。 心跳机制：Leader与Follower利用PING来感知对方的是否存活，当Leader无法相应PING时，将重新发起Leader选举。 术语zxid：zookeeper transaction id, 每个改变Zookeeper状态的操作都会形成一个对应的zxid，并记录到transaction log中。 这个值越大，表示更新越新。 electionEpoch/logicalclock：逻辑时钟，用来判断是否为同一次选举。每调用一次选举函数，logicalclock自增1，并且在选举过程中如果遇到election比当前logicalclock大的值，就更新本地logicalclock的值。 peerEpoch: 表示节点的Epoch。 LeaderElection选举算法LeaderElection是Fast Paxos最简单的一种实现，每个Server启动以后都询问其它的Server它要投票给谁，收到所有Server回复以后，就计算出zxid最大的哪个Server，并将这个Server相关信息设置成下一次要投票的Server。该算法于Zookeeper 3.4以后的版本废弃。 选举算法流程如下： 选举线程首先向所有Server发起一次询问(包括自己)； 选举线程收到回复后，验证是否是自己发起的询问(验证xid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些信息存储到当次选举的投票记录表中； 收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server； 线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得多数Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。 通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1. 异常问题的处理： 选举过程中，Server的加入当一个Server启动时它都会发起一次选举，此时由选举线程发起相关流程，那么每个 Serve r都会获得当前zxi d最大的哪个Serve r是谁，如果当次最大的Serve r没有获得n/2+1 个票数，那么下一次投票时，他将向zxid最大的Server投票，重复以上流程，最后一定能选举出一个Leader。 选举过程中，Server的退出只要保证n/2+1个Server存活就没有任何问题，如果少于n/2+1个Server 存活就没办法选出Leader。 选举过程中，Leader死亡当选举出Leader以后，此时每个Server应该是什么状态(FLLOWING)都已经确定，此时由于Leader已经死亡我们就不管它，其它的Fllower按正常的流程继续下去，当完成这个流程以后，所有的Fllower都会向Leader发送Ping消息，如果无法ping通，就改变自己的状为(FLLOWING ==&gt; LOOKING)，发起新的一轮选举。 选举完成以后，Leader死亡处理过程同上。 双主问题Leader的选举是保证只产生一个公认的Leader的，而且Follower重新选举与旧Leader恢复并退出基本上是同时发生的，当Follower无法ping同Leader是就认为Leader已经出问题开始重新选举，Leader收到Follower的ping没有达到半数以上则要退出Leader重新选举。 FastLeaderElection选举算法由于LeaderElection收敛速度较慢，所以Zookeeper引入了FastLeaderElection选举算法，FastLeaderElection也成了Zookeeper默认的Leader选举算法。 FastLeaderElection是标准的Fast Paxos的实现，它首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决 epoch 和 zxid 的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息。FastLeaderElection算法通过异步的通信方式来收集其它节点的选票，同时在分析选票时又根据投票者的当前状态来作不同的处理，以加快Leader的选举进程。 算法流程数据恢复阶段每个ZooKeeper Server读取当前磁盘的数据（transaction log），获取最大的zxid。 发送选票每个参与投票的ZooKeeper Server向其他Server发送自己所推荐的Leader，这个协议中包括几部分数据： 所推举的Leader id。在初始阶段，第一次投票所有Server都推举自己为Leader。 本机的最大zxid值。这个值越大，说明该Server的数据越新。 logicalclock。这个值从0开始递增，每次选举对应一个值，即在同一次选举中，这个值是一致的。这个值越大说明选举进程越新。 本机的所处状态。包括LOOKING，FOLLOWING，OBSERVING，LEADING。 处理选票每台Server将自己的数据发送给其他Server之后，同样也要接受其他Server的选票，并做一下处理。 如果Sender的状态是LOOKING 如果发送过来的logicalclock大于目前的logicalclock。说明这是更新的一次选举，需要更新本机的logicalclock，同事清空已经收集到的选票，因为这些数据已经不再有效。然后判断是否需要更新自己的选举情况。首先判断zxid，zxid大者胜出；如果相同比较leader id，大者胜出。 如果发送过来的logicalclock小于于目前的logicalclock。说明对方处于一个比较早的选举进程，只需要将本机的数据发送过去即可。 如果发送过来的logicalclock等于目前的logicalclock。根据收到的zxid和leader id更新选票，然后广播出去。 当Server处理完选票后，可能需要对Server的状态进行更新： 判断服务器是否已经收集到所有的服务器的选举状态。如果是根据选举结果设置自己的角色（FOLLOWING or LEADER），然后退出选举。 如果没有收到没有所有服务器的选举状态，也可以判断一下根据以上过程之后更新的选举Leader是不是得到了超过半数以上服务器的支持。如果是，那么尝试在200ms内接收下数据，如果没有心数据到来说明大家已经认同这个结果。这时，设置角色然后退出选举。 如果Sender的状态是FOLLOWING或者LEADER 如果LogicalClock相同，将数据保存早recvset，如果Sender宣称自己是Leader，那么判断是不是半数以上的服务器都选举它，如果是设置角色并退出选举。 否则，这是一条与当前LogicalClock不符合的消息，说明在另一个选举过程中已经有了选举结果，于是将该选举结果加入到OutOfElection集合中，根据OutOfElection来判断是否可以结束选举，如果可以也是保存LogicalClock，更新角色，退出选举。 具体实现数据结构本地消息结构： 12345678910static public class Notification &#123;long leader; //所推荐的Server idlong zxid; //所推荐的Server的zxid(zookeeper transtion id)long epoch; //描述leader是否变化(每一个Server启动时都有一个logicalclock，初始值为0)QuorumPeer.ServerState state; //发送者当前的状态InetSocketAddress addr; //发送者的ip地址&#125; 网络消息结构： 123456789101112static public class ToSend &#123;int type; //消息类型long leader; //Server idlong zxid; //Server的zxidlong epoch; //Server的epochQuorumPeer.ServerState state; //Server的statelong tag; //消息编号InetSocketAddress addr;&#125; 线程处理每个Server都一个接收线程池和一个发送线程池, 在没有发起选举时，这两个线程池处于阻塞状态，直到有消息到来时才解除阻塞并处理消息，同时每个Server都有一个选举线程(可以发起选举的线程担任)。 接收线程的处理notification: 首先检测当前Server上所被推荐的zxid,epoch是否合法(currentServer.epoch &lt;= currentMsg.epoch &amp;&amp; (currentMsg.zxid &gt; currentServer.zxid || (currentMsg.zxid == currentServer.zxid &amp;&amp; currentMsg.id &gt; currentServer.id))) 如果不合法就用消息中的zxid,epoch,id更新当前Server所被推荐的值，此时将收到的消息转换成Notification消息放入接收队列中，将向对方发送ack消息。ack: 将消息编号放入ack队列中，检测对方的状态是否是LOOKING状态，如果不是说明此时已经有Leader已经被选出来，将接收到的消息转发成Notification消息放入接收对队列 发送线程池的处理notification: 将要发送的消息由Notification消息转换成ToSend消息，然后发送对方，并等待对方的回复,如果在等待结束没有收到对方法回复，重做三次,如果重做次还是没有收到对方的回复时检测当前的选举(epoch)是否已经改变，如果没有改变，将消息再次放入发送队列中，一直重复直到有Leader选出或者收到对方回复为止。ack: 主要将自己相关信息发送给对方 选举线程的处理首先自己的epoch加1，然后生成notification消息,并将消息放入发送队列中，系统中配置有几个Server就生成几条消息，保证每个Server都能收到此消息,如果当前Server的状态是LOOKING就一直循环检查接收队列是否有消息，如果有消息，根据消息中对方的状态进行相应的处理。 AuthFastLeaderElection选举算法AuthFastLeaderElection算法同FastLeaderElection算法基本一致，只是在消息中加入了认证信息，该算法在最新的Zookeeper中也建议弃用。 Example下面看一个Leader选举的例子以加深对Leader选举算法的理解。 服务器1启动,此时只有它一台服务器启动了,它发出去的报没有任何响应,所以它的选举状态一直是LOOKING状态. 服务器2启动,它与最开始启动的服务器1进行通信,互相交换自己的选举结果,由于两者都没有历史数据,所以id值较大的服务器2胜出,但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是3),所以服务器1,2还是继续保持LOOKING状态. 服务器3启动,根据前面的理论分析,服务器3成为服务器1,2,3中的Leader,而与上面不同的是,此时有三台服务器选举了它,所以它成为了这次选举的Leader. 服务器4启动,根据前面的分析,理论上服务器4应该是服务器1,2,3,4中最大的,但是由于前面已经有半数以上的服务器选举了服务器3,所以它只能是Follower. 服务器5启动,同4一样,Follower. 参考资料http://www.yidooo.net/2014/10/18/zookeeper-leader-election.html]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java nio 浅析]]></title>
    <url>%2Fjava%2Fjavanio%2F</url>
    <content type="text"><![CDATA[NIO（Non-blocking I/O，在Java领域，也称为New I/O），是一种同步非阻塞的I/O模型，也是I/O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O处理问题的有效方式。 那么NIO的本质是什么样的呢？它是怎样与事件模型结合来解放线程、提高系统吞吐的呢？ 本文会从传统的阻塞I/O和线程池模型面临的问题讲起，然后对比几种常见I/O模型，一步步分析NIO怎么利用事件模型处理I/O，解决线程池瓶颈处理海量连接，包括利用面向事件的方式编写服务端/客户端程序。最后延展到一些高级主题，如Reactor与Proactor模型的对比、Selector的唤醒、Buffer的选择等。 注：本文的代码都是伪代码，主要是为了示意，不可用于生产环境。 传统BIO模型分析让我们先回忆一下传统的服务器端同步阻塞I/O处理（也就是BIO，Blocking I/O）的经典编程模型： 1234567891011121314151617181920212223242526&#123; ExecutorService executor = Excutors.newFixedThreadPollExecutor(100);//线程池 ServerSocket serverSocket = new ServerSocket(); serverSocket.bind(8088); while(!Thread.currentThread.isInturrupted())&#123;//主线程死循环等待新连接到来 Socket socket = serverSocket.accept(); executor.submit(new ConnectIOnHandler(socket));//为新的连接创建新的线程&#125;class ConnectIOnHandler extends Thread&#123; private Socket socket; public ConnectIOnHandler(Socket socket)&#123; this.socket = socket; &#125; public void run()&#123; while(!Thread.currentThread.isInturrupted()&amp;&amp;!socket.isClosed())&#123;死循环处理读写事件 String someThing = socket.read()....//读取数据 if(someThing!=null)&#123; ......//处理数据 socket.write()....//写数据 &#125; &#125; &#125;&#125; 这是一个经典的每连接每线程的模型，之所以使用多线程，主要原因在于socket.accept()、socket.read()、socket.write()三个主要函数都是同步阻塞的，当一个连接在处理I/O的时候，系统是阻塞的，如果是单线程的话必然就挂死在那里；但CPU是被释放出来的，开启多线程，就可以让CPU去处理更多的事情。其实这也是所有使用多线程的本质： 利用多核。 当I/O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。 现在的多线程一般都使用线程池，可以让线程的创建和回收成本相对较低。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的I/O并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。 不过，这个模型最本质的问题在于，严重依赖于线程。但线程是很”贵”的资源，主要表现在： 线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。 线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。 线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过20%以上)，导致系统几乎陷入不可用的状态。 容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激活大量阻塞线程从而使系统负载压力过大。 所以，当面对十万甚至百万级连接的时候，传统的BIO模型是无能为力的。随着移动端应用的兴起和各种网络游戏的盛行，百万级长连接日趋普遍，此时，必然需要一种更高效的I/O处理模型。 NIO是怎么工作的很多刚接触NIO的人，第一眼看到的就是Java相对晦涩的API，比如：Channel，Selector，Socket什么的；然后就是一坨上百行的代码来演示NIO的服务端Demo……瞬间头大有没有？ 我们不管这些，抛开现象看本质，先分析下NIO是怎么工作的。 常见I/O模型对比所有的系统I/O都分为两个阶段：等待就绪和操作。举例来说，读函数，分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。 需要说明的是等待就绪的阻塞是不使用CPU的，是在“空等”；而真正的读写操作的阻塞是使用CPU的，真正在”干活”，而且这个过程非常快，属于memory copy，带宽通常在1GB/s级别以上，可以理解为基本不耗时。 下图是几种常见I/O模型的对比： 以socket.read()为例子： 传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，直到收到数据，返回读到的数据。 对于NIO，如果TCP RecvBuffer有数据，就把数据从网卡读到内存，并且返回给用户；反之则直接返回0，永远不会阻塞。 最新的AIO(Async I/O)里面会更进一步：不但等待就绪是非阻塞的，就连数据从网卡到内存的过程也是异步的。 换句话说，BIO里用户最关心“我要读”，NIO里用户最关心”我可以读了”，在AIO模型里用户更需要关注的是“读完了”。 NIO一个重要的特点是：socket主要的读、写、注册和接收函数，在等待就绪阶段都是非阻塞的，真正的I/O操作是同步阻塞的（消耗CPU但性能非常高）。 如何结合事件模型使用NIO同步非阻塞特性回忆BIO模型，之所以需要多线程，是因为在进行I/O操作的时候，一是没有办法知道到底能不能写、能不能读，只能”傻等”，即使通过各种估算，算出来操作系统没有能力进行读写，也没法在socket.read()和socket.write()函数中返回，这两个函数无法进行有效的中断。所以除了多开线程另起炉灶，没有好的办法利用CPU。 NIO的读写函数可以立刻返回，这就给了我们不开线程利用CPU的最好机会：如果一个连接不能读写（socket.read()返回0或者socket.write()返回0），我们可以把这件事记下来，记录的方式通常是在Selector上注册标记位，然后切换到其它就绪的连接（channel）继续进行读写。 下面具体看下如何利用事件模型单线程处理所有I/O请求： NIO的主要事件有几个：读就绪、写就绪、有新连接到来。 我们首先需要注册当这几个事件到来的时候所对应的处理器。然后在合适的时机告诉事件选择器：我对这个事件感兴趣。对于写操作，就是写不出去的时候对写事件感兴趣；对于读操作，就是完成连接和系统没有办法承载新读入的数据的时；对于accept，一般是服务器刚启动的时候；而对于connect，一般是connect失败需要重连或者直接异步调用connect的时候。 其次，用一个死循环选择就绪的事件，会执行系统调用（Linux 2.6之前是select、poll，2.6之后是epoll，Windows是IOCP），还会阻塞的等待新事件的到来。新事件到来的时候，会在selector上注册标记位，标示可读、可写或者有连接到来。 注意，select是阻塞的，无论是通过操作系统的通知（epoll）还是不停的轮询(select，poll)，这个函数是阻塞的。所以你可以放心大胆地在一个while(true)里面调用这个函数而不用担心CPU空转。 所以我们的程序大概的模样是： 123456789101112131415161718192021222324252627 interface ChannelHandler&#123; void channelReadable(Channel channel); void channelWritable(Channel channel); &#125; class Channel&#123; Socket socket; Event event;//读，写或者连接 &#125; //IO线程主循环: class IoThread extends Thread&#123; public void run()&#123; Channel channel; while(channel=Selector.select())&#123;//选择就绪的事件和对应的连接 if(channel.event==accept)&#123; registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器 &#125; if(channel.event==write)&#123; getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件 &#125; if(channel.event==read)&#123; getChannelHandler(channel).channelReadable(channel);//如果可以读，则执行读事件 &#125; &#125; &#125; Map&lt;Channel，ChannelHandler&gt; handlerMap;//所有channel的对应事件处理器&#125; 这个程序很简短，也是最简单的Reactor模式：注册所有感兴趣的事件处理器，单线程轮询选择就绪事件，执行事件处理器。 优化线程模型由上面的示例我们大概可以总结出NIO是怎么解决掉线程的瓶颈并处理海量连接的： NIO由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的I/O操作都是纯CPU操作，没有必要开启多线程。 并且由于线程的节约，连接数大的时候因为线程切换带来的问题也随之解决，进而为处理海量连接提供了可能。 单线程处理I/O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I/O，无疑对效率会有更大的提高。 仔细分析一下我们需要的线程，其实主要包括以下几种： 事件分发器，单线程选择就绪的事件。 I/O处理器，包括connect、read、write等，这种纯CPU操作，一般开启CPU核心个线程就可以。 业务线程，在处理完I/O后，业务一般还会有自己的业务逻辑，有的还会有其他的阻塞I/O，如DB操作，RPC等。只要有阻塞，就需要单独的线程。 Java的Selector对于Linux系统来说，有一个致命限制：同一个channel的select不能被并发的调用。因此，如果有多个I/O线程，必须保证：一个socket只能属于一个IoThread，而一个IoThread可以管理多个socket。 另外连接的处理和读写的处理通常可以选择分开，这样对于海量连接的注册和读写就可以分发。虽然read()和write()是比较高效无阻塞的函数，但毕竟会占用CPU，如果面对更高的并发则无能为力。 NIO在客户端的魔力通过上面的分析，可以看出NIO在服务端对于解放线程，优化I/O和处理海量连接方面，确实有自己的用武之地。那么在客户端上，NIO又有什么使用场景呢? 常见的客户端BIO+连接池模型，可以建立n个连接，然后当某一个连接被I/O占用的时候，可以使用其他连接来提高性能。 但多线程的模型面临和服务端相同的问题：如果指望增加连接数来提高性能，则连接数又受制于线程数、线程很贵、无法建立很多线程，则性能遇到瓶颈。 每连接顺序请求的Redis对于Redis来说，由于服务端是全局串行的，能够保证同一连接的所有请求与返回顺序一致。这样可以使用单线程＋队列，把请求数据缓冲。然后pipeline发送，返回future，然后channel可读时，直接在队列中把future取回来，done()就可以了。 伪代码如下： 123456789101112131415161718192021222324252627class RedisClient Implements ChannelHandler&#123; private BlockingQueue CmdQueue; private EventLoop eventLoop; private Channel channel; class Cmd&#123; String cmd; Future result; &#125; public Future get(String key)&#123; Cmd cmd= new Cmd(key); queue.offer(cmd); eventLoop.submit(new Runnable()&#123; List list = new ArrayList(); queue.drainTo(list); if(channel.isWritable())&#123; channel.writeAndFlush(list); &#125; &#125;);&#125; public void ChannelReadFinish(Channel channel，Buffer Buffer)&#123; List result = handleBuffer();//处理数据 //从cmdQueue取出future，并设值，future.done();&#125; public void ChannelWritable(Channel channel)&#123; channel.flush();&#125;&#125; 这样做，能够充分的利用pipeline来提高I/O能力，同时获取异步处理能力。 多连接短连接的HttpClient类似于竞对抓取的项目，往往需要建立无数的HTTP短连接，然后抓取，然后销毁，当需要单机抓取上千网站线程数又受制的时候，怎么保证性能呢? 何不尝试NIO，单线程进行连接、写、读操作？如果连接、读、写操作系统没有能力处理，简单的注册一个事件，等待下次循环就好了。 如何存储不同的请求/响应呢？由于http是无状态没有版本的协议，又没有办法使用队列，好像办法不多。比较笨的办法是对于不同的socket，直接存储socket的引用作为map的key。 常见的RPC框架，如Thrift，Dubbo这种框架内部一般维护了请求的协议和请求号，可以维护一个以请求号为key，结果的result为future的map，结合NIO+长连接，获取非常不错的性能。 NIO高级主题Proactor与Reactor一般情况下，I/O 复用机制需要事件分发器（event dispatcher）。 事件分发器的作用，即将那些读写事件源分发给各读写事件的处理者，就像送快递的在楼下喊: 谁谁谁的快递到了， 快来拿吧！开发人员在开始的时候需要在分发器那里注册感兴趣的事件，并提供相应的处理者（event handler)，或者是回调函数；事件分发器在适当的时候，会将请求的事件分发给这些handler或者回调函数。 涉及到事件分发器的两种模式称为：Reactor和Proactor。 Reactor模式是基于同步I/O的，而Proactor模式是和异步I/O相关的。在Reactor模式中，事件分发器等待某个事件或者可应用或个操作的状态发生（比如文件描述符可读写，或者是socket可读写），事件分发器就把这个事件传给事先注册的事件处理函数或者回调函数，由后者来做实际的读写操作。 而在Proactor模式中，事件处理者（或者代由事件分发器发起）直接发起一个异步读写操作（相当于请求），而实际的工作是由操作系统来完成的。发起时，需要提供的参数包括用于存放读到数据的缓存区、读的数据大小或用于存放外发数据的缓存区，以及这个请求完后的回调函数等信息。事件分发器得知了这个请求，它默默等待这个请求的完成，然后转发完成事件给相应的事件处理者或者回调。举例来说，在Windows上事件处理者投递了一个异步IO操作（称为overlapped技术），事件分发器等IO Complete事件完成。这种异步模式的典型实现是基于操作系统底层异步API的，所以我们可称之为“系统级别”的或者“真正意义上”的异步，因为具体的读写是由操作系统代劳的。 举个例子，将有助于理解Reactor与Proactor二者的差异，以读操作为例（写操作类似）。 在Reactor中实现读 注册读就绪事件和相应的事件处理器。 事件分发器等待事件。 事件到来，激活分发器，分发器调用事件对应的处理器。 事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。 在Proactor中实现读： 处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。 事件分发器等待操作完成事件。 在分发器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分发器读操作完成。 事件分发器呼唤处理器。 事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分发器。 可以看出，两个模式的相同点，都是对某个I/O事件的事件通知（即告诉某个模块，这个I/O操作可以进行或已经完成)。在结构上，两者也有相同点：事件分发器负责提交IO操作（异步)、查询设备是否可操作（同步)，然后当条件满足时，就回调handler；不同点在于，异步情况下（Proactor)，当回调handler时，表示I/O操作已经完成；同步情况下（Reactor)，回调handler时，表示I/O设备可以进行某个操作（can read 或 can write)。 下面，我们将尝试应对为Proactor和Reactor模式建立可移植框架的挑战。在改进方案中，我们将Reactor原来位于事件处理器内的Read/Write操作移至分发器（不妨将这个思路称为“模拟异步”），以此寻求将Reactor多路同步I/O转化为模拟异步I/O。以读操作为例子，改进过程如下： 注册读就绪事件和相应的事件处理器。并为分发器提供数据缓冲区地址，需要读取数据量等信息。 分发器等待事件（如在select()上等待）。 事件到来，激活分发器。分发器执行一个非阻塞读操作（它有完成这个操作所需的全部信息），最后调用对应处理器。 事件处理器处理用户自定义缓冲区的数据，注册新的事件（当然同样要给出数据缓冲区地址，需要读取的数据量等信息），最后将控制权返还分发器。如我们所见，通过对多路I/O模式功能结构的改造，可将Reactor转化为Proactor模式。改造前后，模型实际完成的工作量没有增加，只不过参与者间对工作职责稍加调换。没有工作量的改变，自然不会造成性能的削弱。对如下各步骤的比较，可以证明工作量的恒定： 标准/典型的Reactor： 步骤1：等待事件到来（Reactor负责）。 步骤2：将读就绪事件分发给用户定义的处理器（Reactor负责）。 步骤3：读数据（用户处理器负责）。 步骤4：处理数据（用户处理器负责）。 改进实现的模拟Proactor： 步骤1：等待事件到来（Proactor负责）。 步骤2：得到读就绪事件，执行读数据（现在由Proactor负责）。 步骤3：将读完成事件分发给用户处理器（Proactor负责）。 步骤4：处理数据（用户处理器负责）。 对于不提供异步I/O API的操作系统来说，这种办法可以隐藏Socket API的交互细节，从而对外暴露一个完整的异步接口。借此，我们就可以进一步构建完全可移植的，平台无关的，有通用对外接口的解决方案。 代码示例如下： 123456789101112131415161718192021222324252627282930313233343536interface ChannelHandler&#123; void channelReadComplate(Channel channel，byte[] data); void channelWritable(Channel channel); &#125; class Channel&#123; Socket socket; Event event;//读，写或者连接 &#125; //IO线程主循环： class IoThread extends Thread&#123; public void run()&#123; Channel channel; while(channel=Selector.select())&#123;//选择就绪的事件和对应的连接 if(channel.event==accept)&#123; registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器 Selector.interested(read); &#125; if(channel.event==write)&#123; getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件 &#125; if(channel.event==read)&#123; byte[] data = channel.read(); if(channel.read()==0)//没有读到数据，表示本次数据读完了 &#123; getChannelHandler(channel).channelReadComplate(channel，data;//处理读完成事件 &#125; if(过载保护)&#123; Selector.interested(read); &#125; &#125; &#125; &#125; Map&lt;Channel，ChannelHandler&gt; handlerMap;//所有channel的对应事件处理器 &#125; Selector.wakeup()主要作用解除阻塞在Selector.select()/select(long)上的线程，立即返回。 两次成功的select之间多次调用wakeup等价于一次调用。 如果当前没有阻塞在select上，则本次wakeup调用将作用于下一次select——“记忆”作用。 为什么要唤醒？ 注册了新的channel或者事件。 channel关闭，取消注册。 优先级更高的事件触发（如定时器事件），希望及时处理。 原理Linux上利用pipe调用创建一个管道，Windows上则是一个loopback的tcp连接。这是因为win32的管道无法加入select的fd set，将管道或者TCP连接加入select fd set。 wakeup往管道或者连接写入一个字节，阻塞的select因为有I/O事件就绪，立即返回。可见，wakeup的调用开销不可忽视。 Buffer的选择通常情况下，操作系统的一次写操作分为两步： 将数据从用户空间拷贝到系统空间。 从系统空间往网卡写。同理，读操作也分为两步：① 将数据从网卡拷贝到系统空间；② 将数据从系统空间拷贝到用户空间。 对于NIO来说，缓存的使用可以使用DirectByteBuffer和HeapByteBuffer。如果使用了DirectByteBuffer，一般来说可以减少一次系统空间到用户空间的拷贝。但Buffer创建和销毁的成本更高，更不宜维护，通常会用内存池来提高性能。 如果数据量比较小的中小应用情况下，可以考虑使用heapBuffer；反之可以用directBuffer。 NIO存在的问题使用NIO != 高性能，当连接数&lt;1000，并发程度不高或者局域网环境下NIO并没有显著的性能优势。 NIO并没有完全屏蔽平台差异，它仍然是基于各个操作系统的I/O系统实现的，差异仍然存在。使用NIO做网络编程构建事件驱动模型并不容易，陷阱重重。 推荐大家使用成熟的NIO框架，如Netty，MINA等。解决了很多NIO的陷阱，并屏蔽了操作系统的差异，有较好的性能和编程模型。 总结最后总结一下到底NIO给我们带来了些什么： 事件驱动模型 避免多线程 单线程处理多任务 非阻塞I/O，I/O读写不再阻塞，而是返回0 基于block的传输，通常比基于流的传输更高效 更高级的IO函数，zero-copy IO多路复用大大提高了Java网络应用的可伸缩性和实用性 本文抛砖引玉，诠释了一些NIO的思想和设计理念以及应用场景，这只是从冰山一角。关于NIO可以谈的技术点其实还有很多，期待未来有机会和大家继续探讨。 参考https://tech.meituan.com/nio.html]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL事务隔离级别]]></title>
    <url>%2Fmysql%2FMySQL%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[事务隔离级别介绍 隔离级别 脏读 不可重复读 幻读 未提交读（Read uncommitted） 可能 可能 可能 已提交读（Read committed） 不可能 可能 可能 可重复读（Repeatable read） 不可能 不可能 可能 可串行化（Serializable ） 不可能 不可能 不可能 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读) 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读，但是innoDB解决了幻读 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞 接下来一次来验证每个隔离级别的特性,首先我们先建一张表,我们建立账户表account用来测试我们的事务隔离级别： 1234567CREATE TABLE account ( `id` int(11) NOT NULL AUTO_INCREMENT, `customer_name` varchar(255) NOT NULL, `money` int(11) NOT NULL, PRIMARY KEY (`id`), UNIQUE `uniq_name` USING BTREE (customer_name)) ENGINE=`InnoDB` AUTO_INCREMENT=10 DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci ROW_FORMAT=COMPACT RU （read uncommitted）读未提交隔离级别首先我们开启Console A,然后设置session事务隔离级别为read uncommitted; 然后同样开启Console B，设置成read uncommitted; 12345678910mysql&gt; set session transaction isolation level read uncommitted;Query OK, 0 rows affected (0.03 sec) mysql&gt; select @@session.tx_isolation;+------------------------+| @@session.tx_isolation |+------------------------+| READ-UNCOMMITTED |+------------------------+1 rows in set (0.03 sec) 我们两个console的事务隔离级别都是read uncommitted，下面测试RU级别会发生的情况 小结： 可以发现RU模式下，一个事务可以读取到另一个未提交(commit)的数据，导致了脏读。如果B事务回滚了，就会造成数据的不一致。RU是事务隔离级别最低的。 RC （read committed）读提交隔离级别现在我们将事务隔离级别设置成RC (read committed) 1set session transaction isolation level read uncommitted; 小结 我们在RC模式下，可以发现。在console B没有提交数据修改的commit的时候，console A是读不到修改后的数据的，这就避免了在RU模式中的脏读，但是有一个问题我们会发现，在console A同一个事务中。两次select的数据不一样，这就存在了不可重复读的问题.PS：RC事务隔离级别是Oracle数据库的默认隔离级别. RR （Repeatable read）可重复读隔离级别 小结 在RR级别中，我们解决了不可重复读的问题，即在这种隔离级别下，在一个事务中我们能够保证能够获取到一样的数据（即使已经有其他事务修改了我们的数据）。但是无法避免幻读，幻读简单的解释就是在数据有新增的时候，也无法保证两次得到的数据不一致，但是不同数据库对不同的RR级别有不同的实现，有时候或加上间隙锁来避免幻读。 innoDB 解决了幻读前面的定义中RR级别是可能产生幻读，这是在传统的RR级别定义中会出现的。但是在innoDB引擎中利用MVCC多版本并发控制解决了这个问题 这算是幻读吗？在标准的RR隔离级别定义中是无法解决幻读问题的，比如我要保证可重复读，那么我们可以在我们的结果集的范围加一个锁（between 1 and 11），防止数据更改.但是我们毕竟不是锁住真个表，所以insert数据我们并不能保证他不插入。所以是有幻读的问题存在的。但是innodb引擎解决了幻读的问题，基于MVCC（多版本并发控制）:在InnoDB中，会在每行数据后添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。 在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。所以当我们执行update的时候，当前事务的版本号已经更新了？所以也算是幻读？？(存疑)主要是gap间隙锁+MVCC解决幻读问题？ Serializable 串行化隔离级别所有事物串行,最高隔离级别，性能最差 存在的问题？在RR模型,我们虽然避免了幻读，但是存在一个问题，我们得到的数据不是数据中实时的数据，如果是对实时数据比较敏感的业务，这是不现实的。对于这种读取历史数据的方式，我们叫它快照读 (snapshot read)，而读取数据库当前版本数据的方式，叫当前读 (current read)。很显然，在MVCC中： 快照读：就是select select * from table ….; 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。 select * from table where ? lock in share mode; select * from table where ? for update; insert; update ; delete; 事务的隔离级别实际上都是定义了当前读的级别，MySQL为了减少锁处理（包括等待其它锁）的时间，提升并发能力，引入了快照读的概念，使得select不用加锁。而update、insert这些“当前读”，就需要另外的模块来解决了。 比如，我们有以下的订单业务场景，我们队一个商品下单的操作，我们得首先检查这个订单的数量还剩多少，然后下单。 事务1: 12select num from t_goods where id=1;update t_goods set num=num-$mynum where id=1; 事务2： 12select num from t_goods where id=1;update t_goods set num=num-$mynum where id=1; 假设这个时候数量只有1，我们下单也是只有1.如果在并发的情况下，事务1查询到还有一单准备下单，但是这个时候事务2已经提交了。订单变成0.这个事务1在执行update，就会造成事故。 解决问题方法1(悲观锁)：就是利用for update对着个商品加锁，事务完成之后释放锁。切记where条件的有索引，否则会锁全表。 解决方法2(乐观锁)：给数据库表加上个version字段。然后SQL改写: 12select num,version from t_goods where id=1;update t_goods set num=num-1,version=verison+1 where id=1 and version=$&#123;version&#125; 参考MySQL事务隔离级别和Spring事务关系介绍 Innodb 中 RR 隔离级别能否防止幻读？ MySQL 加锁处理分析]]></content>
      <categories>
        <category>mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[eventloop]]></title>
    <url>%2Feventloop%2F</url>
    <content type="text"><![CDATA[Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop@(Netty)[Netty, 源码分析] [TOC] 简述这一章是 Netty 源码分析 的第三章, 我将在这一章中大家一起探究一下 Netty 的 EventLoop 的底层原理, 让大家对 Netty 的线程模型有更加深入的了解. NioEventLoopGroup在 Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (客户端) 章节中我们已经知道了, 一个 Netty 程序启动时, 至少要指定一个 EventLoopGroup(如果使用到的是 NIO, 那么通常是 NioEventLoopGroup), 那么这个 NioEventLoopGroup 在 Netty 中到底扮演着什么角色呢? 我们知道, Netty 是 Reactor 模型的一个实现, 那么首先从 Reactor 的线程模型开始吧. 关于 Reactor 的线程模型首先我们来看一下 Reactor 的线程模型.Reactor 的线程模型有三种: 单线程模型 多线程模型 主从多线程模型 首先来看一下 单线程模型: 所谓单线程, 即 acceptor 处理和 handler 处理都在一个线程中处理. 这个模型的坏处显而易见: 当其中某个 handler 阻塞时, 会导致其他所有的 client 的 handler 都得不到执行, 并且更严重的是, handler 的阻塞也会导致整个服务不能接收新的 client 请求(因为 acceptor 也被阻塞了). 因为有这么多的缺陷, 因此单线程Reactor 模型用的比较少. 那么什么是 多线程模型 呢? Reactor 的多线程模型与单线程模型的区别就是 acceptor 是一个单独的线程处理, 并且有一组特定的 NIO 线程来负责各个客户端连接的 IO 操作. Reactor 多线程模型如下: Reactor 多线程模型 有如下特点: 有专门一个线程, 即 Acceptor 线程用于监听客户端的TCP连接请求. 客户端连接的 IO 操作都是由一个特定的 NIO 线程池负责. 每个客户端连接都与一个特定的 NIO 线程绑定, 因此在这个客户端连接中的所有 IO 操作都是在同一个线程中完成的. 客户端连接有很多, 但是 NIO 线程数是比较少的, 因此一个 NIO 线程可以同时绑定到多个客户端连接中. 接下来我们再来看一下 Reactor 的主从多线程模型.一般情况下, Reactor 的多线程模式已经可以很好的工作了, 但是我们考虑一下如下情况: 如果我们的服务器需要同时处理大量的客户端连接请求或我们需要在客户端连接时, 进行一些权限的检查, 那么单线程的 Acceptor 很有可能就处理不过来, 造成了大量的客户端不能连接到服务器.Reactor 的主从多线程模型就是在这样的情况下提出来的, 它的特点是: 服务器端接收客户端的连接请求不再是一个线程, 而是由一个独立的线程池组成. 它的线程模型如下: 可以看到, Reactor 的主从多线程模型和 Reactor 多线程模型很类似, 只不过 Reactor 的主从多线程模型的 acceptor 使用了线程池来处理大量的客户端请求. NioEventLoopGroup 与 Reactor 线程模型的对应我们介绍了三种 Reactor 的线程模型, 那么它们和 NioEventLoopGroup 又有什么关系呢? 其实, 不同的设置 NioEventLoopGroup 的方式就对应了不同的 Reactor 的线程模型. 单线程模型来看一下下面的例子:12345EventLoopGroup bossGroup = new NioEventLoopGroup(1);ServerBootstrap b = new ServerBootstrap();b.group(bossGroup) .channel(NioServerSocketChannel.class) ... 注意, 我们实例化了一个 NioEventLoopGroup, 构造器参数是1, 表示 NioEventLoopGroup 的线程池大小是1. 然后接着我们调用 b.group(bossGroup) 设置了服务器端的 EventLoopGroup. 有些朋友可能会有疑惑: 我记得在启动服务器端的 Netty 程序时, 是需要设置 bossGroup 和 workerGroup 的, 为什么这里就只有一个 bossGroup?其实很简单, ServerBootstrap 重写了 group 方法:1234@Overridepublic ServerBootstrap group(EventLoopGroup group) &#123; return group(group, group);&#125; 因此当传入一个 group 时, 那么 bossGroup 和 workerGroup 就是同一个 NioEventLoopGroup 了.这时候呢, 因为 bossGroup 和 workerGroup 就是同一个 NioEventLoopGroup, 并且这个 NioEventLoopGroup 只有一个线程, 这样就会导致 Netty 中的 acceptor 和后续的所有客户端连接的 IO 操作都是在一个线程中处理的. 那么对应到 Reactor 的线程模型中, 我们这样设置 NioEventLoopGroup 时, 就相当于 Reactor 单线程模型. 多线程模型同理, 再来看一下下面的例子:123456EventLoopGroup bossGroup = new NioEventLoopGroup(1);EventLoopGroup workerGroup = new NioEventLoopGroup();ServerBootstrap b = new ServerBootstrap();b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) ... bossGroup 中只有一个线程, 而 workerGroup 中的线程是 CPU 核心数乘以2, 因此对应的到 Reactor 线程模型中, 我们知道, 这样设置的 NioEventLoopGroup 其实就是 Reactor 多线程模型. 主从多线程模型相信读者朋友都想到了, 实现主从线程模型的例子如下:123456EventLoopGroup bossGroup = new NioEventLoopGroup(4);EventLoopGroup workerGroup = new NioEventLoopGroup();ServerBootstrap b = new ServerBootstrap();b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) ... bossGroup 线程池中的线程数我们设置为4, 而 workerGroup 中的线程是 CPU 核心数乘以2, 因此对应的到 Reactor 线程模型中, 我们知道, 这样设置的 NioEventLoopGroup 其实就是 Reactor 主从多线程模型. 根据 @labmem 的提示, Netty 的服务器端的 acceptor 阶段, 没有使用到多线程, 因此上面的 主从多线程模型 在 Netty 的服务器端是不存在的. 服务器端的 ServerSocketChannel 只绑定到了 bossGroup 中的一个线程, 因此在调用 Java NIO 的 Selector.select 处理客户端的连接请求时, 实际上是在一个线程中的, 所以对只有一个服务的应用来说, bossGroup 设置多个线程是没有什么作用的, 反而还会造成资源浪费. 经 Google, Netty 中的 bossGroup 为什么使用线程池的原因大家众所纷纭, 不过我在 stackoverflow 上找到一个比较靠谱的答案: the creator of Netty says multiple boss threads are useful if we share NioEventLoopGroup between different server bootstraps, but I don’t see the reason for it.因此上面的 主从多线程模型 分析是有问题, 抱歉. NioEventLoopGroup 类层次结构 NioEventLoopGroup 实例化过程在前面 Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (客户端) 章节中, 我们已经简单地介绍了一下 NioEventLoopGroup 的初始化过程, 这里再回顾一下:点此下载原图 即: EventLoopGroup(其实是MultithreadEventExecutorGroup) 内部维护一个类型为 EventExecutor children 数组, 其大小是 nThreads, 这样就构成了一个线程池 如果我们在实例化 NioEventLoopGroup 时, 如果指定线程池大小, 则 nThreads 就是指定的值, 反之是处理器核心数 * 2 MultithreadEventExecutorGroup 中会调用 newChild 抽象方法来初始化 children 数组 抽象方法 newChild 是在 NioEventLoopGroup 中实现的, 它返回一个 NioEventLoop 实例. NioEventLoop 属性: SelectorProvider provider 属性: NioEventLoopGroup 构造器中通过 SelectorProvider.provider() 获取一个 SelectorProvider Selector selector 属性: NioEventLoop 构造器中通过调用通过 selector = provider.openSelector() 获取一个 selector 对象. NioEventLoopNioEventLoop 继承于 SingleThreadEventLoop, 而 SingleThreadEventLoop 又继承于 SingleThreadEventExecutor. SingleThreadEventExecutor 是 Netty 中对本地线程的抽象, 它内部有一个 Thread thread 属性, 存储了一个本地 Java 线程. 因此我们可以认为, 一个 NioEventLoop 其实和一个特定的线程绑定, 并且在其生命周期内, 绑定的线程都不会再改变. NioEventLoop 类层次结构NioEventLoop 的类层次结构图还是比较复杂的, 不过我们只需要关注几个重要的点即可. 首先 NioEventLoop 的继承链如下:1NioEventLoop -&gt; SingleThreadEventLoop -&gt; SingleThreadEventExecutor -&gt; AbstractScheduledEventExecutor 在 AbstractScheduledEventExecutor 中, Netty 实现了 NioEventLoop 的 schedule 功能, 即我们可以通过调用一个 NioEventLoop 实例的 schedule 方法来运行一些定时任务. 而在 SingleThreadEventLoop 中, 又实现了任务队列的功能, 通过它, 我们可以调用一个 NioEventLoop 实例的 execute 方法来向任务队列中添加一个 task, 并由 NioEventLoop 进行调度执行. 通常来说, NioEventLoop 肩负着两种任务, 第一个是作为 IO 线程, 执行与 Channel 相关的 IO 操作, 包括 调用 select 等待就绪的 IO 事件、读写数据与数据的处理等; 而第二个任务是作为任务队列, 执行 taskQueue 中的任务, 例如用户调用 eventLoop.schedule 提交的定时任务也是这个线程执行的. NioEventLoop 的实例化过程点此下载原图 从上图可以看到, SingleThreadEventExecutor 有一个名为 thread 的 Thread 类型字段, 这个字段就代表了与 SingleThreadEventExecutor 关联的本地线程.下面是这个构造器的代码:123456789101112131415161718192021222324protected SingleThreadEventExecutor( EventExecutorGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp) &#123; this.parent = parent; this.addTaskWakesUp = addTaskWakesUp; thread = threadFactory.newThread(new Runnable() &#123; @Override public void run() &#123; boolean success = false; updateLastExecutionTime(); try &#123; SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; logger.warn(&quot;Unexpected exception from an event executor: &quot;, t); &#125; finally &#123; // 省略清理代码 ... &#125; &#125; &#125;); threadProperties = new DefaultThreadProperties(thread); taskQueue = newTaskQueue();&#125; 在 SingleThreadEventExecutor 构造器中, 通过 threadFactory.newThread 创建了一个新的 Java 线程. 在这个线程中所做的事情主要就是调用 SingleThreadEventExecutor.this.run() 方法, 而因为 NioEventLoop 实现了这个方法, 因此根据多态性, 其实调用的是 NioEventLoop.run() 方法. EventLoop 与 Channel 的关联Netty 中, 每个 Channel 都有且仅有一个 EventLoop 与之关联, 它们的关联过程如下:点此下载原图 从上图中我们可以看到, 当调用了 AbstractChannel#AbstractUnsafe.register 后, 就完成了 Channel 和 EventLoop 的关联. register 实现如下:123456789101112131415161718192021@Overridepublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; // 删除条件检查. ... AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new OneTimeTask() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; ... &#125; &#125;&#125; 在 AbstractChannel#AbstractUnsafe.register 中, 会将一个 EventLoop 赋值给 AbstractChannel 内部的 eventLoop 字段, 到这里就完成了 EventLoop 与 Channel 的关联过程. EventLoop 的启动在前面我们已经知道了, NioEventLoop 本身就是一个 SingleThreadEventExecutor, 因此 NioEventLoop 的启动, 其实就是 NioEventLoop 所绑定的本地 Java 线程的启动.依照这个思想, 我们只要找到在哪里调用了 SingleThreadEventExecutor 的 thread 字段的 start() 方法就可以知道是在哪里启动的这个线程了.从代码中搜索, thread.start() 被封装到 SingleThreadEventExecutor.startThread() 方法中了:1234567private void startThread() &#123; if (STATE_UPDATER.get(this) == ST_NOT_STARTED) &#123; if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &#123; thread.start(); &#125; &#125;&#125; STATE_UPDATER 是 SingleThreadEventExecutor 内部维护的一个属性, 它的作用是标识当前的 thread 的状态. 在初始的时候, STATE_UPDATER == ST_NOT_STARTED, 因此第一次调用 startThread() 方法时, 就会进入到 if 语句内, 进而调用到 thread.start().而这个关键的 startThread() 方法又是在哪里调用的呢? 经过方法调用关系搜索, 我们发现, startThread 是在 SingleThreadEventExecutor.execute 方法中调用的:123456789101112131415161718192021@Overridepublic void execute(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(&quot;task&quot;); &#125; boolean inEventLoop = inEventLoop(); if (inEventLoop) &#123; addTask(task); &#125; else &#123; startThread(); // 调用 startThread 方法, 启动EventLoop 线程. addTask(task); if (isShutdown() &amp;&amp; removeTask(task)) &#123; reject(); &#125; &#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123; wakeup(inEventLoop); &#125;&#125; 既然如此, 那现在我们的工作就变为了寻找 在哪里第一次调用了 SingleThreadEventExecutor.execute() 方法.如果留心的读者可能已经注意到了, 我们在 EventLoop 与 Channel 的关联 这一小节时, 有提到到在注册 channel 的过程中, 会在 AbstractChannel#AbstractUnsafe.register 中调用 eventLoop.execute 方法, 在 EventLoop 中进行 Channel 注册代码的执行, AbstractChannel#AbstractUnsafe.register 部分代码如下:1234567891011121314if (eventLoop.inEventLoop()) &#123; register0(promise);&#125; else &#123; try &#123; eventLoop.execute(new OneTimeTask() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; ... &#125;&#125; 很显然, 一路从 Bootstrap.bind 方法跟踪到 AbstractChannel#AbstractUnsafe.register 方法, 整个代码都是在主线程中运行的, 因此上面的 eventLoop.inEventLoop() 就为 false, 于是进入到 else 分支, 在这个分支中调用了 eventLoop.execute. eventLoop 是一个 NioEventLoop 的实例, 而 NioEventLoop 没有实现 execute 方法, 因此调用的是 SingleThreadEventExecutor.execute:123456789101112131415161718@Overridepublic void execute(Runnable task) &#123; ... boolean inEventLoop = inEventLoop(); if (inEventLoop) &#123; addTask(task); &#125; else &#123; startThread(); addTask(task); if (isShutdown() &amp;&amp; removeTask(task)) &#123; reject(); &#125; &#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123; wakeup(inEventLoop); &#125;&#125; 我们已经分析过了, inEventLoop == false, 因此执行到 else 分支, 在这里就调用了 startThread() 方法来启动 SingleThreadEventExecutor 内部关联的 Java 本地线程了.总结一句话, 当 EventLoop.execute 第一次被调用时, 就会触发 startThread() 的调用, 进而导致了 EventLoop 所对应的 Java 线程的启动.我们将 EventLoop 与 Channel 的关联 小节中的时序图补全后, 就得到了 EventLoop 启动过程的时序图: 点此下载原图 Netty 的 IO 处理循环在 Netty 中, 一个 EventLoop 需要负责两个工作, 第一个是作为 IO 线程, 负责相应的 IO 操作; 第二个是作为任务线程, 执行 taskQueue 中的任务. 接下来我们先从 IO 操纵方面入手, 看一下 TCP 数据是如何从 Java NIO Socket 传递到我们的 handler 中的. Netty 是 Reactor 模型的一个实现, 并且是基于 Java NIO 的, 那么从 Java NIO 的前生今世 之四 NIO Selector 详解 中我们知道, Netty 中必然有一个 Selector 线程, 用于不断调用 Java NIO 的 Selector.select 方法, 查询当前是否有就绪的 IO 事件. 回顾一下在 Java NIO 中所讲述的 Selector 的使用流程: 通过 Selector.open() 打开一个 Selector. 将 Channel 注册到 Selector 中, 并设置需要监听的事件(interest set) 不断重复: 调用 select() 方法 调用 selector.selectedKeys() 获取 selected keys 迭代每个 selected key: 1) 从 selected key 中获取 对应的 Channel 和附加信息(如果有的话) 2) 判断是哪些 IO 事件已经就绪了, 然后处理它们. 如果是 OP_ACCEPT 事件, 则调用 “SocketChannel clientChannel = ((ServerSocketChannel) key.channel()).accept()” 获取 SocketChannel, 并将它设置为 非阻塞的, 然后将这个 Channel 注册到 Selector 中. 3) 根据需要更改 selected key 的监听事件. 4) 将已经处理过的 key 从 selected keys 集合中删除. 上面的使用流程用代码来体现就是:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * @author xiongyongshun * @Email yongshun1228@gmail.com * @version 1.0 * @created 16/8/1 13:13 */public class NioEchoServer &#123; private static final int BUF_SIZE = 256; private static final int TIMEOUT = 3000; public static void main(String args[]) throws Exception &#123; // 打开服务端 Socket ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 打开 Selector Selector selector = Selector.open(); // 服务端 Socket 监听8080端口, 并配置为非阻塞模式 serverSocketChannel.socket().bind(new InetSocketAddress(8080)); serverSocketChannel.configureBlocking(false); // 将 channel 注册到 selector 中. // 通常我们都是先注册一个 OP_ACCEPT 事件, 然后在 OP_ACCEPT 到来时, 再将这个 Channel 的 OP_READ // 注册到 Selector 中. serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) &#123; // 通过调用 select 方法, 阻塞地等待 channel I/O 可操作 if (selector.select(TIMEOUT) == 0) &#123; System.out.print(&quot;.&quot;); continue; &#125; // 获取 I/O 操作就绪的 SelectionKey, 通过 SelectionKey 可以知道哪些 Channel 的哪类 I/O 操作已经就绪. Iterator&lt;SelectionKey&gt; keyIterator = selector.selectedKeys().iterator(); while (keyIterator.hasNext()) &#123; // 当获取一个 SelectionKey 后, 就要将它删除, 表示我们已经对这个 IO 事件进行了处理. keyIterator.remove(); SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; // 当 OP_ACCEPT 事件到来时, 我们就有从 ServerSocketChannel 中获取一个 SocketChannel, // 代表客户端的连接 // 注意, 在 OP_ACCEPT 事件中, 从 key.channel() 返回的 Channel 是 ServerSocketChannel. // 而在 OP_WRITE 和 OP_READ 中, 从 key.channel() 返回的是 SocketChannel. SocketChannel clientChannel = ((ServerSocketChannel) key.channel()).accept(); clientChannel.configureBlocking(false); //在 OP_ACCEPT 到来时, 再将这个 Channel 的 OP_READ 注册到 Selector 中. // 注意, 这里我们如果没有设置 OP_READ 的话, 即 interest set 仍然是 OP_CONNECT 的话, 那么 select 方法会一直直接返回. clientChannel.register(key.selector(), OP_READ, ByteBuffer.allocate(BUF_SIZE)); &#125; if (key.isReadable()) &#123; SocketChannel clientChannel = (SocketChannel) key.channel(); ByteBuffer buf = (ByteBuffer) key.attachment(); long bytesRead = clientChannel.read(buf); if (bytesRead == -1) &#123; clientChannel.close(); &#125; else if (bytesRead &gt; 0) &#123; key.interestOps(OP_READ | SelectionKey.OP_WRITE); System.out.println(&quot;Get data length: &quot; + bytesRead); &#125; &#125; if (key.isValid() &amp;&amp; key.isWritable()) &#123; ByteBuffer buf = (ByteBuffer) key.attachment(); buf.flip(); SocketChannel clientChannel = (SocketChannel) key.channel(); clientChannel.write(buf); if (!buf.hasRemaining()) &#123; key.interestOps(OP_READ); &#125; buf.compact(); &#125; &#125; &#125; &#125;&#125; 还记得不, 上面操作的第一步 通过 Selector.open() 打开一个 Selector 我们已经在第一章的 Channel 实例化 这一小节中已经提到了, Netty 中是通过调用 SelectorProvider.openSocketChannel() 来打开一个新的 Java NIO SocketChannel:1234private static SocketChannel newSocket(SelectorProvider provider) &#123; ... return provider.openSocketChannel();&#125; 第二步 将 Channel 注册到 Selector 中, 并设置需要监听的事件(interest set) 的操作我们在第一章 channel 的注册过程 中也分析过了, 我们在来回顾一下, 在客户端的 Channel 注册过程中, 会有如下调用链:1234567Bootstrap.initAndRegister -&gt; AbstractBootstrap.initAndRegister -&gt; MultithreadEventLoopGroup.register -&gt; SingleThreadEventLoop.register -&gt; AbstractUnsafe.register -&gt; AbstractUnsafe.register0 -&gt; AbstractNioChannel.doRegister 在 AbstractUnsafe.register 方法中调用了 register0 方法:123456@Overridepublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; // 省略条件判断和错误处理 AbstractChannel.this.eventLoop = eventLoop; register0(promise);&#125; register0 方法代码如下:12345678910111213private void register0(ChannelPromise promise) &#123; boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; safeSetSuccess(promise); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (firstRegistration &amp;&amp; isActive()) &#123; pipeline.fireChannelActive(); &#125;&#125; register0 又调用了 AbstractNioChannel.doRegister:12345@Overrideprotected void doRegister() throws Exception &#123; // 省略错误处理 selectionKey = javaChannel().register(eventLoop().selector, 0, this);&#125; 在这里 javaChannel() 返回的是一个 Java NIO SocketChannel 对象, 我们将此 SocketChannel 注册到前面第一步获取的 Selector 中. 那么接下来的第三步的循环是在哪里实现的呢? 第三步的操作就是我们今天分析的关键, 下面我会一步一步向读者展示出来. thread 的 run 循环在 EventLoop 的启动 一小节中, 我们已经了解到了, 当 EventLoop.execute 第一次被调用时, 就会触发 startThread() 的调用, 进而导致了 EventLoop 所对应的 Java 线程的启动. 接着我们来更深入一些, 来看一下此线程启动后都会做什么东东吧.下面是此线程的 run() 方法, 我已经把一些异常处理和收尾工作的代码都去掉了. 这个 run 方法可以说是十分简单, 主要就是调用了 SingleThreadEventExecutor.this.run() 方法. 而 SingleThreadEventExecutor.run() 是一个抽象方法, 它的实现在 NioEventLoop 中.123456789101112131415thread = threadFactory.newThread(new Runnable() &#123; @Override public void run() &#123; boolean success = false; updateLastExecutionTime(); try &#123; SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; logger.warn(&quot;Unexpected exception from an event executor: &quot;, t); &#125; finally &#123; ... &#125; &#125; &#125;); 继续跟踪到 NioEventLoop.run() 方法, 其源码如下:12345678910111213141516171819202122232425262728293031323334353637383940@Overrideprotected void run() &#123; for (;;) &#123; boolean oldWakenUp = wakenUp.getAndSet(false); try &#123; if (hasTasks()) &#123; selectNow(); &#125; else &#123; select(oldWakenUp); if (wakenUp.get()) &#123; selector.wakeup(); &#125; &#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; processSelectedKeys(); runAllTasks(); &#125; else &#123; final long ioStartTime = System.nanoTime(); processSelectedKeys(); final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; if (isShuttingDown()) &#123; closeAll(); if (confirmShutdown()) &#123; break; &#125; &#125; &#125; catch (Throwable t) &#123; ... &#125; &#125;&#125; 啊哈, 看到了上面代码的 for(;;) 所构成的死循环了没? 原来 NioEventLoop 事件循环的核心就是这里!现在我们把上面所提到的 Selector 使用步骤的第三步的部分也找到了.这个 run 方法可以说是 Netty NIO 的核心, 属于重中之重, 把它分析明白了, 那么对 Netty 的事件循环机制也就了解了大部分了. 让我们一鼓作气, 继续分析下去吧! IO 事件的轮询首先, 在 run 方法中, 第一步是调用 hasTasks() 方法来判断当前任务队列中是否有任务:1234protected boolean hasTasks() &#123; assert inEventLoop(); return !taskQueue.isEmpty();&#125; 这个方法很简单, 仅仅是检查了一下 taskQueue 是否为空. 至于 taskQueue 是什么呢, 其实它就是存放一系列的需要由此 EventLoop 所执行的任务列表. 关于 taskQueue, 我们这里暂时不表, 等到后面再来详细分析它.当 taskQueue 不为空时, 就执行到了 if 分支中的 selectNow() 方法. 然而当 taskQueue 为空时, 执行的是 select(oldWakenUp) 方法. 那么 selectNow() 和 select(oldWakenUp) 之间有什么区别呢? 来看一下, selectNow() 的源码如下:12345678910void selectNow() throws IOException &#123; try &#123; selector.selectNow(); &#125; finally &#123; // restore wakup state if needed if (wakenUp.get()) &#123; selector.wakeup(); &#125; &#125;&#125; 首先调用了 selector.selectNow() 方法, 这里 selector 是什么大家还有印象不? 我们在第一章 Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (客户端) 时对它有过介绍, 这个 selector 字段正是 Java NIO 中的多路复用器 Selector. 那么这里 selector.selectNow() 就很好理解了, selectNow() 方法会检查当前是否有就绪的 IO 事件, 如果有, 则返回就绪 IO 事件的个数; 如果没有, 则返回0. 注意, selectNow() 是立即返回的, 不会阻塞当前线程. 当 selectNow() 调用后, finally 语句块中会检查 wakenUp 变量是否为 true, 当为 true 时, 调用 selector.wakeup() 唤醒 select() 的阻塞调用. 看了 if 分支的 selectNow 方法后, 我们再来看一下 else 分支的 select(oldWakenUp) 方法.其实 else 分支的 select(oldWakenUp) 方法的处理逻辑比较复杂, 而我们这里的目的暂时不是分析这个方法调用的具体工作, 因此我这里长话短说, 只列出我们我们关注的内如:12345678910private void select(boolean oldWakenUp) throws IOException &#123; Selector selector = this.selector; try &#123; ... int selectedKeys = selector.select(timeoutMillis); ... &#125; catch (CancelledKeyException e) &#123; ... &#125;&#125; 在这个 select 方法中, 调用了 selector.select(timeoutMillis), 而这个调用是会阻塞住当前线程的, timeoutMillis 是阻塞的超时时间.到来这里, 我们可以看到, 当 hasTasks() 为真时, 调用的的 selectNow() 方法是不会阻塞当前线程的, 而当 hasTasks() 为假时, 调用的 select(oldWakenUp) 是会阻塞当前线程的.这其实也很好理解: 当 taskQueue 中没有任务时, 那么 Netty 可以阻塞地等待 IO 就绪事件; 而当 taskQueue 中有任务时, 我们自然地希望所提交的任务可以尽快地执行, 因此 Netty 会调用非阻塞的 selectNow() 方法, 以保证 taskQueue 中的任务尽快可以执行. IO 事件的处理在 NioEventLoop.run() 方法中, 第一步是通过 select/selectNow 调用查询当前是否有就绪的 IO 事件. 那么当有 IO 事件就绪时, 第二步自然就是处理这些 IO 事件啦.首先让我们来看一下 NioEventLoop.run 中循环的剩余部分:123456789101112final int ioRatio = this.ioRatio;if (ioRatio == 100) &#123; processSelectedKeys(); runAllTasks();&#125; else &#123; final long ioStartTime = System.nanoTime(); processSelectedKeys(); final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio);&#125; 上面列出的代码中, 有两个关键的调用, 第一个是 processSelectedKeys() 调用, 根据字面意思, 我们可以猜出这个方法肯定是查询就绪的 IO 事件, 然后处理它; 第二个调用是 runAllTasks(), 这个方法我们也可以一眼就看出来它的功能就是运行 taskQueue 中的任务.这里的代码还有一个十分有意思的地方, 即 ioRatio. 那什么是 ioRatio呢? 它表示的是此线程分配给 IO 操作所占的时间比(即运行 processSelectedKeys 耗时在整个循环中所占用的时间). 例如 ioRatio 默认是 50, 则表示 IO 操作和执行 task 的所占用的线程执行时间比是 1 : 1. 当知道了 IO 操作耗时和它所占用的时间比, 那么执行 task 的时间就可以很方便的计算出来了:1234设 IO 操作耗时为 ioTime, ioTime 占的时间比例为 ioRatio, 则: ioTime / ioRatio = taskTime / taskRatio taskRatio = 100 - ioRatio =&gt; taskTime = ioTime * (100 - ioRatio) / ioRatio 根据上面的公式, 当我们设置 ioRate = 70 时, 则表示 IO 运行耗时占比为70%, 即假设某次循环一共耗时为 100ms, 那么根据公式, 我们知道 processSelectedKeys() 方法调用所耗时大概为70ms(即 IO 耗时), 而 runAllTasks() 耗时大概为 30ms(即执行 task 耗时).当 ioRatio 为 100 时, Netty 就不考虑 IO 耗时的占比, 而是分别调用 processSelectedKeys()、runAllTasks(); 而当 ioRatio 不为 100时, 则执行到 else 分支, 在这个分支中, 首先记录下 processSelectedKeys() 所执行的时间(即 IO 操作的耗时), 然后根据公式, 计算出执行 task 所占用的时间, 然后以此为参数, 调用 runAllTasks(). 我们这里先分析一下 processSelectedKeys() 方法调用, runAllTasks() 我们留到下一节再分析.processSelectedKeys() 方法的源码如下:1234567private void processSelectedKeys() &#123; if (selectedKeys != null) &#123; processSelectedKeysOptimized(selectedKeys.flip()); &#125; else &#123; processSelectedKeysPlain(selector.selectedKeys()); &#125;&#125; 这个方法中, 会根据 selectedKeys 字段是否为空, 而分别调用 processSelectedKeysOptimized 或 processSelectedKeysPlain. selectedKeys 字段是在调用 openSelector() 方法时, 根据 JVM 平台的不同, 而有设置不同的值, 在我所调试这个值是不为 null 的. 其实 processSelectedKeysOptimized 方法 processSelectedKeysPlain 没有太大的区别, 为了简单起见, 我们以 processSelectedKeysOptimized 为例分析一下源码的工作流程吧.1234567891011121314151617181920private void processSelectedKeysOptimized(SelectionKey[] selectedKeys) &#123; for (int i = 0;; i ++) &#123; final SelectionKey k = selectedKeys[i]; if (k == null) &#123; break; &#125; selectedKeys[i] = null; final Object a = k.attachment(); if (a instanceof AbstractNioChannel) &#123; processSelectedKey(k, (AbstractNioChannel) a); &#125; else &#123; @SuppressWarnings(&quot;unchecked&quot;) NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); &#125; ... &#125;&#125; 其实你别看它代码挺多的, 但是关键的点就两个: 迭代 selectedKeys 获取就绪的 IO 事件, 然后为每个事件都调用 processSelectedKey 来处理它.这里正好完美对应上了我们提到的 Selector 的使用流程中的第三步里操作.还有一点需要注意的是, 我们可以调用 selectionKey.attach(object) 给一个 selectionKey 设置一个附加的字段, 然后可以通过 Object attachedObj = selectionKey.attachment() 获取它. 上面代代码正是通过了 k.attachment() 来获取一个附加在 selectionKey 中的对象, 那么这个对象是什么呢? 它又是在哪里设置的呢? 我们再来回忆一下 SocketChannel 是如何注册到 Selector 中的:在客户端的 Channel 注册过程中, 会有如下调用链:1234567Bootstrap.initAndRegister -&gt; AbstractBootstrap.initAndRegister -&gt; MultithreadEventLoopGroup.register -&gt; SingleThreadEventLoop.register -&gt; AbstractUnsafe.register -&gt; AbstractUnsafe.register0 -&gt; AbstractNioChannel.doRegister 最后的 AbstractNioChannel.doRegister 方法会调用 SocketChannel.register 方法注册一个 SocketChannel 到指定的 Selector:12345@Overrideprotected void doRegister() throws Exception &#123; // 省略错误处理 selectionKey = javaChannel().register(eventLoop().selector, 0, this);&#125; 特别注意一下 register 的第三个参数, 这个参数是设置 selectionKey 的附加对象的, 和调用 selectionKey.attach(object) 的效果一样. 而调用 register 所传递的第三个参数是 this, 它其实就是一个 NioSocketChannel 的实例. 那么这里就很清楚了, 我们在将 SocketChannel 注册到 Selector 中时, 将 SocketChannel 所对应的 NioSocketChannel 以附加字段的方式添加到了selectionKey 中.再回到 processSelectedKeysOptimized 方法中, 当我们获取到附加的对象后, 我们就调用 processSelectedKey 来处理这个 IO 事件:123456789final Object a = k.attachment();if (a instanceof AbstractNioChannel) &#123; processSelectedKey(k, (AbstractNioChannel) a);&#125; else &#123; @SuppressWarnings(&quot;unchecked&quot;) NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task);&#125; processSelectedKey 方法源码如下:1234567891011121314151617181920212223242526272829303132333435private static void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final NioUnsafe unsafe = ch.unsafe(); ... try &#123; int readyOps = k.readyOps(); // 可读事件 if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; unsafe.read(); if (!ch.isOpen()) &#123; // Connection already closed - no need to handle write. return; &#125; &#125; // 可写事件 if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write ch.unsafe().forceFlush(); &#125; // 连接建立事件 if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking // See https://github.com/netty/netty/issues/924 int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &#125; &#125; catch (CancelledKeyException ignored) &#123; unsafe.close(unsafe.voidPromise()); &#125;&#125; 这个代码是不是很熟悉啊? 完全是 Java NIO 的 Selector 的那一套处理流程嘛!processSelectedKey 中处理了三个事件, 分别是: OP_READ, 可读事件, 即 Channel 中收到了新数据可供上层读取. OP_WRITE, 可写事件, 即上层可以向 Channel 写入数据. OP_CONNECT, 连接建立事件, 即 TCP 连接已经建立, Channel 处于 active 状态. 下面我们分别根据这三个事件来看一下 Netty 是怎么处理的吧. OP_READ 处理当就绪的 IO 事件是 OP_READ, 代码会调用 unsafe.read() 方法, 即:12345678// 可读事件if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; unsafe.read(); if (!ch.isOpen()) &#123; // Connection already closed - no need to handle write. return; &#125;&#125; unsafe 这个字段, 我们已经和它打了太多的交道了, 在第一章 Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (客户端) 中我们已经对它进行过浓墨重彩地分析了, 最后我们确定了它是一个 NioSocketChannelUnsafe 实例, 负责的是 Channel 的底层 IO 操作.我们可以利用 Intellij IDEA 提供的 Go To Implementations 功能, 寻找到这个方法的实现. 最后我们发现这个方法没有在 NioSocketChannelUnsafe 中实现, 而是在它的父类 AbstractNioByteChannel 实现的, 它的实现源码如下:12345678910111213141516171819202122232425262728293031323334353637383940@Overridepublic final void read() &#123; ... ByteBuf byteBuf = null; int messages = 0; boolean close = false; try &#123; int totalReadAmount = 0; boolean readPendingReset = false; do &#123; byteBuf = allocHandle.allocate(allocator); int writable = byteBuf.writableBytes(); int localReadAmount = doReadBytes(byteBuf); // 检查读取结果. ... pipeline.fireChannelRead(byteBuf); byteBuf = null; ... totalReadAmount += localReadAmount; // 检查是否是配置了自动读取, 如果不是, 则立即退出循环. ... &#125; while (++ messages &lt; maxMessagesPerRead); pipeline.fireChannelReadComplete(); allocHandle.record(totalReadAmount); if (close) &#123; closeOnRead(pipeline); close = false; &#125; &#125; catch (Throwable t) &#123; handleReadException(pipeline, byteBuf, t, close); &#125; finally &#123; &#125;&#125; read() 源码比较长, 我为了篇幅起见, 删除了部分代码, 只留下了主干. 不过我建议读者朋友们自己一定要看一下 read() 源码, 这对理解 Netty 的 EventLoop 十分有帮助.上面 read 方法其实归纳起来, 可以认为做了如下工作: 分配 ByteBuf 从 SocketChannel 中读取数据 调用 pipeline.fireChannelRead 发送一个 inbound 事件. 前面两点没什么好说的, 第三点 pipeline.fireChannelRead 读者朋友们看到了有没有会心一笑地感觉呢? 反正我看到这里时是有的. pipeline.fireChannelRead 正好就是我们在第二章 Netty 源码分析之 二 贯穿Netty 的大动脉 ── ChannelPipeline (二) 中分析的 inbound 事件起点. 当调用了 pipeline.fireIN_EVT() 后, 那么就产生了一个 inbound 事件, 此事件会以 head -&gt; customContext -&gt; tail 的方向依次流经 ChannelPipeline 中的各个 handler.调用了 pipeline.fireChannelRead 后, 就是 ChannelPipeline 中所需要做的工作了, 这些我们已经在第二章中有过详细讨论, 这里就展开了. OP_WRITE 处理OP_WRITE 可写事件代码如下. 这里代码比较简单, 没有详细分析的必要了.1234if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write ch.unsafe().forceFlush();&#125; OP_CONNECT 处理最后一个事件是 OP_CONNECT, 即 TCP 连接已建立事件.123456789if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking // See https://github.com/netty/netty/issues/924 int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect();&#125; OP_CONNECT 事件的处理中, 只做了两件事情: 正如代码中的注释所言, 我们需要将 OP_CONNECT 从就绪事件集中清除, 不然会一直有 OP_CONNECT 事件. 调用 unsafe.finishConnect() 通知上层连接已建立 unsafe.finishConnect() 调用最后会调用到 pipeline().fireChannelActive(), 产生一个 inbound 事件, 通知 pipeline 中的各个 handler TCP 通道已建立(即 ChannelInboundHandler.channelActive 方法会被调用) 到了这里, 我们整个 NioEventLoop 的 IO 操作部分已经了解完了, 接下来的一节我们要重点分析一下 Netty 的任务队列机制. Netty 的任务队列机制我们已经提到过, 在Netty 中, 一个 NioEventLoop 通常需要肩负起两种任务, 第一个是作为 IO 线程, 处理 IO 操作; 第二个就是作为任务线程, 处理 taskQueue 中的任务. 这一节的重点就是分析一下 NioEventLoop 的任务队列机制的. Task 的添加普通 Runnable 任务NioEventLoop 继承于 SingleThreadEventExecutor, 而 SingleThreadEventExecutor 中有一个 Queue taskQueue 字段, 用于存放添加的 Task. 在 Netty 中, 每个 Task 都使用一个实现了 Runnable 接口的实例来表示.例如当我们需要将一个 Runnable 添加到 taskQueue 中时, 我们可以进行如下操作:1234567EventLoop eventLoop = channel.eventLoop();eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;Hello, Netty!&quot;); &#125;&#125;); 当调用 execute 后, 实际上是调用到了 SingleThreadEventExecutor.execute() 方法, 它的实现如下:123456789101112131415161718192021@Overridepublic void execute(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(&quot;task&quot;); &#125; boolean inEventLoop = inEventLoop(); if (inEventLoop) &#123; addTask(task); &#125; else &#123; startThread(); addTask(task); if (isShutdown() &amp;&amp; removeTask(task)) &#123; reject(); &#125; &#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123; wakeup(inEventLoop); &#125;&#125; 而添加任务的 addTask 方法的源码如下:123456789protected void addTask(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(&quot;task&quot;); &#125; if (isShutdown()) &#123; reject(); &#125; taskQueue.add(task);&#125; 因此实际上, taskQueue 是存放着待执行的任务的队列. schedule 任务除了通过 execute 添加普通的 Runnable 任务外, 我们还可以通过调用 eventLoop.scheduleXXX 之类的方法来添加一个定时任务. EventLoop 中实现任务队列的功能在超类 SingleThreadEventExecutor 实现的, 而 schedule 功能的实现是在 SingleThreadEventExecutor 的父类, 即 AbstractScheduledEventExecutor 中实现的.在 AbstractScheduledEventExecutor 中, 有以 scheduledTaskQueue 字段:1Queue&lt;ScheduledFutureTask&lt;?&gt;&gt; scheduledTaskQueue; scheduledTaskQueue 是一个队列(Queue), 其中存放的元素是 ScheduledFutureTask. 而 ScheduledFutureTask 我们很容易猜到, 它是对 Schedule 任务的一个抽象.我们来看一下 AbstractScheduledEventExecutor 所实现的 schedule 方法吧:1234567891011@Overridepublic ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) &#123; ObjectUtil.checkNotNull(command, &quot;command&quot;); ObjectUtil.checkNotNull(unit, &quot;unit&quot;); if (delay &lt; 0) &#123; throw new IllegalArgumentException( String.format(&quot;delay: %d (expected: &gt;= 0)&quot;, delay)); &#125; return schedule(new ScheduledFutureTask&lt;Void&gt;( this, command, null, ScheduledFutureTask.deadlineNanos(unit.toNanos(delay))));&#125; 这是其中一个重载的 schedule, 当一个 Runnable 传递进来后, 会被封装为一个 ScheduledFutureTask 对象, 这个对象会记录下这个 Runnable 在何时运行、已何种频率运行等信息.当构建了 ScheduledFutureTask 后, 会继续调用 另一个重载的 schedule 方法:1234567891011121314&lt;V&gt; ScheduledFuture&lt;V&gt; schedule(final ScheduledFutureTask&lt;V&gt; task) &#123; if (inEventLoop()) &#123; scheduledTaskQueue().add(task); &#125; else &#123; execute(new OneTimeTask() &#123; @Override public void run() &#123; scheduledTaskQueue().add(task); &#125; &#125;); &#125; return task;&#125; 在这个方法中, ScheduledFutureTask 对象就会被添加到 scheduledTaskQueue 中了. 任务的执行当一个任务被添加到 taskQueue 后, 它是怎么被 EventLoop 执行的呢?让我们回到 NioEventLoop.run() 方法中, 在这个方法里, 会分别调用 processSelectedKeys() 和 runAllTasks() 方法, 来进行 IO 事件的处理和 task 的处理. processSelectedKeys() 方法我们已经分析过了, 下面我们来看一下 runAllTasks() 中到底有什么名堂吧.runAllTasks 方法有两个重载的方法, 一个是无参数的, 另一个有一个参数的. 首先来看一下无参数的 runAllTasks:123456789101112131415161718192021protected boolean runAllTasks() &#123; fetchFromScheduledTaskQueue(); Runnable task = pollTask(); if (task == null) &#123; return false; &#125; for (;;) &#123; try &#123; task.run(); &#125; catch (Throwable t) &#123; logger.warn(&quot;A task raised an exception.&quot;, t); &#125; task = pollTask(); if (task == null) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); return true; &#125; &#125;&#125; 我们前面已经提到过, EventLoop 可以通过调用 EventLoop.execute 来将一个 Runnable 提交到 taskQueue 中, 也可以通过调用 EventLoop.schedule 来提交一个 schedule 任务到 scheduledTaskQueue 中. 在此方法的一开始调用的 fetchFromScheduledTaskQueue() 其实就是将 scheduledTaskQueue 中已经可以执行的(即定时时间已到的 schedule 任务) 拿出来并添加到 taskQueue 中, 作为可执行的 task 等待被调度执行.它的源码如下:123456789101112private void fetchFromScheduledTaskQueue() &#123; if (hasScheduledTasks()) &#123; long nanoTime = AbstractScheduledEventExecutor.nanoTime(); for (;;) &#123; Runnable scheduledTask = pollScheduledTask(nanoTime); if (scheduledTask == null) &#123; break; &#125; taskQueue.add(scheduledTask); &#125; &#125;&#125; 接下来 runAllTasks() 方法就会不断调用 task = pollTask() 从 taskQueue 中获取一个可执行的 task, 然后调用它的 run() 方法来运行此 task. 注意, 因为 EventLoop 既需要执行 IO 操作, 又需要执行 task, 因此我们在调用 EventLoop.execute 方法提交任务时, 不要提交耗时任务, 更不能提交一些会造成阻塞的任务, 不然会导致我们的 IO 线程得不到调度, 影响整个程序的并发量.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis的缓存过期策略]]></title>
    <url>%2Fredis%2FRedis%E7%9A%84%E7%BC%93%E5%AD%98%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[过期策略定时清除含义：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除 优点 保证内存被尽快释放 缺点 若过期key很多，删除这些key会占用很多的CPU时间，在CPU时间紧张的情况下，CPU不能把所有的时间用来做要紧的事儿，还需要去花时间删除这些key 定时器的创建耗时，若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生），性能影响严重 懒汉式删除含义：key过期的时候不删除，每次通过key获取值的时候去检查是否过期，若过期，则删除，返回null。 优点 删除操作只发生在通过key取值的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的key了） 缺点 若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，那么可能发生内存泄露（无用的垃圾占用了大量的内存） 定期删除含义：每隔一段时间执行一次删除过期key操作 优点 通过限制删除操作的时长和频率，来减少删除操作对CPU时间的占用–处理”定时删除”的缺点 定期删除过期key–处理”懒汉式删除”的缺点 缺点 在内存友好方面，不如”定时删除”（会造成一定的内存占用，但是没有懒汉式那么占用内存） 在CPU时间友好方面，不如”懒汉式删除”（会定期的去进行比较和删除操作，cpu方面不如懒汉式，但是比定时好） Redis采用的过期策略懒汉式删除+定期删除 懒汉式删除流程： 在进行get或setnx等操作时，先检查key是否过期； 若过期，删除key，然后执行相应操作； 若没过期，直接执行相应操作； 定期删除流程（简单而言，对指定个数个库的每一个库随机删除小于等于指定个数个过期key）： 遍历每个数据库（就是redis.conf中配置的”database”数量，默认为16） 检查当前库中的指定个数个key（默认是每个库检查20个key，注意相当于该循环执行20次，循环体是下边的描述） 如果当前库中没有一个key设置了过期时间，直接执行下一个库的遍历 随机获取一个设置了过期时间的key，检查该key是否过期，如果过期，删除key 判断定期删除操作是否已经达到指定时长，若已经达到，直接退出定期删除。 参考https://blog.csdn.net/xiangnan129/article/details/54928672]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis持久化]]></title>
    <url>%2Fredis%2Fredis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis 提供了多种不同级别的持久化方式： RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。 AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。 Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。 你甚至可以关闭持久化功能，让数据只在服务器运行时存在。 了解 RDB 持久化和 AOF 持久化之间的异同是非常重要的， 以下几个小节将详细地介绍这这两种持久化功能， 并对它们的相同和不同之处进行说明。 RDB优点 RDB 是一个非常紧凑（compact）的文件，它保存了 Redis 在某个时间点上的数据集。 这种文件非常适合用于进行备份： 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。 RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心，或者亚马逊 S3 中。 RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 缺点 如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据。 每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork()可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。 AOF优点 使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）。 AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题。 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。 AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。 缺点 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。 AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。 （举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug 。） 测试套件里为这种情况添加了测试： 它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的。 http://redisdoc.com/topic/persistence.html]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>持久化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis分布式锁]]></title>
    <url>%2Fredis%2Fredis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[分布式锁可以基于很多种方式实现，比如zookeeper、redis…。不管哪种方式，他的基本原理是不变的：用一个状态值表示锁，对锁的占用和释放通过状态值来标识。 三、使用redis的setNX命令实现分布式锁 、实现的原理 Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系。redis的SETNX命令可以方便的实现分布式锁。 2、基本命令解析 1）setNX（SET if Not eXists） 语法： 1SETNX key value 将 key 的值设为 value ，当且仅当 key 不存在。 若给定的 key 已经存在，则 SETNX 不做任何动作。 SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写 返回值： 设置成功，返回 1 。 设置失败，返回 0 。 例子： 1234567891011redis&gt; EXISTS job # job 不存在(integer) 0redis&gt; SETNX job &quot;programmer&quot; # job 设置成功(integer) 1redis&gt; SETNX job &quot;code-farmer&quot; # 尝试覆盖 job ，失败(integer) 0redis&gt; GET job # 没有被覆盖&quot;programmer&quot; 所以我们使用执行下面的命令 1SETNX lock.foo &lt;current Unix time + lock timeout + 1&gt; 如返回1，则该客户端获得锁，把lock.foo的键值设置为时间值表示该键已被锁定，该客户端最后可以通过DEL lock.foo来释放该锁。 如返回0，表明该锁已被其他客户端取得，这时我们可以先返回或进行重试等对方完成或等待锁超时。 2）getSET 语法： 1GETSET key value 将给定 key 的值设为 value，并返回 key 的旧值(old value)。 当 key 存在但不是字符串类型时，返回一个错误。 返回值： 返回给定 key 的旧值。 1当 key 没有旧值时，也即是， key 不存在时，返回 nil 。 3）get 语法： 1GET key 返回值： 当 key 不存在时，返回 nil ，否则，返回 key 的值。 1如果 key 不是字符串类型，那么返回一个错误 四、解决死锁 上面的锁定逻辑有一个问题：如果一个持有锁的客户端失败或崩溃了不能释放锁，该怎么解决？ 我们可以通过锁的键对应的时间戳来判断这种情况是否发生了，如果当前的时间已经大于lock.foo的值，说明该锁已失效，可以被重新使用。 发生这种情况时，可不能简单的通过DEL来删除锁，然后再SETNX一次（讲道理，删除锁的操作应该是锁拥有这执行的，这里只需要等它超时即可），当多个客户端检测到锁超时后都会尝试去释放它，这里就可能出现一个竞态条件,让我们模拟一下这个场景： C0操作超时了，但它还持有着锁，C1和C2读取lock.foo检查时间戳，先后发现超时了。C1 发送DEL lock.fooC1 发送SETNX lock.foo 并且成功了。C2 发送DEL lock.fooC2 发送SETNX lock.foo 并且成功了。这样一来，C1，C2都拿到了锁！问题大了！ 幸好这种问题是可以避免的，让我们来看看C3这个客户端是怎样做的： C3发送SETNX lock.foo 想要获得锁，由于C0还持有锁，所以Redis返回给C3一个0C3发送GET lock.foo 以检查锁是否超时了，如果没超时，则等待或重试。反之，如果已超时，C3通过下面的操作来尝试获得锁：GETSET lock.foo 通过GETSET，C3拿到的时间戳如果仍然是超时的，那就说明，C3如愿以偿拿到锁了。 如果在C3之前，有个叫C4的客户端比C3快一步执行了上面的操作，那么C3拿到的时间戳是个未超时的值，这时，C3没有如期获得锁，需要再次等待或重试。留意一下，尽管C3没拿到锁，但它改写了C4设置的锁的超时值，不过这一点非常微小的误差带来的影响可以忽略不计。 注意：为了让分布式锁的算法更稳键些，持有锁的客户端在解锁之前应该再检查一次自己的锁是否已经超时，再去做DEL操作，因为可能客户端因为某个耗时的操作而挂起，操作完的时候锁因为超时已经被别人获得，这时就不必解锁了 六、一些问题 1、为什么不直接使用expire设置超时时间，而将时间的毫秒数其作为value放在redis中？ 如下面的方式，把超时的交给redis处理： 1234567lock(key, expireSec)&#123;isSuccess = setnx keyif (isSuccess)expire key expireSec&#125; 这种方式貌似没什么问题，但是假如在setnx后，redis崩溃了，expire就没有执行，结果就是死锁了。锁永远不会超时。 2、为什么前面的锁已经超时了，还要用getSet去设置新的时间戳的时间获取旧的值，然后和外面的判断超时时间的时间戳比较呢？ 因为是分布式的环境下，可以在前一个锁失效的时候，有两个进程进入到锁超时的判断。如： C0超时了，还持有锁,C1/C2同时请求进入了方法里面 C1/C2获取到了C0的超时时间 C1使用getSet方法 C2也执行了getSet方法 假如我们不加 oldValueStr.equals(currentValueStr) 的判断，将会C1/C2都将获得锁，加了之后，能保证C1和C2只能一个能获得锁，一个只能继续等待。 注意：这里可能导致超时时间不是其原本的超时时间，C1的超时时间可能被C2覆盖了，但是他们相差的毫秒及其小，这里忽略了。 http://www.cnblogs.com/0201zcr/p/5942748.html http://blog.csdn.net/ugg/article/details/41894947 仅有一个setnx命令，redis遇到的问题跟数据库锁一样，但是过期时间这一项，redis自带的expire功能可以不需要应用主动去删除锁。而且从 Redis 2.6.12 版本开始，redis的set命令直接直接设置NX和EX属性，NX即附带了setnx数据，key存在就无法插入，EX是过期属性，可以设置过期时间。这样一个命令就能原子的完成加锁和设置过期时间。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络协议]]></title>
    <url>%2Fprotocols%2F</url>
    <content type="text"><![CDATA[TCP/IP、Http、Socket的区别 通俗大白话来理解TCP协议的三次握手和四次分手 Netty 长连接服务]]></content>
  </entry>
  <entry>
    <title><![CDATA[索引系列]]></title>
    <url>%2FBitMap%2F</url>
    <content type="text"><![CDATA[BitMaphttps://www.cnblogs.com/LBSer/p/3322630.html https://www.cnblogs.com/yangjiannr/p/da-shu-ju-chu-libitmap.html https://www.cnblogs.com/scott19820130/p/6058677.html http://blog.renbaobin.com/bitmap.html]]></content>
      <categories>
        <category>索引</category>
      </categories>
      <tags>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm参数]]></title>
    <url>%2Fjava%2Fjvm%2Fjvm%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[-Xms10m 设置堆的最小空间大小。 -Xmx10m 设置堆的最大空间大小。 -Xmn10m 设置年轻代大小 -XX:NewSize=256m 设置新生代最小空间大小。 -XX:MaxNewSize=256m 设置新生代最大空间大小。 -XX:PermSize=256m 设置永久代最小空间大小。 -XX:MaxPermSize=256m 设置永久代最大空间大小。 -Xss128k 设置每个线程的堆栈大小。]]></content>
  </entry>
  <entry>
    <title><![CDATA[类加载机制]]></title>
    <url>%2Fjava%2Fjvm%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[主要关注点： 什么是类的加载 类的生命周期 类加载器 双亲委派模型 什么是类的加载类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。 类的生命周期类的生命周期包括这几个部分，加载、连接、初始化、使用和卸载，其中前三部是类的加载的过程,如下图； 加载，查找并加载类的二进制数据，在Java堆中也创建一个java.lang.Class类的对象 连接，连接又包含三块内容：验证、准备、初始化。1）验证，文件格式、元数据、字节码、符号引用验证；2）准备，为类的静态变量分配内存，并将其初始化为默认值；3）解析，把类中的符号引用转换为直接引用 初始化，为类的静态变量赋予正确的初始值 使用，new出对象程序中使用 卸载，执行垃圾回收 其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备、初始化和卸载这5个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持 Java 语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 加载加载是类加载过程中的一个阶段，这个阶段会在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的入口。注意这里不一定非得要从一个Class文件获取，这里既可以从ZIP包中读取（比如从jar包和war包中读取），也可以在运行时计算生成（动态代理），也可以由其它文件生成（比如将JSP文件转换成对应的Class类）。 通过一个类的全限定名获取描述此类的二进制字节流； 将这个字节流所代表的静态存储结构保存为方法区的运行时数据结构； 在内存（并不一定是java堆，可能在方法区，取决于vm的实现）中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 验证这一阶段的主要目的是为了确保Class文件的字节流中包含的信息是否符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 文件格式 元数据 字节码 符号引用验证 准备准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为： 1public static int v = 8080; 实际上变量v在准备阶段过后的初始值为0而不是8080，将v赋值为8080的putstatic指令是程序被编译后，存放于类构造器&lt;clinit&gt;方法之中，这里我们后面会解释。但是注意如果声明为： 1public static final int v = 8080; 在编译阶段会为v生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将v赋值为8080。 解析解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是class文件中的： CONSTANT_Class_info CONSTANT_Field_info CONSTANT_Method_info 等类型的常量。 下面我们解释一下符号引用和直接引用的概念： 符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。 初始化何时开始初始化： Java并没有规定什么时候开始第一个阶段：加载，但是Java虚拟机规范规定有且只有5种情况必须立即对类进行初始化（而加载、验证、准备自然需要在此之前开始）1）遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。2）使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。3）当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类初始化。4）当虚拟机启动时，用户需要指定一个要执行的主类（包含main方法的），虚拟机会优先初始化这个主类。5）当使用JDK1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic等时， 这个方法的类还没有进行过初始化，则需要先触发其初始化。 初始化阶段是类加载最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载器以外，其它操作都由JVM主导。到了初始阶段，才开始真正执行类中定义的Java程序代码。 初始化阶段是执行类构造器&lt;clinit&gt;方法的过程。&lt;clinit&gt;方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。&lt;clinit&gt;方法不需要显式调用父类的构造器，虚拟机会保证&lt;clinit&gt;方法执行之前，父类的&lt;clinit&gt;方法已经执行完毕。p.s: 如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成&lt;clinit&gt;()方法。 最后看一下接口的初始化过程与类初始化过程的不同。接口也有初始化过程，上面的代码中我们都是用静态语句块来输出初始化信息的，而在接口中不能使用“static{}”语句块，但编译器仍然会为接口生成&lt;clinit&gt;类构造器，用于初始化接口中定义的成员变量（实际上是static final修饰的全局常量）。二者在初始化时最主要的区别是：当一个类在初始化时，要求其父类全部已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量），才会初始化该父接口。这点也与类初始化的情况很不同，调用类中的static final常量时并不会 触发该类的初始化，但是调用接口中的static final常量时便会触发该接口的初始化。 注意以下几种情况不会执行类初始化： 通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。 定义对象数组，不会触发该类的初始化。 常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。 通过类名获取Class对象，不会触发类的初始化。 通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。 通过ClassLoader默认的loadClass方法，也不会触发初始化动作。 几个小问题？1、JVM初始化步骤 ？ 2、类初始化时机 ？3、哪几种情况下，Java虚拟机将结束生命周期？答案参考这篇文章JVM（1）：Java 类的加载机制 类加载器 种类 启动类加载器：Bootstrap ClassLoader，负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库 扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载DK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。 应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器 类加载机制 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 好处： 解决基础类的统一问题。比如位于rt.jar包中的类java.lang.Object，无论哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，确保了Object类在各种加载器环境中都是同一个类。 双亲委托模型打破 线程上下文类加载器（Thread Context Classloader） OSGI http://www.cnblogs.com/lanxuezaipiao/p/4138511.htmlSPI和DriverManager 参考https://blog.csdn.net/briblue/article/details/54973413]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm梳理]]></title>
    <url>%2Fjava%2Fjvm%2Fjvm%E6%A2%B3%E7%90%86%2F</url>
    <content type="text"><![CDATA[在江湖中要练就绝世武功必须内外兼备，精妙的招式和深厚的内功，武功的基础是内功。对于武功低（就像江南七怪）的人，招式更重要，因为他们不能靠内功直接去伤人，只能靠招式，利刃上优势来取胜了，但是练到高手之后，内功就更主要了。一个内功低的人招式在奇妙也打不过一个内功高的人。比如，你剑法再厉害，一剑刺过来，别人一掌打断你的剑，你还怎么使剑法，你一掌打到一个武功高的人身上，那人没什么事，却把你震伤了，你还怎么打。同样两者也是相辅相成的，内功深厚之后，原来普通的一招一式威力也会倍增。 对于搞开发的我们其实也是一样，现在流行的框架越来越多，封装的也越来越完善，各种框架可以搞定一切，几乎不用关注底层的实现，初级程序员只要熟悉基本的使用方法，便可以快速的开发上线；但对于高级程序员来讲，内功的修炼却越发的重要，比如算法、设计模式、底层原理等，只有把这些基础熟练之后，才能在开发过程中知其然知其所以然，出现问题时能快速定位到问题的本质。 对于Java程序员来讲，spring全家桶几乎可以搞定一切，spring全家桶便是精妙的招式，jvm就是内功心法很重要的一块，线上出现性能问题，jvm调优更是不可回避的问题。因此JVM基础知识对于高级程序员的重要性不必言语，我司在面试高级开发的时候，jvm相关知识也必定是考核的标准之一。本篇文章会根据之前写的jvm系列文章梳理出jvm需要关注的所有考察点。 jvm 总体梳理jvm体系总体分四大块： 类的加载机制 jvm内存结构 GC算法 垃圾回收 GC分析 命令调优 当然这些知识点在之前的文章中都有详细的介绍，这里只做主干的梳理 这里画了一个思维导图，将所有的知识点进行了陈列，因为图比较大可以点击右键下载了放大查看。 类的加载机制主要关注点： 什么是类的加载 类的生命周期 类加载器 双亲委派模型 类加载机制 jvm内存结构主要关注点： jvm内存结构都是什么 对象分配规则 jvm内存结构 jvm内存模型 对象分配规则 对象分配规则 如何通过参数来控制个各个内存区域参考此文章：JVM（2）：JVM内存结构 GC算法 垃圾回收主要关注点： 对象存活判断 GC算法 垃圾回收器 GC GC算法和垃圾回收器算法图解以及更详细内容参考JVM（3）：Java GC算法 垃圾收集器 GC分析 命令调优主要关注点： GC日志分析 调优命令 调优工具 GC日志分析 摘录GC日志一部分（前部分为年轻代gc回收；后部分为full gc回收）： 通过上面日志分析得出，PSYoungGen、ParOldGen、PSPermGen属于Parallel收集器。其中PSYoungGen表示gc回收前后年轻代的内存变化；ParOldGen表示gc回收前后老年代的内存变化；PSPermGen表示gc回收前后永久区的内存变化。young gc 主要是针对年轻代进行内存回收比较频繁，耗时短；full gc 会对整个堆内存进行回城，耗时长，因此一般尽量减少full gc的次数 young gc 日志: Full GC日志: 调优命令 Sun JDK监控和故障处理命令有jps jstat jmap jhat jstack jinfo jps，JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。 jstat，JVM statistics Monitoring是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 jmap，JVM Memory Map命令用于生成heap dump文件 jhat，JVM Heap Analysis Tool命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP/HTML服务器，生成dump的分析结果后，可以在浏览器中查看 jstack，用于生成java虚拟机当前时刻的线程快照。 jinfo，JVM Configuration info 这个命令作用是实时查看和调整虚拟机运行参数。 详细的命令使用参考这里JVM（4）：Jvm调优-命令篇 调优工具 常用调优工具分为两类,jdk自带监控工具：jconsole和jvisualvm，第三方有：MAT(Memory Analyzer Tool)、GChisto。 jconsole，Java Monitoring and Management Console是从java5开始，在JDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控 jvisualvm，jdk自带全能工具，可以分析内存快照、线程快照；监控内存变化、GC变化等。 MAT，Memory Analyzer Tool，一个基于Eclipse的内存分析工具，是一个快速、功能丰富的Java heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗 GChisto，一款专业分析gc日志的工具 工具使用参考JVM（7）：JVM调优-工具篇 本系列： JVM（1）：Java 类的加载机制 JVM（2）：JVM内存结构 JVM（3）：Java GC算法 垃圾收集器 JVM（4）：Jvm调优-命令篇 JVM（5）：tomcat性能调优和性能监控（visualvm） JVM（6）：JVM调优-从eclipse开始 JVM（7）：JVM调优-工具篇 JVM（8）：JVM知识点总览-高级Java工程师面试必备 http://www.importnew.com/25295.html https://www.ziwenxie.site/2017/06/07/java-jvm-classloader/]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于幽默]]></title>
    <url>%2F%E5%B9%BD%E9%BB%98%2F</url>
    <content type="text"><![CDATA[男生怎么让自己变得幽默风趣 要练口才,内功第一 很多人觉得,风趣幽默就好像一种技能一样,能够速成。其实没那么简单的,就像所有武功一样,要练招式,必须内功先行。对于口才而言,所谓的内功,就是内涵,就是阅读量,就是多读书。 要活用段子 在这里举个例子吧:男:Hi,我想借一下纸巾。女:给你。男:谢谢,你电话多少,我改天还你。女:不用了。接下来要怎么破呢?你是不是就放弃了?千万不要啊。你可以这样接话:早知道问你借钱了。总之,想变得幽默,就不能按照套路出牌啊! 零门槛幽默大法,自黑无底线 有一句话说得好,黑到深处自然粉,被黑到深处自然红。懂自黑、自嘲的人,更自信、更大度,表现出来更懂得分寸和尊重别人,简直就是活生生的段子手啊!自己有什么缺点,比如矮,比如黑,比如学历低,比如挣得少,比如不聪明……。不要等别人拿你开涮,自己先拿自己开涮,这样其他人也就无话可说了! 熟悉各种网络梗,很有必要 如果说80后是互联网移民,现在的90后、00后妹子,就是互联网的原住民,她们天然地熟悉各种网络梗、各种网络段子。比如”不管你信不信,反正我信了”,”100块钱都不给我”,”我只想做一个安静的美男子”等句子,一定要在生活中活学活用,会很容易拉进与妹子的距离的! 善于运用逆向思维 比如和妹子在一起,迎面走来一只小狗,妹子想必会抱住它亲切交流,这时候,你上去亲切地叫一声”喵”,妹子会是什么反应呢?一定会觉得你这个人挺有意思的,很有生活情趣。 男生必学的5种幽默方式 曲解式幽默 什么叫曲解?就是把意思理解歪了。尤其是在恋爱中。举个例子:男:你吃饭了吗?女:干嘛?男:不干! 上面的例子大家看出来了吗?歪曲女孩的话的意思。这里不仅在在和女孩聊天,朋友,公共场合都可以使用的。看了这条回复,都会认为你是个很幽默的人,并不是色。 夸大式幽默 什么叫夸大?就是一件平常的事扩大化。尤其是对方在做某一件事的时候。例:女:你蹲在那里干嘛呢?男:我在测试地球的吸引力有多大。 这样的一件平常的事,蹲在那里还能干嘛?找东西,厕所,这都是平常的事说的跟专家似的,听起来是不是让人笑呢?可以去和女孩子试试哦。 缩小式幽默 既然有扩大,那么必有缩小。可以让大事化小小事化了的幽默。例子:女:你今天彻底把我惹毛了,我以后再也不理你了。男:我哪有惹毛你了。你的头发我都没碰一下!女:滚!男:好呀,晚上我滚床单给你暖床。 女生很怒火了,可是在你简简单单的两句话中,就直接转移话题,大事化小,最后直接说成你们两个人别的事了。是不是很强大呢?可以去试试。效果威力绝对大! 目的式曲解 目的是,把别人说话的目的直接曲解,引起对方的好奇与笑点。例:女:我现在只想把你送到外星球上!男:这样做是不是太花钱了呀? 目的式曲解,一种是迎着对方的目的去说,一种是嘲讽对方。大家谨慎使用。 日常式幽默 这种幽默用的太多了。我们平常是不是用过呢?举例:女:谢谢你。男:不用谢,请叫我雷锋。女:你看我是不是很漂亮呢?男:仔细看很漂亮。不过得仔细看!(内涵式幽默)。]]></content>
      <categories>
        <category>聊天</category>
      </categories>
      <tags>
        <tag>幽默</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拒绝输出是荒废一个人最好的办法]]></title>
    <url>%2F%E8%81%8A%E5%A4%A9%2F%E6%8B%92%E7%BB%9D%E8%BE%93%E5%87%BA%E6%98%AF%E8%8D%92%E5%BA%9F%E4%B8%80%E4%B8%AA%E4%BA%BA%E6%9C%80%E5%A5%BD%E7%9A%84%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[你是这样的人么？ 沉溺于「轻易获得高成就感」的事情，比如打游戏比如等朋友圈的点赞。 只接收「低信息密度」的信息源。比如不看书，就爱看新闻和八卦。 习惯用「错位成就感」麻痹自己。比如把自己擅长的和别人不擅长的比，甚至总爱和别人比，没有内部计分卡，不关心自我成长。 我们每个人的生活，基本上都是信息的投入产出组成的，你看视频，刷新闻，读公众号，都是一种输入，当你开始输出的时候，你的投入才会通过大脑的思考和逻辑，内化成对你而言有价值的东西。 因此，不论是打游戏成瘾，还是看电视剧看到疯魔，在我眼里，都是一种失控的输入，是一种零输出，是一种对生活完全的透支。 最可怕的地方在于，输出的能力是需要培养和训练的。就好比我们高中的时候，练作文，你光看范文半点用没有，必须自己动笔写才会有提高。 一个人如果很长时间不输出自己的知识，自然就没有兴趣去做这件事，继而更加不会锻炼到这种能力，这样的恶性循环，就会导致被吸收的知识不断被遗忘，知识变成废料。 而这，也是生活中大多数人每天在做的事。想想你上次看的公众号内容，你还记得多少呢？ 但是碎片化的内容也是能够让你保持成长的，只要你这么做↓ 1、先花一点时间，建立自己的知识体系。 把你已经知道的东西梳理一遍。如何梳理呢？以你能够说出某个知识点的影响因素，以及它对其他事物的影响为准。顺着这样的知识点捋一遍，这个网络就是你已经构建完成的知识网络。 2、找到知识网络的触点。 亦即自己感兴趣的、但尚未进行探索和了解的知识点。 阅读、学习的时候，有意识地去接触这些触点的知识，延展自己的知识网络。 3、当接触到一个新的知识点时，先考虑如何将其纳入知识体系。 亦即在脑子里回想你的知识网络，思考它可以如何跟你已经知道的东西联系起来。 4、如果找到了对应的点，弄通路径。 亦即，将这个新的知识点，跟已经知道的某个点之间的路径，查清楚、弄清楚，将它们连接起来，使这个知识点成为你新的“触点”，拓展你的思维网络。 5、检验并输出。 将这两个点之间的联系讲清楚。最简单的办法，就是通过口述、写文章，去教会别人这个知识。或者，在心里把它讲一遍，看是否能够讲得清晰易懂，没有障碍。只有能够输出的东西，才是真正属于你的东西。 6、不符合以上方式的内容，果断舍弃。 如果一个东西无法纳入你的认知体系，那说明你现在还不能掌握它，那就果断放弃，因为它对你来说是没有价值的，或者说（记忆的）成本是远高于收益的。 再多谈几点： 1、读书不用追求“读完一本书”，而应该追求“从这本书中获得了什么东西”。 一本书的内容不可能100%对你有用，其中肯定有你所不感兴趣的东西，也有你所无法接受的东西，没关系，接受你所能接受的即可。不用务求全部读完。甚至，读一半，放回去，再跳着读别的书，也是很好的方式。读书应该为自己所用，而不是让自己去迁就它。 2、如何处理微博上、知乎上那些有趣的碎片化知识？ 个人建议，最好的方式，是将它们作为起点。如果你觉得一个知识很有趣，就以它为出发点，去探索它背后的原理、背景、应用，去查资料、GOOGLE，顺藤摸瓜。这个知识点本身是没有太大价值的，有价值的是你去探索的过程。你经过探索了解到的东西，才能纳入你的知识体系，成为你思维的一部分。 3、以上种种都需要不菲的时间，但学习本就是一件艰难的事情，所以优秀的人永远是凤毛麟角，所谓聪明的人，无非他们把走路、等车、休息等更多的时间花在这上面罢了。再说，学习本身，岂非也是一件很有趣的事情？ 版权声明：如涉及版权问题，请作者持权属证明与本网联系 原文]]></content>
      <categories>
        <category>阅读</category>
      </categories>
      <tags>
        <tag>碎片化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生活语录]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%E8%AF%AD%E5%BD%95%2F</url>
    <content type="text"><![CDATA[关于读书，掌握重点就好，细节的东西，往往来自经验。 事务的出现是因为有使用的需要，所以掌握事务的第一关键是学会使用。]]></content>
  </entry>
  <entry>
    <title><![CDATA[G1 GC]]></title>
    <url>%2Fjava%2FG1GC%2F</url>
    <content type="text"><![CDATA[GarbageFirst（G1）G1（Garbage-First）收集器是当今收集器技术发展最前沿的成果之一，它是一款面向服务端应用的垃圾收集器，HotSpot开发团队赋予它的使命是（在比较长期的）未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点： 并行与并发 G1 能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短“Stop The World”停顿时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。 分代收集 与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同方式去处理新创建的对象和已存活一段时间、熬过多次GC的旧对象来获取更好的收集效果。 空间整合 G1从整体来看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的。这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。 可预测的停顿 这是G1相对CMS的一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了降低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。 内存划分RegionG1算法将堆划分为若干个区域（Region），它仍然属于分代收集器。不过，这些区域的一部分包含新生代，新生代的垃圾收集依然采用暂停所有应用线程的方式，将存活对象拷贝到老年代或者Survivor空间。老年代也分成很多区域，G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有cms内存碎片问题的存在了。 在G1中，还有一种特殊的区域，叫Humongous区域。 如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。 PS：在java 8中，持久代也移动到了普通的堆内存空间中，改为元空间。 对象分配策略 说起大对象的分配，我们不得不谈谈对象的分配策略。它分为3个阶段： TLAB(Thread Local Allocation Buffer)线程本地分配缓冲区 Eden区中分配 Humongous区分配 TLAB为线程本地分配缓冲区，它的目的为了使对象尽可能快的分配出来。如果对象在一个共享的空间中分配，我们需要采用一些同步机制来管理这些空间内的空闲空间指针。在Eden空间中，每一个线程都有一个固定的分区用于分配对象，即一个TLAB。分配对象时，线程之间不再需要进行任何的同步。 对TLAB空间中无法分配的对象，JVM会尝试在Eden空间中进行分配。如果Eden空间无法容纳该对象，就只能在老年代中进行分配空间。 建立可预测的时间模型 G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 避免全堆扫描——Remembered Set G1把Java堆分为多个Region，就是“化整为零”。但是Region不可能是孤立的，一个对象分配在某个Region中，可以与整个Java堆任意的对象发生引用关系。在做可达性分析确定对象是否存活的时候，需要扫描整个Java堆才能保证准确性，这显然是对GC效率的极大伤害。 为了避免全堆扫描的发生，虚拟机为G1中每个Region维护了一个与之对应的Remembered Set。虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set之中。当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全堆扫描也不会有遗漏。 如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为以下几个步骤： 初始标记（Initial Marking） 仅仅只是标记一下GC Roots 能直接关联到的对象，并且修改TAMS（Nest Top Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可以的Region中创建对象，此阶段需要停顿线程，但耗时很短。 并发标记（Concurrent Marking） 从GC Root 开始对堆中对象进行可达性分析，找到存活对象，此阶段耗时较长，但可与用户程序并发执行。 最终标记（Final Marking） 为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。 筛选回收（Live Data Counting and Evacuation） 首先对各个Region中的回收价值和成本进行排序，根据用户所期望的GC 停顿是时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 GC模式G1 Young GCYoung GC主要是对Eden区进行GC，它在Eden空间耗尽时会被触发。在这种情况下，Eden空间的数据移动到Survivor空间中，如果Survivor空间不够，Eden空间的部分数据会直接晋升到年老代空间。Survivor区的数据移动到新的Survivor区中，也有部分数据晋升到老年代空间中。最终Eden空间的数据为空，GC停止工作，应用线程继续执行。 这时，我们需要考虑一个问题，如果仅仅GC 新生代对象，我们如何找到所有的根对象呢？ 老年代的所有对象都是根么？那这样扫描下来会耗费大量的时间。于是，G1引进了RSet的概念。它的全称是Remembered Set，作用是跟踪指向某个heap区内的对象引用。 在CMS中，也有RSet的概念，在老年代中有一块区域用来记录指向新生代的引用。这是一种point-out，在进行Young GC时，扫描根时，仅仅需要扫描这一块区域，而不需要扫描整个老年代。 但在G1中，并没有使用point-out，这是由于一个分区太小，分区数量太多，如果是用point-out的话，会造成大量的扫描浪费，有些根本不需要GC的分区引用也扫描了。于是G1中使用point-in来解决。point-in的意思是哪些分区引用了当前分区中的对象。这样，仅仅将这些对象当做根来扫描就避免了无效的扫描。由于新生代有多个，那么我们需要在新生代之间记录引用吗？这是不必要的，原因在于每次GC时，所有新生代都会被扫描，所以只需要记录老年代到新生代之间的引用即可。 需要注意的是，如果引用的对象很多，赋值器需要对每个引用做处理，赋值器开销会很大，为了解决赋值器开销这个问题，在G1 中又引入了另外一个概念，卡表（Card Table）。一个Card Table将一个分区在逻辑上划分为固定大小的连续区域，每个区域称之为卡。卡通常较小，介于128到512字节之间。Card Table通常为字节数组，由Card的索引（即数组下标）来标识每个分区的空间地址。默认情况下，每个卡都未被引用。当一个地址空间被引用时，这个地址空间对应的数组索引的值被标记为”0″，即标记为脏被引用，此外RSet也将这个数组下标记录下来。一般情况下，这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。 Young GC 阶段： 阶段1：根扫描静态和本地对象被扫描 阶段2：更新RS处理dirty card队列更新RS 阶段3：处理RS检测从年轻代指向年老代的对象 阶段4：对象拷贝拷贝存活的对象到survivor/old区域 阶段5：处理引用队列软引用，弱引用，虚引用处理 G1 Mix GCMix GC是伴随着Young GC一起发生的。 Mix GC不仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的老年代分区。 它的GC步骤分2步： 全局并发标记（global concurrent marking） 拷贝存活对象（evacuation） 在进行Mix GC之前，会先进行global concurrent marking（全局并发标记）。 global concurrent marking的执行过程是怎样的呢？ 在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为五个步骤： Phase Description (1) Initial Mark(Stop the World Event)初始标记 This is a stop the world event. With G1, it is piggybacked on a normal young GC. Mark survivor regions (root regions) which may have references to objects in old generation.是STW的事件，并且依赖于young GC的发生。标记survivor regions作为root regions，因为它可能有指向老年代的引用。 (2) Root Region Scanningroot region 扫描 Scan survivor regions for references into the old generation. This happens while the application continues to run. The phase must be completed before a young GC can occur.扫描survivor regions 中指向 old generation 的引用。同时，应用还在继续执行。这个阶段必须在young GC发生之前完成。 (3) Concurrent Marking并发标记 Find live objects over the entire heap. This happens while the application is running. This phase can be interrupted by young generation garbage collections.找到整个heap 中存活的对象。同时，应用程序继续执行。这个阶段可以被young GC中断。 (4) Remark(Stop the World Event)最终标记 Completes the marking of live object in the heap. Uses an algorithm called snapshot-at-the-beginning (SATB) which is much faster than what was used in the CMS collector.使用SATB算法完成heap中活对象的标记。 (5) Cleanup(Stop the World Event and Concurrent) - Performs accounting on live objects and completely free regions. (Stop the world)- Scrubs the Remembered Sets. (Stop the world)- Reset the empty regions and return them to the free list. (Concurrent)- 计算存活对象和完全空闲的regions。- 重置remember set。 - 重置空闲regions，并放入空闲列表中。 () Copying(Stop the World Event)* These are the stop the world pauses to evacuate or copy live objects to new unused regions. This can be done with young generation regions which are logged as [GC pause (young)]. Or both young and old generation regions which are logged as [GC Pause (mixed)].计算并拷贝存活对象到新的regions中。这个阶段可能发生在yong GC 和mixed GC 中。 三色标记算法 提到并发标记，我们不得不了解并发标记的三色标记算法。它是描述追踪式回收器的一种有用的方法，利用它可以推演回收器的正确性。 首先，我们将对象分成三种类型的。 黑色:根对象，或者该对象与它的子对象都被扫描 灰色:对象本身被扫描,但还没扫描完该对象中的子对象 白色:未被扫描对象，扫描完成所有对象之后，最终为白色的为不可达对象，即垃圾对象 当GC开始扫描对象时，按照如下图步骤进行对象的扫描： 根对象被置为黑色，子对象被置为灰色。 继续由灰色遍历,将已扫描了子对象的对象置为黑色。 遍历了所有可达的对象后，所有可达的对象都变成了黑色。不可达的对象即为白色，需要被清理。 这看起来很美好，但是如果在标记过程中，应用程序也在运行，那么对象的指针就有可能改变。这样的话，我们就会遇到一个问题：对象丢失问题 我们看下面一种情况，当垃圾收集器扫描到下面情况时： 这时候应用程序执行了以下操作： A.c=CB.c=null 这样，对象的状态图变成如下情形： 这时候垃圾收集器再标记扫描的时候就会下图成这样： 很显然，此时C是白色，被认为是垃圾需要清理掉，显然这是不合理的。那么我们如何保证应用程序在运行的时候，GC标记的对象不丢失呢？有如下2中可行的方式： 在插入的时候记录对象 在删除的时候记录对象 刚好这对应CMS和G1的2种不同实现方式： 在CMS采用的是增量更新（Incremental update），只要在写屏障（write barrier）里发现要有一个白对象的引用被赋值到一个黑对象 的字段里，那就把这个白对象变成灰色的。即插入的时候记录下来。 在G1中，使用的是STAB（snapshot-at-the-beginning）的方式，删除的时候记录所有的对象，它有3个步骤： 1，在开始标记的时候生成一个快照图标记存活对象 2，在并发标记的时候所有被改变的对象入队（在write barrier里把所有旧的引用所指向的对象都变成非白的） 3，可能存在游离的垃圾，将在下次被收集 这样，G1到现在可以知道哪些老的分区可回收垃圾最多。 当全局并发标记完成后，在某个时刻，就开始了Mix GC。这些垃圾回收被称作“混合式”是因为他们不仅仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的分区。混合式垃圾收集如下图： 混合式GC也是采用的复制的清理策略，当GC完成后，会重新释放空间。 至此，混合式GC告一段落了。下一小节我们讲进入调优实践。 G1 Full GC如果对象内存分配速度过快，mixed gc来不及回收，导致老年代被填满，就会触发一次full gc，G1的full gc算法就是单线程执行的serial old gc，会导致异常长时间的暂停时间，需要进行不断的调优，尽可能的避免full gc. 关键技术Remember Set和Card TableRS(Remember Set)是一种抽象概念，用于记录从非收集部分指向收集部分的指针的集合。在传统的分代垃圾回收算法里面，RS(Remember Set)被用来记录分代之间的指针。在G1回收器里面，RS被用来记录从其他Region指向一个Region的指针情况。因此，一个Region就会有一个RS。这种记录可以带来一个极大的好处：在回收一个Region的时候不需要执行全堆扫描，只需要检查它的RS就可以找到外部引用，而这些引用就是initial mark的根之一。 那么，如果一个线程修改了Region内部的引用，就必须要去通知RS，更改其中的记录。为了达到这种目的，G1回收器引入了一种新的结构，CT(Card Table)——卡表。每一个Region，又被分成了固定大小的若干张卡(Card)。每一张卡，都用一个Byte来记录是否修改过。卡表即这些byte的集合。实际上，如果把RS理解成一个概念模型，那么CT就可以说是RS的一种实现方式。 从第一感觉，或者出于直觉的考虑，使用一个bit来记录一张卡是否被修改过，就已经足够了。而使用一个byte会造成更多的空间开销。但是实际上，使用一个byte来记录一张卡是否被修改过，会比使用一个bit来记录效率更高。更多细节参阅资料3。 在RS的修改上也会遇到并发的问题。因为一个Region可能有多个线程在并发修改，因此它们也会并发修改RS。为了避免这样一种冲突，G1垃圾回收器进一步把RS划分成了多个哈希表。每一个线程都在各自的哈希表里面修改。最终，从逻辑上来说，RS就是这些哈希表的集合。哈希表是实现RS的一种通常的方式之一。它有一个极大的好处就是能够去除重复。这意味着，RS的大小将和修改的指针数量相当。而在不去重的情况下，RS的数量和写操作的数量相当。 整个关系如下： Remember Set 图中RS的虚线表名的是，RS并不是一个和Card Table独立的，不同的数据结构，而是指RS是一个概念模型。实际上，Card Table是RS的一种实现方式。 Remember Set的写屏障写屏障是指，在改变特定内存的值（实际上也就是写入内存）的时候额外执行的一些动作。在大多数的垃圾回收算法中，都利用到了写屏障。写屏障通常用于在运行时探测并记录回收相关指针(interesting pointer)，在回收器只回收堆中部分区域的时候，任何来自该区域外的指针都需要被写屏障捕获，这些指针将会在垃圾回收的时候作为标记开始的根。JAVA使用的其余的分代的垃圾回收器，都有写屏障。举例来说，每一次将一个老年代对象的引用修改为指向年轻代对象，都会被写屏障捕获，并且记录下来。因此在年轻代回收的时候，就可以避免扫描整个老年代来查找根。 G1垃圾回收器的写屏障和RS是相辅相成的，也就是记录Region内部的指针。这种记录发生在写操作之后。对于一个写屏障来说，过滤掉不必要的写操作是十分有必要的。这种过滤既能加快赋值器的速度，也能减轻回收器的负担。G1垃圾回收器采用的双重过滤 过滤掉同一个Region内部引用； 过滤掉空引用； 过滤掉这两个部分之后，可以使RS的大小大大减小。 G1的垃圾回收器的写屏障使用一种两级的log buffer结构： global set of filled buffer：所有线程共享的一个全局的，存放填满了的log buffer的集合； thread log buffer：每个线程自己的log buffer。所有的线程都会把写屏障的记录先放进去自己的log buffer中，装满了之后，就会把log buffer放到 global set of filled buffer中，而后再申请一个log buffer； Collect SetCollect Set(CSet)是指，在Evacuation阶段，由G1垃圾回收器选择的待回收的Region集合。G1垃圾回收器的软实时的特性就是通过CSet的选择来实现的。对应于算法的两种模式fully-young generational mode和partially-young mode，CSet的选择可以分成两种： 在fully-young generational mode下：顾名思义，该模式下CSet将只包含young的Region。G1将调整young的Region的数量来匹配软实时的目标； 在partially-young mode下：该模式会选择所有的young region，并且选择一部分的old region。old region的选择将依据在Marking cycle phase中对存活对象的计数。G1选择存活对象最少的Region进行回收。 SATB(snapshot-at-the-beginning)SATB(snapshot-at-the-beginning)，是最开始用于实时垃圾回收器的一种技术。G1垃圾回收器使用该技术在标记阶段记录一个存活对象的快照(“logically takes a snapshot of the set of live objects in the heap at the start of marking cycle”)。然而在并发标记阶段，应用可能修改了原本的引用，比如删除了一个原本的引用。这就会导致并发标记结束之后的存活对象的快照和SATB不一致。G1是通过在并发标记阶段引入一个写屏障来解决这个问题的：每当存在引用更新的情况，G1会将修改之前的值写入一个log buffer（这个记录会过滤掉原本是空引用的情况），在最终标记(final marking phase)阶段扫描SATB，修正SATB的误差。 SATB的log buffer如RS的写屏障使用的log buffer一样，都是两级结构，作用机制也是一样的。 细节可以参阅资料2，6 Marking bitmaps和TAMSMarking bitmap是一种数据结构，其中的每一个bit代表的是一个可用于分配给对象的起始地址。举例来说： 其中addrN代表的是一个对象的起始地址。绿色的块代表的是在该起始地址处的对象是存活对象，而其余白色的块则代表了垃圾对象。G1使用了两个bitmap，一个叫做previous bitmap，另外一个叫做next bitmap。previous bitmap记录的是上一次的标记阶段完成之后的构造的bitmap；next bitmap则是当前正在标记阶段正在构造的bitmap。在当前标记阶段结束之后，当前标记的next bitmap就变成了下一次标记阶段的previous bitmap。TAMS(top at mark start)变量，是一对用于区分在标记阶段新分配对象的变量，分别被称为previous TAMS和next TAMS。在previous TAMS和next TAMS之间的对象则是本次标记阶段时候新分配的对象。如图： 白色region代表的是空闲空间，绿色region代表是存活对象，橙色region代表的在此次标记阶段新分配的对象。注意的是，在橙色区域的对象，并不能确保它们都事实上是存活的。 算法详解整个算法可以分成两大部分： Marking cycle phase：标记阶段，该阶段是不断循环进行的； Evacuation phase：该阶段是负责把一部分region的活对象拷贝到空Region里面去，然后回收原本的Region空间，该阶段是STW(stop-the-world)的； 而算法也可以分成两种模式： fully-young generational mode：有时候也会被称为young GC，该模式只会回收young region，算法是通过调整young region的数量来达到软实时目标的； partially-young mode：也被称为Mixed GC，该阶段会回收young region和old region，算法通过调整old region的数量来达到软实时目标； 有趣的地方是不论处在何种模式之下，yong region都在被回收的范围内。而old region只能期望于Mixed GC。但是，如同在CMS垃圾回收器中遇到的困境一样，Mixed GC可能来不及回收old region。也就说，在需要分配老年代的对象的时候，并没有足够的空间。这个时候就只能触发一次full GC。 算法会自动在young GC和mixed GC之间切换，并且定期触发Marking cycle phase。HotSpot的G1实现允许指定一个参数InitiatingHeapOccupancyPercent，在达到该参数的情况下，就会执行marking cycle phase。 算法并不使用在对象头增加字段来标记该对象，而是采用bitmap的方式来记录一个对象被标记的情况。这种记录方法的好处就是在使用这些标记信息的时候，仅仅需要扫描bitmap而已。G1统计一个region的存活的对象，就是依赖于bitmap的标记。 调优实践MaxGCPauseMillis调优 前面介绍过使用GC的最基本的参数： -XX:+UseG1GC -Xmx32g -XX:MaxGCPauseMillis=200 前面2个参数都好理解，后面这个MaxGCPauseMillis参数该怎么配置呢？这个参数从字面的意思上看，就是允许的GC最大的暂停时间。G1尽量确保每次GC暂停的时间都在设置的MaxGCPauseMillis范围内。 那G1是如何做到最大暂停时间的呢？这涉及到另一个概念，CSet(collection set)。它的意思是在一次垃圾收集器中被收集的区域集合。 Young GC：选定所有新生代里的region。通过控制新生代的region个数来控制young GC的开销。 Mixed GC：选定所有新生代里的region，外加根据global concurrent marking统计得出收集收益高的若干老年代region。在用户指定的开销目标范围内尽可能选择收益高的老年代region。 在理解了这些后，我们再设置最大暂停时间就好办了。 首先，我们能容忍的最大暂停时间是有一个限度的，我们需要在这个限度范围内设置。但是应该设置的值是多少呢？我们需要在吞吐量跟MaxGCPauseMillis之间做一个平衡。如果MaxGCPauseMillis设置的过小，那么GC就会频繁，吞吐量就会下降。如果MaxGCPauseMillis设置的过大，应用程序暂停时间就会变长。G1的默认暂停时间是200毫秒，我们可以从这里入手，调整合适的时间。 其他调优参数 -XX:G1HeapRegionSize=n 设置的 G1 区域的大小。值是 2 的幂，范围是 1 MB 到 32 MB 之间。目标是根据最小的 Java 堆大小划分出约 2048 个区域。 -XX:ParallelGCThreads=n 设置 STW 工作线程数的值。将 n 的值设置为逻辑处理器的数量。n 的值与逻辑处理器的数量相同，最多为 8。 如果逻辑处理器不止八个，则将 n 的值设置为逻辑处理器数的 5/8 左右。这适用于大多数情况，除非是较大的 SPARC 系统，其中 n 的值可以是逻辑处理器数的 5/16 左右。 -XX:ConcGCThreads=n 设置并行标记的线程数。将 n 设置为并行垃圾回收线程数 (ParallelGCThreads) 的 1/4 左右。 -XX:InitiatingHeapOccupancyPercent=45 设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。 避免使用以下参数： 避免使用 -Xmn 选项或 -XX:NewRatio 等其他相关选项显式设置年轻代大小。固定年轻代的大小会覆盖暂停时间目标。 触发Full GC 在某些情况下，G1触发了Full GC，这时G1会退化使用Serial收集器来完成垃圾的清理工作，它仅仅使用单线程来完成GC工作，GC暂停时间将达到秒级别的。整个应用处于假死状态，不能处理任何请求，我们的程序当然不希望看到这些。那么发生Full GC的情况有哪些呢？ 并发模式失败 G1启动标记周期，但在Mix GC之前，老年代就被填满，这时候G1会放弃标记周期。这种情形下，需要增加堆大小，或者调整周期（例如增加线程数-XX:ConcGCThreads等）。 晋升失败或者疏散失败 G1在进行GC的时候没有足够的内存供存活对象或晋升对象使用，由此触发了Full GC。可以在日志中看到(to-space exhausted)或者（to-space overflow）。解决这种问题的方式是： a,增加 -XX:G1ReservePercent 选项的值（并相应增加总的堆大小），为“目标空间”增加预留内存量。 b,通过减少 -XX:InitiatingHeapOccupancyPercent 提前启动标记周期。 c,也可以通过增加 -XX:ConcGCThreads 选项的值来增加并行标记线程的数目。 巨型对象分配失败 当巨型对象找不到合适的空间进行分配时，就会启动Full GC，来释放空间。这种情况下，应该避免分配大量的巨型对象，增加内存或者增大-XX:G1HeapRegionSize，使巨型对象不再是巨型对象。 由于篇幅有限，G1还有很多调优实践，在此就不一一列出了，大家在平常的实践中可以慢慢探索。最后，期待java 9能正式发布，默认使用G1为垃圾收集器的java性能会不会又提高呢？ 使用场景The first focus of G1 is to provide a solution for users running applications that require large heaps with limited GC latency. This means heap sizes of around 6GB or larger, and stable and predictable pause time below 0.5 seconds. Applications running today with either the CMS or the ParallelOldGC garbage collector would benefit switching to G1 if the application has one or more of the following traits. Full GC durations are too long or too frequent. The rate of object allocation rate or promotion varies significantly. Undesired long garbage collection or compaction pauses (longer than 0.5 to 1 second) 总结 regions 划分：Eden、Survivor、Old、Humongous young gc 和 mixed gc remember set、card table、satb(snapshot-at-the-beginning) 参考https://crowhawk.github.io/2017/08/15/jvm_3/http://blog.jobbole.com/109170/https://www.jianshu.com/p/8bd15969a641http://www.importnew.com/27793.htmlhttps://tech.meituan.com/g1.htmlhttp://www.oracle.com/technetwork/tutorials/tutorials-1876574.htmlhttps://blog.csdn.net/renfufei/article/details/41897113https://www.jianshu.com/p/870abddaba41]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机字节码执行引擎]]></title>
    <url>%2Fjava%2Fjvm%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[多态性实现机制——静态分派与动态分派方法解析Class 文件的编译过程中不包含传统编译中的连接步骤，一切方法调用在 Class 文件里面存储的都只是符号引用，而不是方法在实际运行时内存布局中的入口地址。这个特性给 Java 带来了更强大的动态扩展能力，使得可以在类运行期间才能确定某些目标方法的直接引用，称为动态连接，也有一部分方法的符号引用在类加载阶段或第一次使用时转化为直接引用，这种转化称为静态解析。这在前面的“Java 内存区域与内存溢出”一文中有提到。 静态解析成立的前提是：方法在程序真正执行前就有一个可确定的调用版本，并且这个方法的调用版本在运行期是不可改变的。换句话说，调用目标在编译器进行编译时就必须确定下来，这类方法的调用称为解析。 在 Java 语言中，符合“编译器可知，运行期不可变”这个要求的方法主要有静态方法和私有方法两大类，前者与类型直接关联，后者在外部不可被访问，这两种方法都不可能通过继承或别的方式重写出其他的版本，因此它们都适合在类加载阶段进行解析。 Java 虚拟机里共提供了四条方法调用字节指令，分别是： invokestatic：调用静态方法。 invokespecial：调用实例构造器方法、私有方法和父类方法。 invokevirtual：调用所有的虚方法。 invokeinterface：调用接口方法，会在运行时再确定一个实现此接口的对象。 只要能被 invokestatic 和 invokespecial 指令调用的方法，都可以在解析阶段确定唯一的调用版本，符合这个条件的有静态方法、私有方法、实例构造器和父类方法四类，它们在类加载时就会把符号引用解析为该方法的直接引用。这些方法可以称为非虚方法（还包括 final 方法），与之相反，其他方法就称为虚方法（final 方法除外）。这里要特别说明下 final 方法，虽然调用 final 方法使用的是 invokevirtual 指令，但是由于它无法覆盖，没有其他版本，所以也无需对方发接收者进行多态选择。Java 语言规范中明确说明了 final 方法是一种非虚方法。 解析调用一定是个静态过程，在编译期间就完全确定，在类加载的解析阶段就会把涉及的符号引用转化为可确定的直接引用，不会延迟到运行期再去完成。而分派调用则可能是静态的也可能是动态的，根据分派依据的宗量数（方法的调用者和方法的参数统称为方法的宗量）又可分为单分派和多分派。两类分派方式两两组合便构成了静态单分派、静态多分派、动态单分派、动态多分派四种分派情况。 静态分派所有依赖静态类型来定位方法执行版本的分派动作，都称为静态分派，静态分派的最典型应用就是多态性中的方法重载。静态分派发生在编译阶段，因此确定静态分配的动作实际上不是由虚拟机来执行的。下面通过一段方法重载的示例程序来更清晰地说明这种分派机制： 123456789101112131415161718192021222324252627class Human&#123; &#125; class Man extends Human&#123; &#125; class Woman extends Human&#123; &#125; public class StaticPai&#123; public void say(Human hum)&#123; System.out.println("I am human"); &#125; public void say(Man hum)&#123; System.out.println("I am man"); &#125; public void say(Woman hum)&#123; System.out.println("I am woman"); &#125; public static void main(String[] args)&#123; Human man = new Man(); Human woman = new Woman(); StaticPai sp = new StaticPai(); sp.say(man); sp.say(woman); &#125; &#125; 上面代码的执行结果如下： 12I am humanI am human 以上结果的得出应该不难分析。在分析为什么会选择参数类型为 Human 的重载方法去执行之前，先看如下代码： 1Human man = new Man（）; 我们把上面代码中的“Human”称为变量的静态类型，后面的“Man”称为变量的实际类型。静态类型和实际类型在程序中都可以发生一些变化，区别是静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且最终的静态类型是在编译期可知的，而实际类型变化的结果在运行期才可确定。 回到上面的代码分析中，在调用 say()方法时，方法的调用者（回忆上面关于宗量的定义，方法的调用者属于宗量）都为 sp 的前提下，使用哪个重载版本，完全取决于传入参数的数量和数据类型（方法的参数也是属于宗量）。代码中刻意定义了两个静态类型相同、实际类型不同的变量，可见编译器（不是虚拟机，因为如果是根据静态类型做出的判断，那么在编译期就确定了）在重载时是通过参数的静态类型而不是实际类型作为判定依据的。并且静态类型是编译期可知的，所以在编译阶段，javac 编译器就根据参数的静态类型决定使用哪个重载版本。这就是静态分派最典型的应用。 动态分派动态分派与多态性的另一个重要体现——方法覆写有着很紧密的关系。向上转型后调用子类覆写的方法便是一个很好地说明动态分派的例子。这种情况很常见，因此这里不再用示例程序进行分析。很显然，在判断执行父类中的方法还是子类中覆盖的方法时，如果用静态类型来判断，那么无论怎么进行向上转型，都只会调用父类中的方法，但实际情况是，根据对父类实例化的子类的不同，调用的是不同子类中覆写的方法，很明显，这里是要根据变量的实际类型来分派方法的执行版本的。而实际类型的确定需要在程序运行时才能确定下来，这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。 单分派和多分派前面给出：方法的接受者（亦即方法的调用者）与方法的参数统称为方法的宗量。单分派是根据一个宗量对目标方法进行选择，多分派是根据多于一个宗量对目标方法进行选择。 为了方便理解，下面给出一段示例代码： 12345678910111213141516171819202122232425262728293031class Eat&#123; &#125; class Drink&#123; &#125; class Father&#123; public void doSomething(Eat arg)&#123; System.out.println("爸爸在吃饭"); &#125; public void doSomething(Drink arg)&#123; System.out.println("爸爸在喝水"); &#125; &#125; class Child extends Father&#123; public void doSomething(Eat arg)&#123; System.out.println("儿子在吃饭"); &#125; public void doSomething(Drink arg)&#123; System.out.println("儿子在喝水"); &#125; &#125; public class SingleDoublePai&#123; public static void main(String[] args)&#123; Father father = new Father(); Father child = new Child(); father.doSomething(new Eat()); child.doSomething(new Drink()); &#125; &#125; 运行结果应该很容易预测到，如下： 12爸爸在吃饭儿子在喝水 我们首先来看编译阶段编译器的选择过程，即静态分派过程。这时候选择目标方法的依据有两点：一是方法的接受者（即调用者）的静态类型是 Father 还是 Child，二是方法参数类型是 Eat 还是 Drink。因为是根据两个宗量进行选择，所以 Java 语言的静态分派属于多分派类型。 再来看运行阶段虚拟机的选择，即动态分派过程。由于编译期已经了确定了目标方法的参数类型（编译期根据参数的静态类型进行静态分派），因此唯一可以影响到虚拟机选择的因素只有此方法的接受者的实际类型是 Father 还是 Child。因为只有一个宗量作为选择依据，所以 Java 语言的动态分派属于单分派类型。 根据以上论证，我们可以总结如下：目前的Java 语言（JDK1.6）是一门静态多分派、动态单分派的语言。 虚拟机动态分派的实现其实上面的叙述已经把虚拟机重写与重载的本质讲清楚了，那么Java虚拟机是如何做到这点的呢？ 由于动态分派是非常频繁的操作，实际实现中不可能真正如此实现。Java虚拟机是通过“稳定优化”的手段——在方法区中建立一个虚方法表（Virtual Method Table），通过使用方法表的索引来代替元数据查找以提高性能。虚方法表中存放着各个方法的实际入口地址（由于Java虚拟机自己建立并维护的方法表，所以没有必要使用符号引用，那不是跟自己过不去嘛），如果子类没有覆盖父类的方法，那么子类的虚方法表里面的地址入口与父类是一致的；如果重写父类的方法，那么子类的方法表的地址将会替换为子类实现版本的地址。 方法表是在类加载的连接阶段（验证、准备、解析）进行初始化，准备了子类的初始化值后，虚拟机会把该类的虚方法表也进行初始化。 动态类型语言支持https://my.oschina.net/itblog/blog/538748 https://blog.souche.com/invokedynamic/]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SPI和DriverManager]]></title>
    <url>%2Fjava%2FSPI%E5%92%8CDriverManager%2F</url>
    <content type="text"><![CDATA[Java中SPI机制深入及源码解析真正理解线程上下文类加载器（多案例分析）]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spi</tag>
        <tag>driver manager</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LockSupport]]></title>
    <url>%2Fjava%2FLockSupport%2F</url>
    <content type="text"><![CDATA[LockSupport 用法简介LockSupport是用来创建锁和其他同步类的基本线程阻塞原语。LockSupport 提供park()和unpark()方法实现阻塞线程和解除线程阻塞，LockSupport和每个使用它的线程都与一个许可(permit)关联。permit相当于1，0的开关，默认是0，调用一次unpark就加1变成1，调用一次park会消费permit, 也就是将1变成0，同时park立即返回。再次调用park会变成block（因为permit为0了，会阻塞在这里，直到permit变为1）, 这时调用unpark会把permit置为1。每个线程都有一个相关的permit, permit最多只有一个，重复调用unpark也不会积累。 park()和unpark()不会有 “Thread.suspend和Thread.resume所可能引发的死锁” 问题，由于许可的存在，调用 park 的线程和另一个试图将其 unpark 的线程之间的竞争将保持活性。 如果调用线程被中断，则park方法会返回。同时park也拥有可以设置超时时间的版本。 三种形式的 park 还各自支持一个 blocker 对象参数。此对象在线程受阻塞时被记录，以允许监视工具和诊断工具确定线程受阻塞的原因。（这样的工具可以使用方法 getBlocker(java.lang.Thread) 访问 blocker。）建议最好使用这些形式，而不是不带此参数的原始形式。在锁实现中提供的作为 blocker 的普通参数是 this。看下线程dump的结果来理解blocker的作用。 LockSupport 源码解读 LockSupport中主要的两个成员变量： 123// Hotspot implementation via intrinsics APIprivate static final sun.misc.Unsafe UNSAFE;private static final long parkBlockerOffset; 再来看parkBlockerOffset:parkBlocker就是第一部分说到的用于记录线程被谁阻塞的，用于线程监控和分析工具来定位原因的，可以通过LockSupport的getBlocker获取到阻塞的对象。 12345678static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; tk = Thread.class; parkBlockerOffset = UNSAFE.objectFieldOffset (tk.getDeclaredField("parkBlocker")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125; 从这个静态语句块可以看的出来，先是通过反射机制获取Thread类的parkBlocker字段对象。然后通过sun.misc.Unsafe对象的objectFieldOffset方法获取到parkBlocker在内存里的偏移量，parkBlockerOffset的值就是这么来的. JVM的实现可以自由选择如何实现Java对象的“布局”，也就是在内存里Java对象的各个部分放在哪里，包括对象的实例字段和一些元数据之类。 sun.misc.Unsafe里关于对象字段访问的方法把对象布局抽象出来，它提供了objectFieldOffset()方法用于获取某个字段相对 Java对象的“起始地址”的偏移量，也提供了getInt、getLong、getObject之类的方法可以使用前面获取的偏移量来访问某个Java 对象的某个字段。 为什么要用偏移量来获取对象？干吗不要直接写个get，set方法。多简单？仔细想想就能明白，这个parkBlocker就是在线程处于阻塞的情况下才会被赋值。线程都已经阻塞了，如果不通过这种内存的方法，而是直接调用线程内的方法，线程是不会回应调用的。 2.LockSupport的方法： 可以看到，LockSupport中主要是park和unpark方法以及设置和读取parkBlocker方法。 1234private static void setBlocker(Thread t, Object arg) &#123; // Even though volatile, hotspot doesn't need a write barrier here. UNSAFE.putObject(t, parkBlockerOffset, arg); &#125; 对给定线程t的parkBlocker赋值。 12345public static Object getBlocker(Thread t) &#123; if (t == null) throw new NullPointerException(); return UNSAFE.getObjectVolatile(t, parkBlockerOffset);&#125; 从线程t中获取它的parkBlocker对象，即返回的是阻塞线程t的Blocker对象。 接下来主查两类方法，一类是阻塞park方法，一类是解除阻塞unpark方法 阻塞线程 park() 123public static void park() &#123; UNSAFE.park(false, 0L);&#125; 调用native方法阻塞当前线程。 parkNanos(long nanos) 1234public static void parkNanos(long nanos) &#123; if (nanos &gt; 0) UNSAFE.park(false, nanos);&#125; 阻塞当前线程，最长不超过nanos纳秒，返回条件在park()的基础上增加了超时返回。 parkUntil(long deadline) 123public static void parkUntil(long deadline) &#123; UNSAFE.park(true, deadline);&#125; 阻塞当前线程，知道deadline时间（deadline - 毫秒数）。 JDK1.6引入这三个方法对应的拥有Blocker版本。 park(Object blocker) 123456public static void park(Object blocker) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null);&#125; 1) 记录当前线程等待的对象（阻塞对象）；2) 阻塞当前线程；3) 当前线程等待对象置为null。 parkNanos(Object blocker, long nanos) 12345678public static void parkNanos(Object blocker, long nanos) &#123; if (nanos &gt; 0) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, nanos); setBlocker(t, null); &#125;&#125; 阻塞当前线程，最长等待时间不超过nanos毫秒，同样，在阻塞当前线程的时候做了记录当前线程等待的对象操作。 parkUntil(Object blocker, long deadline) 123456public static void parkUntil(Object blocker, long deadline) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(true, deadline); setBlocker(t, null);&#125; 阻塞当前线程直到deadline时间，相同的，也做了阻塞前记录当前线程等待对象的操作。 唤醒线程 unpark(Thread thread) 1234public static void unpark(Thread thread) &#123; if (thread != null) UNSAFE.unpark(thread);&#125; 唤醒处于阻塞状态的线程Thread。 Locksupport 底层在Linux系统下，是用的Posix线程库pthread中的mutex（互斥量），condition（条件变量）来实现的。mutex和condition保护了一个_counter的变量，当park时，这个变量被设置为0，当unpark时，这个变量被设置为1。 看看Locksupport的源码中的注释可知，Locksupport是实现别的锁和同步类的基本原语。 123456789101112131415class Parker : public os::PlatformParker &#123;private: volatile int _counter ; ...public: void park(bool isAbsolute, jlong time); void unpark(); ...&#125;class PlatformParker : public CHeapObj&lt;mtInternal&gt; &#123; protected: pthread_mutex_t _mutex [1] ; pthread_cond_t _cond [1] ; ...&#125; 可以看到Parker类实际上用Posix的mutex，condition来实现的。在Parker类里的_counter字段，就是用来记录“许可”的。 park 过程 当调用park时，先尝试能否直接拿到“许可”，即_counter&gt;0时，如果成功，则把_counter设置为0，并返回： 1234567891011void Parker::park(bool isAbsolute, jlong time) &#123; // Ideally we'd do something useful while spinning, such // as calling unpackTime(). // Optional fast-path check: // Return immediately if a permit is available. // We depend on Atomic::xchg() having full barrier semantics // since we are doing a lock-free update to _counter. if (Atomic::xchg(0, &amp;_counter) &gt; 0) return; 如果不成功，则构造一个ThreadBlockInVM，然后检查_counter是不是&gt;0，如果是，则把_counter设置为0，unlock mutex并返回： 1234ThreadBlockInVM tbivm(jt); if (_counter &gt; 0) &#123; // no wait needed _counter = 0; status = pthread_mutex_unlock(_mutex); 否则，再判断等待的时间，然后再调用pthread_cond_wait函数等待，如果等待返回，则把_counter设置为0，unlock mutex并返回： 1234567if (time == 0) &#123; status = pthread_cond_wait (_cond, _mutex) ; &#125; _counter = 0 ; status = pthread_mutex_unlock(_mutex) ; assert_status(status == 0, status, "invariant") ; OrderAccess::fence(); unpark 过程 当unpark时，则简单多了，直接设置_counter为1，再unlock mutex返回。如果_counter之前的值是0，则还要调用pthread_cond_signal唤醒在park中等待的线程： 1234567891011121314151617181920212223void Parker::unpark() &#123; int s, status ; status = pthread_mutex_lock(_mutex); assert (status == 0, "invariant") ; s = _counter; _counter = 1; if (s &lt; 1) &#123; if (WorkAroundNPTLTimedWaitHang) &#123; status = pthread_cond_signal (_cond) ; assert (status == 0, "invariant") ; status = pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; &#125; else &#123; status = pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; status = pthread_cond_signal (_cond) ; assert (status == 0, "invariant") ; &#125; &#125; else &#123; pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; &#125; &#125; LockSupport的特性先释放许可，再获取许可1234567public static void main(String[] args)&#123; Thread thread = Thread.currentThread(); LockSupport.unpark(thread);//释放许可 LockSupport.park();// 获取许可 System.out.println("b");&#125; 不可重入123456789101112public static void main(String[] args) throws Exception&#123; Thread thread = Thread.currentThread(); LockSupport.unpark(thread); System.out.println("a"); LockSupport.park(); System.out.println("b"); LockSupport.park(); System.out.println("c");&#125; 这段代码打印出a和b，不会打印c，因为第二次调用park的时候，线程无法获取许可出现死锁。 中断响应LockSupport.part()方法是响应中断地，当线程中断后，会从park方法返回执行后续逻辑，所以，LockSupport中的对中断地响应可以灵活控制。1234567891011121314151617181920212223242526272829/** * @author joyo * @date 2018/4/16 */public class LockSupportInterruptTest &#123; public static void main(String[] args) throws InterruptedException &#123; ReentrantLock lock = new ReentrantLock(); Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; lock.lock(); try &#123; LockSupport.park(); System.out.println("come back here"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;); thread.start(); Thread.sleep(2000); thread.interrupt(); &#125;&#125; 最终输出结果：come back here，而不是打印异常栈。 而Object.wait()方法并没有这个特性，会直接抛出中断异常。 LockSupport 和 Object的区别两者区别总结如下： Object.wait和notify都是针对对象的，notify实际上是不知道唤醒具体哪个线程的，而Locksupport支持指定线程唤醒 实现原理不同，Locksupport是基于Unsafe.park来实现的。具体可以见参考资料3 Locksupport功能更加强大些： 基于“许可”的同步实现，提供parkBlocker来监视锁的持有等。而Object.wait方法来完成同步，需要依赖监视器锁。 JDK1.6之后针对synchrnized引入了分级的锁，根据后面的代码示例发现两类同步原语的开销是差不多的 两者相同点： park和wait都会阻塞线程，释放锁 虽然响应中断行动不同，但是都会更改中断标志位 功能上其实相近，但是为了易用性和功能妥协，park和unpark基本可以替代Object.wait和notify等 从区别上来看可知，使用Locksupport能更加精细、灵活地控制线程的同步，利于实现各种同步工具和锁。精细体现在针对线程的同步控制，灵活体现在通过“许可”获取的方式来保证活性。 参考https://segmentfault.com/a/1190000008420938https://www.jianshu.com/p/e3afe8ab8364https://blog.csdn.net/u013851082/article/details/70242395https://kaimingwan.com/post/java/javabing-fa-yu-suo/liao-liao-locksupport]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>LockSupport</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2Fjava%2Fdatastructure%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal 作为 Thread 中的 ThreadLocalMap 的 key 。 Example123456789101112131415161718192021222324252627public class ThreadLocalExample &#123; public static class MyRunnable implements Runnable &#123; private ThreadLocal threadLocal = new ThreadLocal(); @Override public void run() &#123; threadLocal.set((int) (Math.random() * 100D)); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; &#125; System.out.println(threadLocal.get()); &#125; &#125; public static void main(String[] args) &#123; MyRunnable sharedRunnableInstance = new MyRunnable(); Thread thread1 = new Thread(sharedRunnableInstance); Thread thread2 = new Thread(sharedRunnableInstance); thread1.start(); thread2.start(); &#125;&#125; get and Set123456789101112131415161718192021222324252627282930313233343536373839/** * Sets the current thread's copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the &#123;@link #initialValue&#125; * method to set the values of thread-locals. * * @param value the value to be stored in the current thread's copy of * this thread-local. */public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;/** * Returns the value in the current thread's copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread's value of this thread-local*/public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; hash冲突当set发生hash冲突时，获取数组中下一个可插入的位置：12345678910111213141516171819202122232425262728293031323334private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; // 走到这里，说明key不相等，即发生了key的冲突，通过nextIndex 获取下一个可用的位置 &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; 内存泄露ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 深入分析 ThreadLocal 内存泄漏问题ThreadLocal 内存泄露的实例分析]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis缓存]]></title>
    <url>%2Fredis%2Fredis%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[缓存穿透什么是缓存穿透？一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如DB）。如果key对应的value是一定不存在的，并且对该key并发请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。 如何避免？1：对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key对应的数据insert了之后清理缓存。2：对一定不存在的key进行过滤。可以把所有的可能存在的key放到一个大的Bitmap中，查询时通过该bitmap过滤。【感觉应该用的不多吧】 开发提示：有关布隆过滤器的相关知识，可以参考：https://en.wikipedia.org/wiki/Bloom_filter可以利用 Redis 的 Bitmaps 实现布隆过滤器，GitHub 上已经开源了类似的方案，读者可以进行参考：https://github.com/erikdubbelboer/Redis-Lua-scaling-bloom-filter 缓存雪崩什么是缓存雪崩？当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。 如何避免？ 预防 保证缓存层服务高可用性（多个节点） 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。 从缓存层面来看，不设置过期时间，每个 value 设置一个逻辑过期时间 可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存 做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期 提前演练 事后处理 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 依赖隔离组件为后端限流并降级 缓存预热缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样避免，用户请求的时候，再去加载相关的数据。 解决思路： 直接写个缓存刷新页面，上线时手工操作下。 数据量不大，可以在WEB系统启动的时候加载。 定时刷新缓存 缓存数据的淘汰缓存淘汰的策略有两种： (1) 定时去清理过期的缓存。 （2）当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂，具体用哪种方案，大家可以根据自己的应用场景来权衡。 淘汰机制 LRU TTL Redis数据淘汰机制 参考缓存穿透与缓存雪崩Redis架构之防雪崩设计：网站不宕机背后的兵法]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis事务]]></title>
    <url>%2Fredis%2Fredis%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Redis 通过 MULTI 、 DISCARD 、 EXEC 和 WATCH 四个命令来实现事务功能， 本章首先讨论使用 MULTI 、 DISCARD 和 EXEC 三个命令实现的一般事务， 然后再来讨论带有 WATCH 的事务的实现。 因为事务的安全性也非常重要， 所以本章最后通过常见的 ACID 性质对 Redis 事务的安全性进行了说明。 事务事务提供了一种“将多个命令打包， 然后一次性、按顺序地执行”的机制， 并且事务在执行的期间不会主动中断 —— 服务器在执行完事务中的所有命令之后， 才会继续处理其他客户端的其他命令。 以下是一个事务的例子， 它先以 MULTI 开始一个事务， 然后将多个命令入队到事务中， 最后由 EXEC 命令触发事务， 一并执行事务中的所有命令： 12345678910111213141516171819202122redis&gt; MULTIOKredis&gt; SET book-name &quot;Mastering C++ in 21 days&quot;QUEUEDredis&gt; GET book-nameQUEUEDredis&gt; SADD tag &quot;C++&quot; &quot;Programming&quot; &quot;Mastering Series&quot;QUEUEDredis&gt; SMEMBERS tagQUEUEDredis&gt; EXEC1) OK2) &quot;Mastering C++ in 21 days&quot;3) (integer) 34) 1) &quot;Mastering Series&quot; 2) &quot;C++&quot; 3) &quot;Programming&quot; 一个事务从开始到执行会经历以下三个阶段： 开始事务。 命令入队。 执行事务。 下文将分别介绍事务的这三个阶段。 开始事务MULTI 命令的执行标记着事务的开始： 12redis&gt; MULTIOK 这个命令唯一做的就是， 将客户端的 REDIS_MULTI 选项打开， 让客户端从非事务状态切换到事务状态。 命令入队当客户端处于非事务状态下时， 所有发送给服务器端的命令都会立即被服务器执行： 12345redis&gt; SET msg &quot;hello moto&quot;OKredis&gt; GET msg&quot;hello moto&quot; 但是， 当客户端进入事务状态之后， 服务器在收到来自客户端的命令时， 不会立即执行命令， 而是将这些命令全部放进一个事务队列里， 然后返回 QUEUED ， 表示命令已入队： 12345678redis&gt; MULTIOKredis&gt; SET msg &quot;hello moto&quot;QUEUEDredis&gt; GET msgQUEUED 以下流程图展示了这一行为： 事务队列是一个数组， 每个数组项是都包含三个属性： 要执行的命令（cmd）。 命令的参数（argv）。 参数的个数（argc）。 举个例子， 如果客户端执行以下命令： 1234567891011121314redis&gt; MULTIOKredis&gt; SET book-name &quot;Mastering C++ in 21 days&quot;QUEUEDredis&gt; GET book-nameQUEUEDredis&gt; SADD tag &quot;C++&quot; &quot;Programming&quot; &quot;Mastering Series&quot;QUEUEDredis&gt; SMEMBERS tagQUEUED 那么程序将为客户端创建以下事务队列： 数组索引 cmd argv argc 0 SET [&quot;book-name&quot;, &quot;Mastering C++ in 21 days&quot;] 2 1 GET [&quot;book-name&quot;] 1 2 SADD [&quot;tag&quot;, &quot;C++&quot;, &quot;Programming&quot;, &quot;Mastering Series&quot;] 4 3 SMEMBERS [&quot;tag&quot;] 1 执行事务前面说到， 当客户端进入事务状态之后， 客户端发送的命令就会被放进事务队列里。 但其实并不是所有的命令都会被放进事务队列， 其中的例外就是 EXEC 、 DISCARD 、 MULTI 和 WATCH 这四个命令 —— 当这四个命令从客户端发送到服务器时， 它们会像客户端处于非事务状态一样， 直接被服务器执行： 如果客户端正处于事务状态， 那么当 EXEC 命令执行时， 服务器根据客户端所保存的事务队列， 以先进先出（FIFO）的方式执行事务队列中的命令： 最先入队的命令最先执行， 而最后入队的命令最后执行。 比如说，对于以下事务队列： 数组索引 cmd argv argc 0 SET [&quot;book-name&quot;, &quot;Mastering C++ in 21 days&quot;] 2 1 GET [&quot;book-name&quot;] 1 2 SADD [&quot;tag&quot;, &quot;C++&quot;, &quot;Programming&quot;, &quot;Mastering Series&quot;] 4 3 SMEMBERS [&quot;tag&quot;] 1 程序会首先执行 SET 命令， 然后执行 GET 命令， 再然后执行 SADD 命令， 最后执行 SMEMBERS 命令。 执行事务中的命令所得的结果会以 FIFO 的顺序保存到一个回复队列中。 比如说，对于上面给出的事务队列，程序将为队列中的命令创建如下回复队列： 数组索引 回复类型 回复内容 0 status code reply OK 1 bulk reply &quot;Mastering C++ in 21 days&quot; 2 integer reply 3 3 multi-bulk reply [&quot;Mastering Series&quot;, &quot;C++&quot;, &quot;Programming&quot;] 当事务队列里的所有命令被执行完之后， EXEC 命令会将回复队列作为自己的执行结果返回给客户端， 客户端从事务状态返回到非事务状态， 至此， 事务执行完毕。 事务的整个执行过程可以用以下伪代码表示： 12345678910111213141516171819202122def execute_transaction(): # 创建空白的回复队列 reply_queue = [] # 取出事务队列里的所有命令、参数和参数数量 for cmd, argv, argc in client.transaction_queue: # 执行命令，并取得命令的返回值 reply = execute_redis_command(cmd, argv, argc) # 将返回值追加到回复队列末尾 reply_queue.append(reply) # 清除客户端的事务状态 clear_transaction_state(client) # 清空事务队列 clear_transaction_queue(client) # 将事务的执行结果返回给客户端 send_reply_to_client(client, reply_queue) 在事务和非事务状态下执行命令无论在事务状态下， 还是在非事务状态下， Redis 命令都由同一个函数执行， 所以它们共享很多服务器的一般设置， 比如 AOF 的配置、RDB 的配置，以及内存限制，等等。 不过事务中的命令和普通命令在执行上还是有一点区别的，其中最重要的两点是： 非事务状态下的命令以单个命令为单位执行，前一个命令和后一个命令的客户端不一定是同一个； 而事务状态则是以一个事务为单位，执行事务队列中的所有命令：除非当前事务执行完毕，否则服务器不会中断事务，也不会执行其他客户端的其他命令。 在非事务状态下，执行命令所得的结果会立即被返回给客户端； 而事务则是将所有命令的结果集合到回复队列，再作为 EXEC 命令的结果返回给客户端。 事务状态下的 DISCARD 、 MULTI 和 WATCH 命令除了 EXEC 之外， 服务器在客户端处于事务状态时， 不加入到事务队列而直接执行的另外三个命令是 DISCARD 、 MULTI 和 WATCH。 DISCARD 命令用于取消一个事务， 它清空客户端的整个事务队列， 然后将客户端从事务状态调整回非事务状态， 最后返回字符串 OK 给客户端， 说明事务已被取消。 Redis 的事务是不可嵌套的， 当客户端已经处于事务状态， 而客户端又再向服务器发送 MULTI 时， 服务器只是简单地向客户端发送一个错误， 然后继续等待其他命令的入队。 MULTI 命令的发送不会造成整个事务失败， 也不会修改事务队列中已有的数据。 WATCH 只能在客户端进入事务状态之前执行， 在事务状态下发送 WATCH 命令会引发一个错误， 但它不会造成整个事务失败， 也不会修改事务队列中已有的数据（和前面处理 MULTI 的情况一样）。 带 WATCH 的事务WATCH 命令用于在事务开始之前监视任意数量的键： 当调用 EXEC 命令执行事务时， 如果任意一个被监视的键已经被其他客户端修改了， 那么整个事务不再执行， 直接返回失败。 以下示例展示了一个执行失败的事务例子： 1234567891011redis&gt; WATCH nameOKredis&gt; MULTIOKredis&gt; SET name peterQUEUEDredis&gt; EXEC(nil) 以下执行序列展示了上面的例子是如何失败的： 时间 客户端 A 客户端 B T1 WATCH name T2 MULTI T3 SET name peter T4 SET name john T5 EXEC 在时间 T4 ，客户端 B 修改了 name 键的值， 当客户端 A 在 T5 执行 EXEC 时，Redis 会发现 name 这个被监视的键已经被修改， 因此客户端 A 的事务不会被执行，而是直接返回失败。 下文就来介绍 WATCH 的实现机制，并且看看事务系统是如何检查某个被监视的键是否被修改，从而保证事务的安全性的。 WATCH 命令的实现在每个代表数据库的 redis.h/redisDb 结构类型中， 都保存了一个 watched_keys 字典， 字典的键是这个数据库被监视的键， 而字典的值则是一个链表， 链表中保存了所有监视这个键的客户端。 比如说，以下字典就展示了一个 watched_keys 字典的例子： 其中， 键 key1 正在被 client2 、 client5 和 client1 三个客户端监视， 其他一些键也分别被其他别的客户端监视着。 WATCH 命令的作用， 就是将当前客户端和要监视的键在 watched_keys 中进行关联。 举个例子， 如果当前客户端为 client10086 ， 那么当客户端执行 WATCH key1 key2 时， 前面展示的 watched_keys 将被修改成这个样子： 通过 watched_keys 字典， 如果程序想检查某个键是否被监视， 那么它只要检查字典中是否存在这个键即可； 如果程序要获取监视某个键的所有客户端， 那么只要取出键的值（一个链表）， 然后对链表进行遍历即可。 WATCH 的触发在任何对数据库键空间（key space）进行修改的命令成功执行之后 （比如 FLUSHDB 、 SET 、 DEL 、 LPUSH 、 SADD 、 ZREM ，诸如此类）， multi.c/touchWatchedKey 函数都会被调用 —— 它检查数据库的 watched_keys 字典， 看是否有客户端在监视已经被命令修改的键， 如果有的话， 程序将所有监视这个/这些被修改键的客户端的 REDIS_DIRTY_CAS 选项打开： 当客户端发送 EXEC 命令、触发事务执行时， 服务器会对客户端的状态进行检查： 如果客户端的 REDIS_DIRTY_CAS 选项已经被打开，那么说明被客户端监视的键至少有一个已经被修改了，事务的安全性已经被破坏。服务器会放弃执行这个事务，直接向客户端返回空回复，表示事务执行失败。 如果 REDIS_DIRTY_CAS 选项没有被打开，那么说明所有监视键都安全，服务器正式执行事务。 可以用一段伪代码来表示这个检查： 123456789101112def check_safety_before_execute_trasaction(): if client.state &amp; REDIS_DIRTY_CAS: # 安全性已破坏，清除事务状态 clear_transaction_state(client) # 清空事务队列 clear_transaction_queue(client) # 返回空回复给客户端 send_empty_reply(client) else: # 安全性完好，执行事务 execute_transaction() 举个例子，假设数据库的 watched_keys 字典如下图所示： 如果某个客户端对 key1 进行了修改（比如执行 DEL key1 ）， 那么所有监视 key1 的客户端， 包括 client2 、 client5 和 client1 的 REDIS_DIRTY_CAS 选项都会被打开， 当客户端 client2 、 client5 和 client1 执行 EXEC 的时候， 它们的事务都会以失败告终。 最后，当一个客户端结束它的事务时，无论事务是成功执行，还是失败， watched_keys 字典中和这个客户端相关的资料都会被清除。 事务的 ACID 性质勘误：Redis 的事务是保证原子性的，本节的内容将原子性和回滚功能混淆了，等待修复中。 —— 2013.6.23 在传统的关系式数据库中，常常用 ACID 性质来检验事务功能的安全性。 Redis 事务保证了其中的一致性（C）和隔离性（I），但并不保证原子性（A）和持久性（D）。 以下四小节是关于这四个性质的详细讨论。 原子性（Atomicity）单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。 如果一个事务队列中的所有命令都被成功地执行，那么称这个事务执行成功。 另一方面，如果 Redis 服务器进程在执行事务的过程中被停止 —— 比如接到 KILL 信号、宿主机器停机，等等，那么事务执行失败。 当事务失败时，Redis 也不会进行任何的重试或者回滚动作。 一致性（Consistency）Redis 的一致性问题可以分为三部分来讨论：入队错误、执行错误、Redis 进程被终结。 入队错误在命令入队的过程中，如果客户端向服务器发送了错误的命令，比如命令的参数数量不对，等等， 那么服务器将向客户端返回一个出错信息， 并且将客户端的事务状态设为 REDIS_DIRTY_EXEC 。 当客户端执行 EXEC 命令时， Redis 会拒绝执行状态为 REDIS_DIRTY_EXEC 的事务， 并返回失败信息。 1234567891011redis 127.0.0.1:6379&gt; MULTIOKredis 127.0.0.1:6379&gt; set key(error) ERR wrong number of arguments for &apos;set&apos; commandredis 127.0.0.1:6379&gt; EXISTS keyQUEUEDredis 127.0.0.1:6379&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors. 因此，带有不正确入队命令的事务不会被执行，也不会影响数据库的一致性。 执行错误如果命令在事务执行的过程中发生错误，比如说，对一个不同类型的 key 执行了错误的操作， 那么 Redis 只会将错误包含在事务的结果中， 这不会引起事务中断或整个失败，不会影响已执行事务命令的结果，也不会影响后面要执行的事务命令， 所以它对事务的一致性也没有影响。 Redis 进程被终结如果 Redis 服务器进程在执行事务的过程中被其他进程终结，或者被管理员强制杀死，那么根据 Redis 所使用的持久化模式，可能有以下情况出现： 内存模式：如果 Redis 没有采取任何持久化机制，那么重启之后的数据库总是空白的，所以数据总是一致的。 RDB 模式：在执行事务时，Redis 不会中断事务去执行保存 RDB 的工作，只有在事务执行之后，保存 RDB 的工作才有可能开始。所以当 RDB 模式下的 Redis 服务器进程在事务中途被杀死时，事务内执行的命令，不管成功了多少，都不会被保存到 RDB 文件里。恢复数据库需要使用现有的 RDB 文件，而这个 RDB 文件的数据保存的是最近一次的数据库快照（snapshot），所以它的数据可能不是最新的，但只要 RDB 文件本身没有因为其他问题而出错，那么还原后的数据库就是一致的。 AOF 模式：因为保存 AOF 文件的工作在后台线程进行，所以即使是在事务执行的中途，保存 AOF 文件的工作也可以继续进行，因此，根据事务语句是否被写入并保存到 AOF 文件，有以下两种情况发生： 1）如果事务语句未写入到 AOF 文件，或 AOF 未被 SYNC 调用保存到磁盘，那么当进程被杀死之后，Redis 可以根据最近一次成功保存到磁盘的 AOF 文件来还原数据库，只要 AOF 文件本身没有因为其他问题而出错，那么还原后的数据库总是一致的，但其中的数据不一定是最新的。 2）如果事务的部分语句被写入到 AOF 文件，并且 AOF 文件被成功保存，那么不完整的事务执行信息就会遗留在 AOF 文件里，当重启 Redis 时，程序会检测到 AOF 文件并不完整，Redis 会退出，并报告错误。需要使用 redis-check-aof 工具将部分成功的事务命令移除之后，才能再次启动服务器。还原之后的数据总是一致的，而且数据也是最新的（直到事务执行之前为止）。 隔离性（Isolation）Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。 持久性（Durability）因为事务不过是用队列包裹起了一组 Redis 命令，并没有提供任何额外的持久性功能，所以事务的持久性由 Redis 所使用的持久化模式决定： 在单纯的内存模式下，事务肯定是不持久的。 在 RDB 模式下，服务器可能在事务执行之后、RDB 文件更新之前的这段时间失败，所以 RDB 模式下的 Redis 事务也是不持久的。 在 AOF 的“总是 SYNC ”模式下，事务的每条命令在执行成功之后，都会立即调用 fsync 或 fdatasync 将事务数据写入到 AOF 文件。但是，这种保存是由后台线程进行的，主线程不会阻塞直到保存成功，所以从命令执行成功到数据保存到硬盘之间，还是有一段非常小的间隔，所以这种模式下的事务也是不持久的。 其他 AOF 模式也和“总是 SYNC ”模式类似，所以它们都是不持久的。 小结 事务提供了一种将多个命令打包，然后一次性、有序地执行的机制。 事务在执行过程中不会被中断，所有事务命令执行完之后，事务才能结束。 多个命令会被入队到事务队列中，然后按先进先出（FIFO）的顺序执行。 带 WATCH 命令的事务会将客户端和被监视的键在数据库的 watched_keys 字典中进行关联，当键被修改时，程序会将所有监视被修改键的客户端的 REDIS_DIRTY_CAS 选项打开。 只有在客户端的 REDIS_DIRTY_CAS 选项未被打开时，才能执行事务，否则事务直接返回失败。 Redis 的事务保证了 ACID 中的一致性（C）和隔离性（I），但并不保证原子性（A）和持久性（D）。 参考事务]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的几种实现方式]]></title>
    <url>%2Fredis%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[目前几乎很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。分布式的CAP理论告诉我们“任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。 在很多场景中，我们为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。有的时候，我们需要保证一个方法在同一时间内只能被同一个线程执行。在单机环境中，Java中其实提供了很多并发处理相关的API，但是这些API在分布式场景中就无能为力了。也就是说单纯的Java Api并不能提供分布式锁的能力。所以针对分布式锁的实现目前有多种方案。 针对分布式锁的实现，目前比较常用的有以下几种方案： 基于数据库实现分布式锁 基于缓存（redis，memcached，tair）实现分布式锁 基于Zookeeper实现分布式锁 在分析这几种实现方案之前我们先来想一下，我们需要的分布式锁应该是怎么样的？（这里以方法锁为例，资源锁同理） 可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。 这把锁要是一把可重入锁（避免死锁） 这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条） 有高可用的获取锁和释放锁功能 获取锁和释放锁的性能要好 基于数据库实现分布式锁基于数据库表要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。 当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。 创建这样一张数据库表： 12345678CREATE TABLE `methodLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `method_name` varchar(64) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;锁定的方法名&apos;, `desc` varchar(1024) NOT NULL DEFAULT &apos;备注信息&apos;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;保存数据时间，自动生成&apos;, PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;锁定中的方法&apos;; 当我们想要锁住某个方法时，执行以下SQL： 1insert into methodLock(method_name,desc) values (‘method_name’,‘desc’) 因为我们对method_name做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。 当方法执行完毕之后，想要释放锁的话，需要执行以下Sql: 1delete from methodLock where method_name =&apos;method_name&apos; 上面这种简单的实现有以下几个问题： 1、这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。 2、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。 3、这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。 4、这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。 当然，我们也可以有其他方式解决上面的问题。 数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。 没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。 非阻塞的？搞一个while循环，直到insert成功再返回成功。 非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。 基于数据库排他锁除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。 我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。 基于MySql的InnoDB引擎，可以使用以下方法来实现加锁操作： 123456789101112131415public boolean lock()&#123; connection.setAutoCommit(false) while(true)&#123; try&#123; result = select * from methodLock where method_name=xxx for update; if(result==null)&#123; return true; &#125; &#125;catch(Exception e)&#123; &#125; sleep(1000); &#125; return false;&#125; 在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给method_name添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。 我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁： 123public void unlock()&#123; connection.commit();&#125; 通过connection.commit()操作来释放锁。 这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。 阻塞锁？ for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。 锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。 但是还是无法直接解决数据库单点和可重入问题。 这里还可能存在另外一个问题，虽然我们对method_name 使用了唯一索引，并且显示使用for update来使用行级锁。但是，MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。如果发生这种情况就悲剧了。。。 还有一个问题，就是我们要使用排他锁来进行分布式锁的lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆 总结总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。 数据库实现分布式锁的优点 直接借助数据库，容易理解。 数据库实现分布式锁的缺点 会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。 操作数据库需要一定的开销，性能问题需要考虑。 使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。 基于缓存实现分布式锁相比较于基于数据库实现分布式锁的方案来说，基于缓存来实现在性能方面会表现的更好一点。而且很多缓存是可以集群部署的，可以解决单点问题。 目前有很多成熟的缓存产品，包括Redis，memcached以及我们公司内部的Tair。 这里以Tair为例来分析下使用缓存实现分布式锁的方案。关于Redis和memcached在网络上有很多相关的文章，并且也有一些成熟的框架及算法可以直接使用。 基于Tair的实现分布式锁其实和Redis类似，其中主要的实现方式是使用TairManager.put方法来实现。 12345678910public boolean trylock(String key) &#123; ResultCode code = ldbTairManager.put(NAMESPACE, key, "This is a Lock.", 2, 0); if (ResultCode.SUCCESS.equals(code)) return true; else return false;&#125;public boolean unlock(String key) &#123; ldbTairManager.invalid(NAMESPACE, key);&#125; 以上实现方式同样存在几个问题： 1、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在tair中，其他线程无法再获得到锁。 2、这把锁只能是非阻塞的，无论成功还是失败都直接返回。 3、这把锁是非重入的，一个线程获得锁之后，在释放锁之前，无法再次获得该锁，因为使用到的key在tair中已经存在。无法再执行put操作。 当然，同样有方式可以解决。 没有失效时间？tair的put方法支持传入失效时间，到达时间之后数据会自动删除。 非阻塞？while重复执行。 非可重入？在一个线程获取到锁之后，把当前主机信息和线程信息保存起来，下次再获取之前先检查自己是不是当前锁的拥有者。 但是，失效时间我设置多长时间为好？如何设置的失效时间太短，方法没等执行完，锁就自动释放了，那么就会产生并发问题。如果设置的时间太长，其他获取锁的线程就可能要平白的多等一段时间。这个问题使用数据库实现分布式锁同样存在 总结可以使用缓存来代替数据库来实现分布式锁，这个可以提供更好的性能，同时，很多缓存服务都是集群部署的，可以避免单点问题。并且很多缓存服务都提供了可以用来实现分布式锁的方法，比如Tair的put方法，redis的setnx方法等。并且，这些缓存服务也都提供了对数据的过期自动删除的支持，可以直接设置超时时间来控制锁的释放。 使用缓存实现分布式锁的优点 性能好，实现起来较为方便。 使用缓存实现分布式锁的缺点 通过超时时间来控制锁的失效时间并不是十分的靠谱。 基于Zookeeper实现分布式锁基于zookeeper临时有序节点可以实现的分布式锁。 大致思想即为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。 来看下Zookeeper能不能解决前面提到的问题。 锁无法释放？使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。 非阻塞锁？使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。 不可重入？使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。 单点问题？使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。 可以直接使用zookeeper第三方库Curator客户端，这个客户端中封装了一个可重入的锁服务。 123456789101112131415161718public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; try &#123; return interProcessMutex.acquire(timeout, unit); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return true;&#125;public boolean unlock() &#123; try &#123; interProcessMutex.release(); &#125; catch (Throwable e) &#123; log.error(e.getMessage(), e); &#125; finally &#123; executorService.schedule(new Cleaner(client, path), delayTimeForClean, TimeUnit.MILLISECONDS); &#125; return true;&#125; Curator提供的InterProcessMutex是分布式锁的实现。acquire方法用户获取锁，release方法用于释放锁。 使用ZK实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。 其实，使用Zookeeper也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端可ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。） 总结使用Zookeeper实现分布式锁的优点 有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。 使用Zookeeper实现分布式锁的缺点 性能上不如使用缓存实现分布式锁。 需要对ZK的原理有所了解。 三种方案的比较上面几种方式，哪种方式都无法做到完美。就像CAP一样，在复杂性、可靠性、性能等方面无法同时满足，所以，根据不同的应用场景选择最适合自己的才是王道。 从理解的难易程度角度（从低到高）数据库 &gt; 缓存 &gt; Zookeeper 从实现的复杂性角度（从低到高）Zookeeper &gt;= 缓存 &gt; 数据库 从性能角度（从高到低）缓存 &gt; Zookeeper &gt;= 数据库 从可靠性角度（从高到低）Zookeeper &gt; 缓存 &gt; 数据库 原文]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis合集]]></title>
    <url>%2Fredis%2Fredis%E5%90%88%E9%9B%86%2F</url>
    <content type="text"><![CDATA[分布式锁Redis RedLock 完美的分布式锁么？ 聊一聊分布式锁的设计 redis分布式锁实现 分布式锁的几种实现方式 Redis 学习教程 redis并发问题 redis下并发问题解决方案 事务事务 持久化持久化 分区Redis分区实现原理 https://mp.weixin.qq.com/s/Ime_GyDkAJMTird1nWRNUA http://mp.weixin.qq.com/s__biz=MzIwNDU2MTI4NQ==&amp;mid=2247483728&amp;idx=1&amp;sn=c2076dbc98de6fbd40b87236f2033925&amp;chksm=973f0fbaa04886ac83c975b7046885f7171be8d26695d23fcab974124ce054a65d10caea3db5&amp;scene=21#wechat_redirect]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java IO]]></title>
    <url>%2Fjava%2FJava%20IO%2F</url>
    <content type="text"><![CDATA[也谈BIO | NIO | AIO （Java版） Java NIO浅析]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>io</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty相关概念]]></title>
    <url>%2Fnetty%2Fnetty%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[怎样理解阻塞非阻塞与同步异步的区别？ 也谈BIO | NIO | AIO （Java版） 通俗地讲，Netty 能做什么？ Netty的核心组件 Netty入门教程——认识NettyNetty入门教程2——动手搭建HttpServerNetty入门教程3——Decoder和EncoderNetty笔记4-如何实现长连接Essential Netty in Action 《Netty 实战(精髓)》Way Lau’s Open Souce Books 源码源码之下无秘密 ── 做最好的 Netty 源码分析教程 zero copyNetty的零拷贝体现在三个方面： Netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才写入Socket中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。 Netty提供了组合Buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个Buffer那样方便的对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。 Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。 Netty中的零拷贝对于 Netty ByteBuf 的零拷贝(Zero Copy) 的理解 概述Netty概述 Java NIO浅析]]></content>
      <categories>
        <category>netty</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql索引及查询优化]]></title>
    <url>%2Fmysql%2Fmysql%E7%B4%A2%E5%BC%95%E5%8F%8A%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[建索引的几大原则 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录 索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’); 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可 慢查询优化基本步骤 先运行看看是否真的很慢，注意设置SQL_NO_CACHE where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高 explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询） order by limit 形式的sql语句让排序的表优先查 了解业务方使用场景 加索引时参照建索引的几大原则 观察结果，不符合预期继续从0分析 常用索引优化 有索引但未被用到的情况（不建议） Like的参数以通配符开头时，将导致全表扫描 where条件不符合最左前缀原则时 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。优化器将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行 索引列参与计算 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描。可以在num上设置默认值0，确保表中num列没有null值 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描 避免select * order by 语句优化 GROUP BY语句优化 用 exists 代替 in 使用 varchar/nvarchar 代替 char/nchar 能用DISTINCT的就不用GROUP BY 能用UNION ALL就不要用UNION 在Join表的时候使用相当类型的例，并将其索引 MYSQL性能优化的最佳20+条经验MySQL 索引及查询优化总结 参考MySQL 索引及查询优化总结MySQL索引原理及慢查询优化]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[感悟]]></title>
    <url>%2F%E6%84%9F%E6%82%9F%2F</url>
    <content type="text"><![CDATA[当想找到一种通用的解决策略时，可以先列出所有的情况，然后再找统一的策略。 每天至少做3件事，长时间关注于一件事，容易迷茫。]]></content>
  </entry>
  <entry>
    <title><![CDATA[彻底看懂 so called 红黑树]]></title>
    <url>%2Fjava%2Fdatastructure%2Ftreemap%2F</url>
    <content type="text"><![CDATA[为了理解 TreeMap 的底层实现，必须先介绍排序二叉树和红黑树这两种数据结构。其中红黑树又是一种特殊的排序二叉树。 排序二叉树排序二叉树是一种特殊结构的二叉树，可以非常方便地对树中所有节点进行排序和检索。 排序二叉树要么是一棵空二叉树，要么是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若它的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 它的左、右子树也分别为排序二叉树。 图 1 显示了一棵排序二叉树： 对排序二叉树，若按中序遍历就可以得到由小到大的有序序列。如图 1 所示二叉树，中序遍历得： {2，3，4，8，9，9，10，13，15，18} 排序二叉树的中序遍历，最终结果是从小到大的升序排列。 添加节点创建排序二叉树的步骤，也就是不断地向排序二叉树添加节点的过程，向排序二叉树添加节点的步骤如下： 以根节点当前节点开始搜索。 拿新节点的值和当前节点的值比较。 如果新节点的值更大，则以当前节点的右子节点作为新的当前节点；如果新节点的值更小，则以当前节点的左子节点作为新的当前节点。 重复 2、3 两个步骤，直到搜索到合适的叶子节点为止。 将新节点添加为第 4 步找到的叶子节点的子节点；如果新节点更大，则添加为右子节点；否则添加为左子节点。 删除节点当程序从排序二叉树中删除一个节点之后，为了让它依然保持为排序二叉树，程序必须对该排序二叉树进行维护。维护可分为如下几种情况： （1）被删除的节点是叶子节点，则只需将它从其父节点中删除即可。 （2）被删除节点 p 只有左子树，将 p 的左子树 pL 添加成 p 的父节点的左子树即可；被删除节点 p 只有右子树，将 p 的右子树 pR 添加成 p 的父节点的右子树即可。 （3）若被删除节点 p 的左、右子树均非空，有两种做法： 将 pL 设为 p 的父节点 q 的左或右子节点（取决于 p 是其父节点 q 的左、右子节点），将 pR 设为 p 节点的中序前趋节点 s 的右子节点（s 是 pL 最右下的节点，也就是 pL 子树中最大的节点）。 以 p 节点的中序前趋或后继替代 p 所指节点，然后再从原排序二叉树中删去中序前趋或后继节点即可。（也就是用大于 p 的最小节点或小于 p 的最大节点代替 p 节点即可）。 图 2. 被删除节点只有左子树 图 3 显示了被删除节点只有右子树的示意图： 图 4 显示了被删除节点既有左子节点，又有右子节点的情形，此时我们采用到是第一种方式进行维护： 图 5 显示了被删除节点既有左子树，又有右子树的情形，此时我们采用到是第二种方式进行维护： TreeMapTreeMap的添加和删除节点，是在二叉排序树的添加、删除的基础上，进行旋转和变色。 添加节点掌握上面理论之后，下面我们来分析 TreeMap 添加节点（TreeMap 中使用 Entry 内部类代表节点）的实现，TreeMap 集合的 put(K key, V value) 方法实现了将 Entry 放入排序二叉树中，下面是该方法的源代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public V put(K key, V value) &#123; // 先以 t 保存链表的 root 节点 Entry&lt;K,V&gt; t = root; // 如果 t==null，表明是一个空链表，即该 TreeMap 里没有任何 Entry if (t == null) &#123; // 将新的 key-value 创建一个 Entry，并将该 Entry 作为 root root = new Entry&lt;K,V&gt;(key, value, null); // 设置该 Map 集合的 size 为 1，代表包含一个 Entry size = 1; // 记录修改次数为 1 modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; Comparator&lt;? super K&gt; cpr = comparator; // 如果比较器 cpr 不为 null，即表明采用定制排序 if (cpr != null) &#123; do &#123; // 使用 parent 上次循环后的 t 所引用的 Entry parent = t; // 拿新插入 key 和 t 的 key 进行比较 cmp = cpr.compare(key, t.key); // 如果新插入的 key 小于 t 的 key，t 等于 t 的左边节点 if (cmp &lt; 0) t = t.left; // 如果新插入的 key 大于 t 的 key，t 等于 t 的右边节点 else if (cmp &gt; 0) t = t.right; // 如果两个 key 相等，新的 value 覆盖原有的 value， // 并返回原有的 value else return t.setValue(value); &#125; while (t != null); &#125; else &#123; if (key == null) throw new NullPointerException(); Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; // 使用 parent 上次循环后的 t 所引用的 Entry parent = t; // 拿新插入 key 和 t 的 key 进行比较 cmp = k.compareTo(t.key); // 如果新插入的 key 小于 t 的 key，t 等于 t 的左边节点 if (cmp &lt; 0) t = t.left; // 如果新插入的 key 大于 t 的 key，t 等于 t 的右边节点 else if (cmp &gt; 0) t = t.right; // 如果两个 key 相等，新的 value 覆盖原有的 value， // 并返回原有的 value else return t.setValue(value); &#125; while (t != null); &#125; // 将新插入的节点作为 parent 节点的子节点 Entry&lt;K,V&gt; e = new Entry&lt;K,V&gt;(key, value, parent); // 如果新插入 key 小于 parent 的 key，则 e 作为 parent 的左子节点 if (cmp &lt; 0) parent.left = e; // 如果新插入 key 小于 parent 的 key，则 e 作为 parent 的右子节点 else parent.right = e; // 修复红黑树 fixAfterInsertion(e); // ① size++; modCount++; return null; &#125; 每当程序希望添加新节点时：系统总是从树的根节点开始比较 —— 即将根节点当成当前节点，如果新增节点大于当前节点、并且当前节点的右子节点存在，则以右子节点作为当前节点；如果新增节点小于当前节点、并且当前节点的左子节点存在，则以左子节点作为当前节点；如果新增节点等于当前节点，则用新增节点覆盖当前节点，并结束循环 —— 直到找到某个节点的左、右子节点不存在，将新节点添加该节点的子节点 —— 如果新节点比该节点大，则添加为右子节点；如果新节点比该节点小，则添加为左子节点。 删除节点TreeMap 删除节点采用图 5 所示右边的情形进行维护（中序遍历顺序的后继节点）——也就是用被删除节点的右子树中最小节点与被删节点交换的方式进行维护。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private void deleteEntry(Entry&lt;K,V&gt; p) &#123; modCount++; size--; // 如果被删除节点的左子树、右子树都不为空 if (p.left != null &amp;&amp; p.right != null) &#123; // 用 p 节点的中序后继节点代替 p 节点，且p必然为叶子节点（可参考中序遍历的顺序），所以p.left == null, p.right == null Entry&lt;K,V&gt; s = successor (p); p.key = s.key; p.value = s.value; p = s; &#125; // 如果 p 节点的左节点存在，replacement 代表左节点；否则代表右节点。 Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right); if (replacement != null) // p 只有一个节点（如果 p 有两个节点，那么 replacement 为 null） &#123; replacement.parent = p.parent; // 如果 p 没有父节点，则 replacemment 变成父节点 if (p.parent == null) root = replacement; // 如果 p 节点是其父节点的左子节点 else if (p == p.parent.left) p.parent.left = replacement; // 如果 p 节点是其父节点的右子节点 else p.parent.right = replacement; p.left = p.right = p.parent = null; // 修复红黑树 if (p.color == BLACK) // 当 p 为黑色时，由于 p 被删除，那么少了一个黑色节点，需要重新平衡 fixAfterDeletion(replacement); // ① &#125; // 如果 p 节点没有父节点 else if (p.parent == null) &#123; root = null; &#125; else &#123; // 删除子节点 if (p.color == BLACK) // 修复红黑树 fixAfterDeletion(p); // ② if (p.parent != null) &#123; // 如果 p 是其父节点的左子节点 if (p == p.parent.left) p.parent.left = null; // 如果 p 是其父节点的右子节点 else if (p == p.parent.right) p.parent.right = null; p.parent = null; &#125; &#125; &#125; 红黑树红黑树在原有的排序二叉树增加了如下几个要求： 性质 1：每个节点要么是红色，要么是黑色。 性质 2：根节点永远是黑色的。 性质 3：所有的叶节点都是空节点（即 null），并且是黑色的。 性质 4：每个红色节点的两个子节点都是黑色。（从每个叶子到根的路径上不会有两个连续的红色节点，但是黑色节点可以连续） 性质 5：从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点。 注意：上面的性质 3 中指定红黑树的每个叶子节点都是空节点，而且并叶子节点都是黑色。但 Java 实现的红黑树将使用 null 来代表空节点，因此遍历红黑树时将看不到黑色的叶子节点，反而看到每个叶子节点都是红色的。 Java 中实现的红黑树可能有如图 6 所示结构： 备注：本文中所有关于红黑树中的示意图采用白色代表红色。黑色节点还是采用了黑色表示。 根据性质 5：红黑树从根节点到每个叶子节点的路径都包含相同数量的黑色节点，因此从根节点到叶子节点的路径中包含的黑色节点数被称为树的“黑色高度（black-height）”。 性质 4 则保证了从根节点到叶子节点的最长路径的长度不会超过任何其他路径的两倍。假如有一棵黑色高度为 3 的红黑树：从根节点到叶节点的最短路径长度是 2，该路径上全是黑色节点（黑节点 - 黑节点 - 黑节点）。最长路径也只可能为 4，在每个黑色节点之间插入一个红色节点（黑节点 - 红节点 - 黑节点 - 红节点 - 黑节点），性质 4 保证绝不可能插入更多的红色节点。由此可见，红黑树中最长路径就是一条红黑交替的路径。 由此我们可以得出结论：对于给定的黑色高度为 N 的红黑树，从根到叶子节点的最短路径长度为 N-1，最长路径长度为 2 * (N-1)。 提示：排序二叉树的深度直接影响了检索的性能，正如前面指出，当插入节点本身就是由小到大排列时，排序二叉树将变成一个链表，这种排序二叉树的检索性能最低：N 个节点的二叉树深度就是 N-1。 红黑树通过上面这种限制来保证它大致是平衡的——因为红黑树的高度不会无限增高，这样保证红黑树在最坏情况下都是高效的，不会出现普通排序二叉树的情况。 由于红黑树只是一个特殊的排序二叉树，因此对红黑树上的只读操作与普通排序二叉树上的只读操作完全相同，只是红黑树保持了大致平衡，因此检索性能比排序二叉树要好很多。 但在红黑树上进行插入操作和删除操作会导致树不再符合红黑树的特征，因此插入操作和删除操作都需要进行一定的维护，以保证插入节点、删除节点后的树依然是红黑树。 注意：红黑树并不是真正的平衡二叉树，但在实际应用中，红黑树的统计性能要高于平衡二叉树，但极端性能略差。 添加节点后的修复上面 put(K key, V value) 方法中①`号代码处使用fixAfterInsertion(e) 方法来修复红黑树——因此每次插入节点后必须进行简单修复，使该排序二叉树满足红黑树的要求。` 插入操作按如下步骤进行： （1）以排序二叉树的方法插入新节点，并将它设为红色。 （2）进行颜色调换和树旋转。 在插入操作中，红黑树的性质 1 和性质 3 两个永远不会发生改变，因此无需考虑红黑树的这两个特性。 这种颜色调用和树旋转就比较复杂了，下面将分情况进行介绍。在介绍中，我们把新插入的节点定义为 N 节点，N 节点的父节点定义为 P 节点，P 节点的兄弟节点定义为 U 节点，P 节点父节点定义为 G 节点。 下面分成不同情形来分析插入操作 情形 1：新节点 N 是树的根节点，没有父节点 在这种情形下，直接将它设置为黑色以满足性质 2。 情形 2：新节点的父节点 P 是黑色 在这种情况下，新插入的节点是红色的，因此依然满足性质 4。而且因为新节点 N 有两个黑色叶子节点；但是由于新节点 N 是红色，通过它的每个子节点的路径依然保持相同的黑色节点数，因此依然满足性质 5。 情形 3：如果父节点 P 和父节点的兄弟节点 U 都是红色 在这种情况下，程序应该将 P 节点、U 节点都设置为黑色，并将 P 节点的父节点设为红色（用来保持性质 5）。现在新节点 N 有了一个黑色的父节点 P。由于从 P 节点、U 节点到根节点的任何路径都必须通过 G 节点，在这些路径上的黑节点数目没有改变（原来有叶子和 G 节点两个黑色节点，现在有叶子和 P 两个黑色节点）。 经过上面处理后，红色的 G 节点的父节点也有可能是红色的，这就违反了性质 4，因此还需要对 G 节点递归地进行整个过程（把 G 当成是新插入的节点进行处理即可）。 图 7 显示了这种处理过程： 备注：虽然图 11.28 绘制的是新节点 N 作为父节点 P 左子节点的情形，其实新节点 N 作为父节点 P 右子节点的情况与图 11.28 完全相同。 情形 4：父节点 P 是红色、而其兄弟节点 U 是黑色或缺少；且新节点 N 是父节点 P 的右子节点，而父节点 P 又是其父节点 G 的左子节点。 在这种情形下，我们进行一次左旋转对新节点和其父节点进行，接着按情形 5 处理以前的父节点 P（也就是把 P 当成新插入的节点即可）。这导致某些路径通过它们以前不通过的新节点 N 或父节点 P 的其中之一，但是这两个节点都是红色的，因此不会影响性质 5。 图 8 显示了对情形 4 的处理： 备注：图 11.29 中 P 节点是 G 节点的左子节点，如果 P 节点是其父节点 G 节点的右子节点，那么上 面的处理情况应该左、右对调一下。 情形 5：父节点 P 是红色、而其兄弟节点 U 是黑色或缺少；且新节点 N 是其父节点的左子节点，而父节点 P 又是其父节点 G 的左子节点。 在这种情形下，需要对节点 G 的一次右旋转，在旋转产生的树中，以前的父节点 P 现在是新节点 N 和节点 G 的父节点。由于以前的节点 G 是黑色，否则父节点 P 就不可能是红色，我们切换以前的父节点 P 和节点 G 的颜色，使之满足性质 4，性质 5 也仍然保持满足，因为通过这三个节点中任何一个的所有路径以前都通过节点 G，现在它们都通过以前的父节点 P。在各自的情形下，这都是三个节点中唯一的黑色节点。 图 9 显示了情形 5 的处理过程： 备注：图 11.30 中 P 节点是 G 节点的左子节点，如果 P 节点是其父节点 G 节点的右子节点，那么上面的处理情况应该左、右对调一下。 情形 4 和情形 5 中的新插入的N节点，貌似会破坏红黑树的性质5（从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点），实际上，新节点N是由于变色而来的，其内部是包含一个黑色节点的。 TreeMap 为插入节点后的修复操作由 fixAfterInsertion(Entry&lt;K,V&gt; x) 方法提供，该方法的源代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// 插入节点后修复红黑树private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123; x.color = RED; // 直到 x 节点的父节点不是根，且 x 的父节点不是红色 while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; // 如果 x 的父节点是其父节点的左子节点 if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123; // 获取 x 的父节点的兄弟节点 Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x))); // 如果 x 的父节点的兄弟节点是红色 if (colorOf(y) == RED) &#123; // 将 x 的父节点设为黑色 setColor(parentOf(x), BLACK); // 将 x 的父节点的兄弟节点设为黑色 setColor(y, BLACK); // 将 x 的父节点的父节点设为红色 setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); &#125; // 如果 x 的父节点的兄弟节点是黑色 else &#123; // 如果 x 是其父节点的右子节点 if (x == rightOf(parentOf(x))) &#123; // 将 x 的父节点设为 x x = parentOf(x); rotateLeft(x); &#125; // 把 x 的父节点设为黑色 setColor(parentOf(x), BLACK); // 把 x 的父节点的父节点设为红色 setColor(parentOf(parentOf(x)), RED); rotateRight(parentOf(parentOf(x))); &#125; &#125; // 如果 x 的父节点是其父节点的右子节点 else &#123; // 获取 x 的父节点的兄弟节点 Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x))); // 如果 x 的父节点的兄弟节点是红色 if (colorOf(y) == RED) &#123; // 将 x 的父节点设为黑色。 setColor(parentOf(x), BLACK); // 将 x 的父节点的兄弟节点设为黑色 setColor(y, BLACK); // 将 x 的父节点的父节点设为红色 setColor(parentOf(parentOf(x)), RED); // 将 x 设为 x 的父节点的节点 x = parentOf(parentOf(x)); &#125; // 如果 x 的父节点的兄弟节点是黑色 else &#123; // 如果 x 是其父节点的左子节点 if (x == leftOf(parentOf(x))) &#123; // 将 x 的父节点设为 x x = parentOf(x); rotateRight(x); &#125; // 把 x 的父节点设为黑色 setColor(parentOf(x), BLACK); // 把 x 的父节点的父节点设为红色 setColor(parentOf(parentOf(x)), RED); rotateLeft(parentOf(parentOf(x))); &#125; &#125; &#125; // 将根节点设为黑色 root.color = BLACK; &#125; 删除节点后的修复与添加节点之后的修复类似的是，TreeMap 删除节点之后也需要进行类似的修复操作，通过这种修复来保证该排序二叉树依然满足红黑树特征。大家可以参考插入节点之后的修复来分析删除之后的修复。TreeMap 在删除之后的修复操作由 fixAfterDeletion(Entry&lt;K,V&gt; x) 方法提供，该方法源代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102// 删除节点后修复红黑树private void fixAfterDeletion(Entry&lt;K,V&gt; x) &#123; // 直到 x 不是根节点，且 x 的颜色是黑色 while (x != root &amp;&amp; colorOf(x) == BLACK) &#123; // 如果 x 是其父节点的左子节点 if (x == leftOf(parentOf(x))) &#123; // 获取 x 节点的兄弟节点 Entry&lt;K,V&gt; sib = rightOf(parentOf(x)); // 如果 sib 节点是红色 if (colorOf(sib) == RED) &#123; // 将 sib 节点设为黑色 setColor(sib, BLACK); // 将 x 的父节点设为红色 setColor(parentOf(x), RED); rotateLeft(parentOf(x)); // 再次将 sib 设为 x 的父节点的右子节点 sib = rightOf(parentOf(x)); &#125; // 如果 sib 的两个子节点都是黑色 if (colorOf(leftOf(sib)) == BLACK &amp;&amp; colorOf(rightOf(sib)) == BLACK) &#123; // 将 sib 设为红色 setColor(sib, RED); // 让 x 等于 x 的父节点 x = parentOf(x); &#125; else &#123; // 如果 sib 的只有右子节点是黑色 if (colorOf(rightOf(sib)) == BLACK) &#123; // 将 sib 的左子节点也设为黑色 setColor(leftOf(sib), BLACK); // 将 sib 设为红色 setColor(sib, RED); rotateRight(sib); sib = rightOf(parentOf(x)); &#125; // 设置 sib 的颜色与 x 的父节点的颜色相同 setColor(sib, colorOf(parentOf(x))); // 将 x 的父节点设为黑色 setColor(parentOf(x), BLACK); // 将 sib 的右子节点设为黑色 setColor(rightOf(sib), BLACK); rotateLeft(parentOf(x)); x = root; &#125; &#125; // 如果 x 是其父节点的右子节点 else &#123; // 获取 x 节点的兄弟节点 Entry&lt;K,V&gt; sib = leftOf(parentOf(x)); // 如果 sib 的颜色是红色 if (colorOf(sib) == RED) &#123; // 将 sib 的颜色设为黑色 setColor(sib, BLACK); // 将 sib 的父节点设为红色 setColor(parentOf(x), RED); rotateRight(parentOf(x)); sib = leftOf(parentOf(x)); &#125; // 如果 sib 的两个子节点都是黑色 if (colorOf(rightOf(sib)) == BLACK &amp;&amp; colorOf(leftOf(sib)) == BLACK) &#123; // 将 sib 设为红色 setColor(sib, RED); // 让 x 等于 x 的父节点 x = parentOf(x); &#125; else &#123; // 如果 sib 只有左子节点是黑色 if (colorOf(leftOf(sib)) == BLACK) &#123; // 将 sib 的右子节点也设为黑色 setColor(rightOf(sib), BLACK); // 将 sib 设为红色 setColor(sib, RED); rotateLeft(sib); sib = leftOf(parentOf(x)); &#125; // 将 sib 的颜色设为与 x 的父节点颜色相同 setColor(sib, colorOf(parentOf(x))); // 将 x 的父节点设为黑色 setColor(parentOf(x), BLACK); // 将 sib 的左子节点设为黑色 setColor(leftOf(sib), BLACK); rotateRight(parentOf(x)); x = root; &#125; &#125; &#125; setColor(x, BLACK); &#125; 检索节点当 TreeMap 根据 key 来取出 value 时，TreeMap 对应的方法如下：1234567public V get(Object key) &#123; // 根据指定 key 取出对应的 Entry Entry&gt;K,V&lt; p = getEntry(key); // 返回该 Entry 所包含的 value return (p==null ? null : p.value); &#125; 从上面程序的粗体字代码可以看出，get(Object key) 方法实质是由于 getEntry() 方法实现的，这个 getEntry() 方法的代码如下：1234567891011121314151617181920212223242526272829final Entry&lt;K,V&gt; getEntry(Object key) &#123; // 如果 comparator 不为 null，表明程序采用定制排序 if (comparator != null) // 调用 getEntryUsingComparator 方法来取出对应的 key return getEntryUsingComparator(key); // 如果 key 形参的值为 null，抛出 NullPointerException 异常 if (key == null) throw new NullPointerException(); // 将 key 强制类型转换为 Comparable 实例 Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; // 从树的根节点开始 Entry&lt;K,V&gt; p = root; while (p != null) &#123; // 拿 key 与当前节点的 key 进行比较 int cmp = k.compareTo(p.key); // 如果 key 小于当前节点的 key，向“左子树”搜索 if (cmp &lt; 0) p = p.left; // 如果 key 大于当前节点的 key，向“右子树”搜索 else if (cmp &gt; 0) p = p.right; // 不大于、不小于，就是找到了目标 Entry else return p; &#125; return null; &#125; 上面的 getEntry(Object obj) 方法也是充分利用排序二叉树的特征来搜索目标 Entry，程序依然从二叉树的根节点开始，如果被搜索节点大于当前节点，程序向“右子树”搜索；如果被搜索节点小于当前节点，程序向“左子树”搜索；如果相等，那就是找到了指定节点。 当 TreeMap 里的 comparator != null 即表明该 TreeMap 采用了定制排序，在采用定制排序的方式下，TreeMap 采用 getEntryUsingComparator(key) 方法来根据 key 获取 Entry。下面是该方法的代码：1234567891011121314151617181920212223242526final Entry&lt;K,V&gt; getEntryUsingComparator(Object key) &#123; K k = (K) key; // 获取该 TreeMap 的 comparator Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; // 从根节点开始 Entry&lt;K,V&gt; p = root; while (p != null) &#123; // 拿 key 与当前节点的 key 进行比较 int cmp = cpr.compare(k, p.key); // 如果 key 小于当前节点的 key，向“左子树”搜索 if (cmp &lt; 0) p = p.left; // 如果 key 大于当前节点的 key，向“右子树”搜索 else if (cmp &gt; 0) p = p.right; // 不大于、不小于，就是找到了目标 Entry else return p; &#125; &#125; return null; &#125; 其实 getEntry、getEntryUsingComparator 两个方法的实现思路完全类似，只是前者对自然排序的 TreeMap 获取有效，后者对定制排序的 TreeMap 有效。 通过上面源代码的分析不难看出，TreeMap 这个工具类的实现其实很简单。或者说：从内部结构来看，TreeMap 本质上就是一棵“红黑树”，而 TreeMap 的每个 Entry 就是该红黑树的一个节点。 参考 通过分析 JDK 源代码研究 TreeMap 红黑树算法实现 红黑树详细分析，看了都说好 红黑树的变色与旋转 红黑树插入删除过程 复习红黑树（二）–红黑树的删除 重温数据结构：深入理解红黑树]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试]]></title>
    <url>%2F%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[跳槽时时刻刻都在发生，但是我建议大家跳槽之前，先想清楚为什么要跳槽。切不可跟风，看到同事一个个都走了，自己也盲目的面试起来（期间也没有准备充分），到底是因为技术原因（影响自己的发展，偏移自己规划的轨迹），还是钱给少了，不受重视。 准备不充分的面试，完全是浪费时间，更是对自己的不负责（如果title很高，当我没说）。 今天给大家分享下chenssy在这次跳槽中整理的Java面试大纲，其中大部分都是面试过程中的面试题，可以对照这查漏补缺，当然了，这里所列的肯定不可能覆盖全部方式。 项目介绍大部分情况，这是一场面试的开门题，面试官问这个问题，主要是考察你的概述能力和全局视野。有的人经常抱怨自己每天在堆业务，但没有成长。事实上，很多情况下确实在堆业务，但并不是没有成长的。并非做中间件或者技术架构才是成长，例如我们的需求分析能力，沟通协作能力，产品思维能力，抽象建模能力等都是一个非常重要的硬实力。 好的，现在进入正文。 1、明确项目是做什么的 2、明确项目的价值。（为什么做这个项目，它解决了用户什么痛点，它带来什么价值？） 3、明确项目的功能。（这个项目涉及哪些功能？） 4、明确项目的技术。（这个项目用到哪些技术？） 5、明确个人在项目中的位置和作用。（你在这个项目的承担角色？） 6、明确项目的整体架构。 7、明确项目的优缺点,如果重新设计你会如何设计。 8、明确项目的亮点。（这个项目有什么亮点？） 9、明确技术成长。（你通过这个项目有哪些技术成长？） Java基础List 、 Set、Map 的区别List、Set、Map HashSet 是如何保证不重复的List、Set、Map HashMap 是线程安全的吗，为什么不是线程安全的（最好画图说明多线程环境下不安全）?List、Set、Map HashMap 的扩容过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 链表优化重hash的代码块 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; Java 8系列之重新认识HashMapHashMap原理-1.8 HashMap 1.7 与 1.8 的 区别，说明 1.8 做了哪些优化，如何优化的？ 引入了红黑树 扩容hash的优化，利用扩容后的位置的特性，不需要像JDK1.7的实现那样重新计算hash。 resize的时候，不想1.7那样需要倒置元素 Java 8系列之重新认识HashMapJava源码分析：HashMap 1.8 相对于1.7 到底更新了什么？HashMap原理-1.8 final finally finalizefinal：用于修饰类、成员变量和成员方法。final修饰的类，不能被继承（String、StringBuilder、StringBuffer、Math，不可变类）；Final修饰的方法不能被重写，但是子类可以用父类中final修饰的方法；Final修饰的成员变量是不可变的，如果成员变量是基本数据类型，初始化之后成员变量的值不能被改变，如果成员变量是引用类型，那么它只能指向初始化时指向的那个对象，不能再指向别的对象，但是对象当中的内容是允许改变的。 finally：用于异常代码块执行完成之后执行，通常用于关闭资源 finalize：object类中的一个方法，Java虚拟机在垃圾回收之前会先调用垃圾对象的finalize方法用于使对象释放资源（如关闭连接、关闭文件），之后才进行垃圾回收，这个方法一般不会显示的调用，在垃圾回收时垃圾回收器会主动调用。并且，虚拟机并不承诺等待它允许结束，是为了避免其中一个执行缓慢，导致整个内存回收系统崩溃。 强引用 、软引用、 弱引用、虚引用 类型 生命周期 用途 强引用 不会被GC … SoftReference 直到内存不足时 二级缓存 WeakReference 下次GC 缓存（WeakHashMap） PhantomReference 下次GC 堆外内存管理 关于java内存泄露的总结–引用的类型：强引用，弱引用，软引用从面试题中看Java的Reference（引用）ThreadLocal内存泄露 Java反射说说 Java 反射机制深入分析Java方法反射的实现原理Java反射机制应用实践 应用： AOP分离业务代码（jdk动态代理） 获取注解 泛型擦除 eclipse等IDE的代码智能提示 Arrays.sort 实现原理和 Collection 实现原理LinkedHashMap的应用LinkedHashMap 能够做到按照插入顺序或者访问顺序进行迭代，这样在我们以后的开发中遇到相似的问题，才能想到用 LinkedHashMap 来解决，否则就算对其内部结构非常了解，不去使用也是没有什么用的。 List、Set、Map cloneable接口实现原理克隆规则：1、基本类型如果变量是基本类型，则拷贝其值，比如int、float等。2、 对象如果变量是一个实例对象，则拷贝其地址引用，也就是说新对象和原来对象是共用实例变量的。3、 String字符串若变量为String字符串，则拷贝其地址引用。但是在修改时，它会从字符串池中重新生成一个新的字符串，原有的对象保持不变。 使用：Object.java的clone()是一个native方法，当需要克隆时，子类实现Cloneable接口后，重写clone()，调用super.clone()。需要注意涉及到深、浅拷贝。 实现深克隆：1、先对对象进行序列化，紧接着马上反序列化出2、先调用super.clone()方法克隆出一个新对象来，然后在子类的clone()方法中手动给克隆出来的非基本数据类型（引用类型）赋值，比如ArrayList的clone()方法：3、在clone方法里面，递归克隆非基本类型的成员变量 1234567891011121314151617181920212223242526public class Administrator implements Cloneable &#123; private User user; private Boolean editable; public Administrator(User user, Boolean editable) &#123; this.user = user; this.editable = editable; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; Bean bean = (Bean) super.clone(); // 实现深克隆，需要User实现了Cloneable接口 bean.user = (ChildBean) bean.user.clone(); return bean; &#125; @Override public int hashCode() &#123; // 老规矩 &#125; @Override public boolean equals(Object obj) &#123; // 老规矩 &#125; // 老规矩&#125; Java中的clone()和Cloneable接口 Java创建对象的几种方式(1) 用new语句创建对象，这是最常见的创建对象的方法。(2) 运用反射手段,调用java.lang.Class或者java.lang.reflect.Constructor类的newInstance()实例方法。(3) 调用对象的clone()方法。(4) 运用反序列化手段，调用java.io.ObjectInputStream对象的 readObject()方法。 (1)和(2)都会明确的显式的调用构造函数 ；(3)是在内存上对已有对象的影印，所以不会调用构造函数 ；(4)是从文件中还原类的对象，也不会调用构造函数。 异常分类以及处理机制 Error是无法处理的异常，比如OutOfMemoryError，一般发生这种异常，JVM会选择终止程序。因此我们编写程序时不需要关心这类异常。 Exception，也就是我们经常见到的一些异常情况，这些异常是我们可以处理的异常，是所有异常类的父类。 unchecked exception（非受查异常），包括Error和RuntimeException，比如常见的NullPointerException、IndexOutOfBoundsException。对于RuntimeException，java编译器不要求必须进行异常捕获处理或者抛出声明，由程序员自行决定。 checked exception（受查异常），也称非运行时异常（运行时异常以外的异常就是非运行时异常），由代码能力之外的因素导致的运行时错误。java编译器强制程序员必须进行捕获处理，比如常见的有IOExeption和SQLException。如果不进行捕获或者抛出声明处理，编译都不会通过。 典型的RuntimeException包括NullPointerException、IndexOutOfBoundsException、IllegalArgumentException等。 典型的非RuntimeException包括IOException、SQLException等。 wait和sleep的区别wait：调用后，必须被通知才能重新运行，且释放锁资源。 sleep：睡眠一定时间后继续执行，且不释放锁资源。 首先，要记住这个差别，“sleep是Thread类的方法,wait是Object类中定义的方法”。尽管这两个方法都会影响线程的执行行为，但是本质上是有区别的。 Thread.sleep不会导致锁行为的改变，如果当前线程是拥有锁的，那么Thread.sleep不会让线程释放锁。如果能够帮助你记忆的话，可以简单认为和锁相关的方法都定义在Object类中，因此调用Thread.sleep是不会影响锁的相关行为。 Thread.sleep和Object.wait都会暂停当前的线程，对于CPU资源来说，不管是哪种方式暂停的线程，都表示它暂时不再需要CPU的执行时间。OS会将执行时间分配给其它线程。区别是，调用wait后，需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间。 线程的状态参考 Thread.State的定义。新创建的但是没有执行（还没有调用start())的线程处于“就绪”，或者说Thread.State.NEW状态。 Thread.State.BLOCKED（阻塞）表示线程正在获取锁时，因为锁不能获取到而被迫暂停执行下面的指令，一直等到这个锁被别的线程释放。BLOCKED状态下线程，OS调度机制需要决定下一个能够获取锁的线程是哪个，这种情况下，就是产生锁的争用，无论如何这都是很耗时的操作。 数组在内存中如何分配对象在堆上分配连续空间。 Java 并发synchronized 的实现原理以及锁优化？JVM基于进入和退出Monitor对象来实现方法同步和代码同步。使用monitorenter和monitorexit指令实现。 每个对象有一个监视器锁（monitor）； 偏向锁：使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点，没有字节码在执行）。 轻量级锁：轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁； 重量级锁。 volatile 的实现原理？通过lock前缀实现，底层是通过总线锁定和缓存锁定来实现。 Lock前缀指令会引起处理器缓存回写到内存。一个处理器的缓存回写到内存会导致其他处理器的缓存无效。 Java 的信号灯？控制并发线程数量。 通过AQS来实现的。 12345678910111213141516171819202122232425262728293031public class SemaphoreTest &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newCachedThreadPool(); final Semaphore sp = new Semaphore(3); for(int i=0;i&lt;10;i++)&#123; Runnable runnable = new Runnable()&#123; public void run()&#123; try &#123; sp.acquire(); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("线程" + Thread.currentThread().getName() + "进入，当前已有" + (3-sp.availablePermits()) + "个并发"); try &#123; Thread.sleep((long)(Math.random()*10000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("线程" + Thread.currentThread().getName() + "即将离开"); sp.release(); //下面代码有时候执行不准确，因为其没有和上面的代码合成原子单元 System.out.println("线程" + Thread.currentThread().getName() + "已离开，当前已有" + (3-sp.availablePermits()) + "个并发"); &#125; &#125;; service.execute(runnable); &#125; &#125;&#125; synchronized 在静态方法和普通方法的区别？静态方法和实例方法不是同一把锁 怎么实现所有线程在等待某个事件的发生才会去执行？CountDownLatch、CyclicBarrier CAS？CAS 有什么缺陷，如何解决？CompareAndSwap，不用加锁 存在ABA问题，通过添加版本号来区分（AtomicStampedReference）；循环时间开销大； synchronized 和 lock 有什么区别？ lock能够非阻塞获取锁、中断地获取锁、超时获取锁、更加灵活。 悲观锁与乐观锁 synchronized由jvm自动释放，lock需要手动释放 在资源竞争不是很激烈的情况下，Synchronized的性能要优于ReetrantLock，但是在资源竞争很激烈的情况下，Synchronized的性能会下降几十倍，但是ReetrantLock的性能能维持常态； Synchronized与Lock锁的区别 Hashtable 是怎么加锁的 ？synchronized HashMap 的并发问题？死循环导致CPU100%使用 HashMap的死循环 ConcurrenHashMap 介绍？1.8 中为什么要用红黑树？彻底看懂 so called 红黑树红黑树深入剖析及Java实现 AQS抽象队列同步器，AbstractQueueSynchronizer。 模板方法 volatile int 状态变量 CAS 同步队列（FIFO双向队列） 共享、独占获取同步状态 如何检测死锁？怎么预防死锁？检测： cpu使用率低 io使用率低 jstack 预防： 资源使用顺序 增加资源 超时退出资源 Java 内存模型？Java内存模型定义了多线程之间共享变量的可见性以及如何在需要的时候对共享变量进行同步。 Java内存模型定义了volatile和synchronized的行为，更重要的是保证了同步的java程序在所有的处理器架构下面都能正确的运行。 happens-before规则 重排序、内存屏障 如何保证多线程下 i++ 结果正确？synchronized、lock 线程池的种类，区别和使用场景？ newCachedThreadPool：适用于执行很多的短期异步任务的小程序，或者负载比较轻的服务器;是一个根据需要创建线程的线程池 newFixedThreadPool：FixedThreadPool适用于为了满足管理资源的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。 newSingleThreadExecutor：适用于需要保证顺序地执行各个任务，并且在任意时间点不会有多个线程在活动的场景。 newScheduledThreadPool：适用于需要在多个后台线程执行周期任务，同时为了满足资源管理需求需要限制后台线程数量的应用场景。 分析线程池的实现原理和线程的调度过程？worker从队列中不断取任务执行，当任务队列为空时，worker线程阻塞； 线程池如何调优，最大数目如何确认？取决于任务的类型，CPU密集型可以coreNum + 1；IO密集型可以2coreNum； ThreadLocal原理，用的时候需要注意什么？ThreadLocal CountDownLatch 和 CyclicBarrier 的用法，以及相互之间的差别?区别：CyclicBarrier可以重复使用，CountDownLatch只能使用一次。 LockSupport工具LockSupport Condition接口及其实现原理底层依赖LockSupport方法 condition Fork/Join框架的理解需要通过ForkJoinPool来提交任务。任务一般通过使用ForkJoinTask的子类来实现： RecursiveAction：用于没有返回结果的任务 RecursiveTask：用于有返回结果的任务 12ForkJoinPool forkJoinPool = newForkJoinPool();Future result = forkJoinPool.submit(task); 任务的切割: 12345678910111213// 分割任务task.fork();public final ForkJoinTask&lt;V&gt; fork() &#123; Thread t; if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) // ForkJoinPool.WorkQueue workQueue，workQueue是ForkJoinPool的全局变量 // 所有分割出来的任务都在一个queue中 ((ForkJoinWorkerThread)t).workQueue.push(this); else ForkJoinPool.common.externalPush(this); return this; &#125; 分段锁的原理,锁力度减小的思考八种阻塞队列以及各个阻塞队列的特性ArrayBlockingQueue ：由数组结构组成的有界阻塞队列。LinkedBlockingQueue ：由链表结构组成的有界阻塞队列。PriorityBlockingQueue ：支持优先级排序的无界阻塞队列。DelayQueue：使用优先级队列实现的无界阻塞队列。SynchronousQueue：不存储元素的阻塞队列。LinkedTransferQueue：链表结构组成的无界阻塞队列。LinkedBlockingDeque：链表结构组成的双向阻塞队列。 方法/处理方式 抛出异常 返回特殊值 一直阻塞 超时退出 插入 add(e) offer(e) put(e) offer(e, time, unit) 移除 remove() poll () take() poll(time, unit) 检查 element() peek() 不可用 不可用 如果是无界阻塞队列，队列不可能会出现满的情况，所以使用put或offer方法永远不会被阻塞，而且使用offer方法时，该方法永远返回rue。 实现： 通过Lock和Condition实现，插入市判断容量调用LockSupport的await或signal方法 JVM详细jvm内存模型jvm内存模型 讲讲什么情况下回出现内存溢出，内存泄漏？内存溢出：指程序申请内存时,没有足够的内存空间使用 内存泄漏：指程序申请了内存后(new),用完的内存没有释放(delete),一直被某个或某些实例所持有却不再被使用导致 GC 不能回收 https://www.jianshu.com/p/e97ed5d8a403关于java内存泄露的总结–引用的类型：强引用，弱引用，软引用 说说Java线程栈https://blog.csdn.net/hust_superman/article/details/39402087 JVM 年轻代到年老代的晋升过程的判断条件是什么呢？ 大对象直接进入老年代 存活一定时间的年轻代晋升老年代 同一年代的对象在monitor gc后，占用内存大于Survivor的二分之一，晋升老年代 JVM 出现 fullGC 很频繁，怎么去线上排查问题？ ​ 类加载为什么要使用双亲委派模式，有没有什么场景是打破了这个模式？http://www.cnblogs.com/lanxuezaipiao/p/4138511.html 解决基础类的统一问题 打破场景： 线程上下文类加载器（Thread Context Classloader） OSGI 类的实例化顺序https://blog.csdn.net/zd836614437/article/details/64126826 https://segmentfault.com/a/1190000004527951 JVM垃圾回收机制，何时触发MinorGC等操作Minor GC触发条件：当Eden区满时，触发Minor GC。 Full GC触发条件： （1）调用System.gc时，系统建议执行Full GC，但是不必然执行 （2）老年代空间不足 （3）方法区空间不足 （4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存 （5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 JVM 中一次完整的 GC 流程（从 ygc 到 fgc）是怎样的答：对象优先在Eden区中分配，若没有足够空间，Minor GC；大对象（需要大量连续内存空间）直接进入老年态；长期存活的对象进入老年态。如果对象在新生代出生并经过第一次MGC后仍然存活，年龄+1，若年龄超过一定限制（15），则被晋升到老年态。 https://blog.csdn.net/zd836614437/article/details/64126826 各种回收器，各自优缺点，重点CMS、G1 名称 优点 缺点 Serial client机器上、简单而高效 单线程；STW ParNew 多线程 STW Parallel Scavenge 时间可控 Serial Old 单线程；STW Parallel Old CMS 占用用户时间少；并发收集、低停顿 CPU资源非常敏感；无法处理浮动垃圾；空间碎片 G1 无空间碎片；低停顿；并发执行；支持大内存； 是的 CMS收集器和G1收集器优缺点g1 gc 各种回收算法 标记 - 清除 标记 - 整理 复制 分代收集算法 OOM错误，stackoverflow错误，permgen space错误https://my.oschina.net/liting/blog/476918 JVM 之 OopMap 和 RememberedSetOopMap：记录了从栈到堆的引用关系，以避免全栈扫描，加快枚举根节点的速度。它的另外一个更根本的作用是，可以帮助 HotSpot 实现准确式 GC。 RememberSet：记录老年代对象引用新生代对象。 SpringBeanFactory 和 FactoryBean？BeanFactory: BeanFactory，以Factory结尾，表示它是一个工厂类(接口)，用于管理Bean的一个工厂。在Spring中，BeanFactory是IOC容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。 Spring为我们提供了许多易用的BeanFactory实现，XmlBeanFactory就是常用的一个，该实现将以XML方式描述组成应用的对象及对象间的依赖关系。XmlBeanFactory类将持有此XML配置元数据，并用它来构建一个完全可配置的系统或应用。 123456789// No.1Resource resource = new FileSystemResource("beans.xml");BeanFactory factory = new XmlBeanFactory(resource);// No.2ClassPathResource resource = new ClassPathResource("beans.xml");BeanFactory factory = new XmlBeanFactory(resource);// No.3ApplicationContext context = new ClassPathXmlApplicationContext(new String[] &#123;"applicationContext.xml", "applicationContext-part2.xml"&#125;);BeanFactory factory = (BeanFactory) context; FactoryBean: 实现 FactoryBean 的类表明此类也是一个Bean，类型为工厂Bean（Spring中共有两种bean，一种为普通bean，另一种则为工厂bean）。顾名思义，它也是用来管理Bean的，而它本身由spring管理。 FactoryBean管理的bean实际上也是由spring进行配置、实例化、管理，因此由FactoryBean管理的bean不能再次配置到spring配置文件中（xml、java类配置、注解均不可以），否则会报异常。 Spring IOC 的理解，其初始化过程？12ApplicationContext appContext = new ClassPathXmlApplicationContext("cjj/models/beans.xml");Person p = (Person)appContext.getBean("person"); 上面代码中，在创建ApplicationContext实例对象过程中会创建一个spring容器，该容器会读取配置文件”cjj/models/beans.xml”,并统一管理由该文件中定义好的所有bean实例对象，如果要获取某个bean实例，使用getBean方法就行了。例如我们只需要将Person提前配置在beans.xml文件中（可以理解为注入），之后我们可以不需使用new Person()的方式创建实例，而是通过容器来获取Person实例，这就相当于将Person的控制权交由spring容器了，差不多这就是控制反转的概念。 Spring中有两个主要的容器系列： 实现BeanFactory接口的简单容器； 实现ApplicationContext接口的高级容器。ApplicationContext比较复杂，它不但继承了BeanFactory的大部分属性，还继承其它可扩展接口，扩展的了许多高级的属性。 初始化过程： Resource定位（Bean的定义文件定位） 将Resource定位好的资源载入到BeanDefinition 将BeanDefiniton注册到容器中 容器初始化的时候会预先对单例和非延迟加载的对象进行预先初始化。其他的都是延迟加载是在第一次调用getBean 的时候被创建。 第一步 Resource定位可以通过先获取resource，再获取beanFactory 12Resource resource = new FileSystemResource("beans.xml");BeanFactory factory = new XmlBeanFactory(resource); FileSystemResource：以文件的绝对路径方式进行访问资源，效果类似于Java中的File; ClassPathResourcee：以类路径的方式访问资源，效果类似于this.getClass().getResource(“/“).getPath(); ServletContextResource：web应用根目录的方式访问资源，效果类似于request.getServletContext().getRealPath(“”); UrlResource：访问网络资源的实现类。例如file: http: ftp:等前缀的资源对象; ByteArrayResource: 访问字节数组资源的实现类。 也可以直接创建applicationContext对象： 12345678910111213public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; //super方法为容器设置好Bean资源加载器 //该方法最终会调用到AbstractApplicationContext的无参构造方法 //这里会默认设置解析路径的模式为Ant-style super(parent); //设置Bean定义资源文件的路径 setConfigLocations(configLocations); if (refresh) &#123; //调用容器的refresh，载入BeanDefinition的入口 refresh(); &#125;&#125; 注：ApplicationContext的所有实现类都实现RecourceLoader接口，因此可以直接调用getResource（参数）获取Resoure对象。不同的ApplicatonContext实现类使用getResource方法取得的资源类型不同，例如：FileSystemXmlApplicationContext.getResource获取的就是FileSystemResource实例；ClassPathXmlApplicationContext.gerResource获取的就是ClassPathResource实例；XmlWebApplicationContext.getResource获取的就是ServletContextResource实例，另外像不需要通过xml直接使用注解@Configuation方式加载资源的AnnotationConfigApplicationContext等等。 第二步 通过返回的resource对象，进行BeanDefinition的载入总之，BeanDefinition相当于一个数据结构，这个数据结构的生成过程是根据定位的resource资源对象中的bean而来的，这些bean在Spirng IoC容器内部表示成了的BeanDefintion这样的数据结构，IoC容器对bean的管理和依赖注入的实现都是通过操作BeanDefinition来进行的。 1.构造BeanFactory时，首先调用的是BeanDefinitionReader类型的reader属性的loadBeanDefinitions()方法，是整个资源加载的切入点。 封装资源文件：当进入BeanDefinitionReader后首先对参数Resource进行EncodedResource类进行封装 获取输入流：从Resource中获取InputStream并构造InputSource 通过构造器的InputSource实例和Resource实例继续调用loadBeanDefinitions. 2.loadBeanDefinition调用doLoadBeanDefinitons方法，完成以下三个方法 对XML文档的验证模式 用DocumentLoader处理资源文件，生成Document 根据返回的Document信息注册bean信息 第三步，将BeanDefiniton注册到容器中最终Bean配置会被解析成BeanDefinition并与beanName,Alias一同封装到BeanDefinitionHolder中,之后beanFactory.registerBeanDefinition(beanName, bdHolder.getBeanDefinition())，注册到DefaultListableBeanFactory.beanDefinitionMap中。之后客户端如果要获取Bean对象，Spring容器会根据注册的BeanDefinition信息进行实例化。 参考1 参考2 BeanFactory 和 ApplicationContext？ApplicationContext 继承BeanFactory，添加了一些属性和方法。 BeanFactory容器中，不会调用ApplicationContextAware接口的setApplicationContext()方法， BeanPostProcessor接口的postProcessBeforeInitialzation()方法和postProcessAfterInitialization()方法不会自动调用，必须自己通过代码手动注册 BeanFactory容器启动的时候，不会去实例化所有Bean,包括所有scope为singleton且非懒加载的Bean也是一样，而是在调用的时候去实例化。 Spring Bean 的生命周期，如何被管理的？https://www.jianshu.com/p/3944792a5fff Spring Bean 的加载过程是怎样的？https://segmentfault.com/a/1190000012887776 http://www.cnblogs.com/xrq730/p/6285358.html 如果要你实现Spring AOP，请问怎么实现？如果要你实现Spring IOC，你会注意哪些问题？Spring 是如何管理事务的，事务管理机制？ 编程式事务管理 TransactionDefinition PlatformTransactionManager TransactionStatus 声明式事务管理(AOP和IOC) DataSource TransactionManager https://blog.csdn.net/justloveyou_/article/details/73733278 Spring 的不同事务传播行为有哪些，干什么用的？浅析Spring事务传播行为 Spring中事务的隔离级别[MySQL事务隔离级别和Spring事务关系介绍 Spring 中用到了那些设计模式？https://www.cnblogs.com/yuefan/p/3763898.html http://www.uml.org.cn/j2ee/201301074.asp 设计模式之创建型模式 Spring MVC 的工作原理？SpringMVC工作原理 Spring 循环注入的原理？Spring AOP的理解，各个术语，他们是怎么相互工作的？分离业务逻辑和系统逻辑；有各种各样的常见的很好的方面的例子，如日志记录、审计、声明式事务、安全性和缓存等 原理：jdk动态代理、cglib动态代理与AspectJ的静态代理不同，Spring AOP使用的动态代理，所谓的动态代理就是说AOP框架不会去修改字节码，而是在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。 https://wiki.jikexueyuan.com/project/spring/aop-with-spring.htmlhttp://www.importnew.com/24305.html Spring 如何保证 Controller 并发的安全？https://blog.csdn.net/hejingyuan6/article/details/50363647 http://www.cnblogs.com/duanxz/p/5051916.html NettyBIO、NIO和AIONetty 的各大组件【死磕Netty】—–Netty的核心组件 Netty的线程模型Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(一)Netty概述 TCP 粘包/拆包的原因及解决方法TCP粘包，拆包及解决方法Netty概述 了解哪几种序列化协议？包括使用场景和如何去选择影响序列化性能的关键因素：1、序列化后的码流大小（网络带宽的占用）；2、序列化的性能（CPU资源占用）；3、是否支持跨语言（异构系统的对接和开发语言切换）。 1、json2、xml3、Protobuf4、Avro5、Thrift Netty概述 Netty的零拷贝实现Netty的零拷贝体现在三个方面： Netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才写入Socket中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。 Netty提供了组合Buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个Buffer那样方便的对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。 Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。 netty相关概念 Netty的高性能表现在哪些方面1、并发高nio、reactor模型2、传输快zero copy3、封装好api简单 Netty入门教程——认识Netty 分布式相关Zookeeper的用途，选举的原理是什么？zookeeper原理和适用场景zookeeper watch机制zookeeper的选举策略redis/zk节点宕机如何处理如何做一个分布式锁Dubbo的底层实现原理和机制Dubbo的服务请求失败怎么处理描述一个服务从发布到被消费的详细过程分布式系统怎么做服务治理接口的幂等性的概念重连机制会不会造成错误如何实现负载均衡，有哪些算法可以实现？用过哪些MQ，怎么用的，和其他mq比较有什么优缺点，MQ的连接是线程安全的吗消息中间件如何解决消息丢失问题MQ系统的数据如何保证不丢失数据的垂直拆分水平拆分。列举出你能想到的数据库分库分表策略；分库分表后，如何解决全表查询的问题对分布式事务的理解分布式集群下如何做到唯一序列号全局ID数据库mysql分页有什么优化https://blog.csdn.net/bingduanlbd/article/details/51767850 https://my.oschina.net/No5stranger/blog/158202 两阶段锁协议https://www.cnblogs.com/zszmhd/p/3365220.html 悲观锁、乐观锁悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。 MySQL 乐观锁与悲观锁 深入理解乐观锁与悲观锁 MySQL InnoDB中使用悲观锁要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。set autocommit=0; 组合索引，最左原则mysql索引及查询优化 mysql 的表锁、行锁行锁：使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。 mysql 性能优化1、建索引2、查询优化3、数据类型（比如用ENUM代替VARCHAR等） mysql索引及查询优化 mysql的索引分类：B+，hash；什么情况用什么索引MySQL索引背后的数据结构及算法原理 事务的特性和隔离级别 原子性 一致性 持久性 隔离性 Serializable（串行化）：可避免脏读、不可重复读、幻读的发生。（级别最高） Repeatable-read（可重复读）：可避免脏读、不可重复读的发生。 Read-committed（读已提交）：可避免脏读的发生。 Read-uncommitted（读未提交）：最低级别，任何情况都无法保证。（级别最低） https://blog.csdn.net/lamp_yang_3533/article/details/79344736 http://blog.sina.com.cn/s/blog_8020e4110101bfc6.html RedisRedis用过哪些数据数据，以及Redis底层怎么实现String: int、SDSlist: linkedlist、ziplistmap: hashtable、ziplistset: hashtable、intsetsorted-set：ziplist、skiplist + hashtable Redis缓存穿透，缓存雪崩redis缓存 如何使用Redis来实现分布式锁 setNX、getSET、get redlock Redis的并发竞争问题如何解决Redis的并发通过队列模式，编程串行模式执行 客户端实现： synchronized redis服务端实现： setNX锁 watch + 事务 Redis持久化的几种方式，优缺点是什么，怎么实现的AOF：丢失数据少；文件大、恢复慢、有bug；RDB：文件小、恢复快；丢失数据多redis持久化 Redis的缓存过期策略Redis的缓存过期策略 Redis集群，高可用，原理Redis缓存分片优点 性能的提升，单机Redis的网络I/O能力和计算资源是有限的，将请求分散到多台机器，充分利用多台机器的计算能力可网络带宽，有助于提高Redis总体的服务能力。 存储的横向扩展，即使Redis的服务能力能够满足应用需求，但是随着存储数据的增加，单台机器受限于机器本身的存储容量，将数据分散到多台机器上存储使得Redis服务可以横向扩展。 缺点 多键操作是不被支持的，比如我们将要批量操作的键被映射到了不同的Redis实例中。 多键的Redis事务是不被支持的。 分区的最小粒度是键，因此我们不能将关联到一个键的很大的数据集映射到不同的实例。 当应用分区的时候，数据的处理是非常复杂的，比如我们需要处理多个rdb/aof文件，将分布在不同实例的文件聚集到一起备份。 添加和删除机器是很复杂的，例如Redis集群支持几乎运行时透明的因为增加或减少机器而需要做的rebalancing,然而像客户端和代理分区这种方式是不支持这种功能的。 分布方式 范围分区 hash分区 Pre-Sharding：我们可以开启多个Redis实例，尽管是一台物理机器，我们在刚开始的时候也可以开启多个实例。我们可以从中选择一些实例，比如32或64个实例来作为我们的工作集群。当一台物理机器存储不够的时候，我们可以将一般的实例移动到我们的第二台物理机上，依次类对，我们可以保证集群中Redis的实例数不变，又可以达到扩充机器的目的。 Redis分区实现原理 Redis的数据淘汰策略volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.allkeys-lru -&gt; Evict any key using approximated LRU.volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.allkeys-lfu -&gt; Evict any key using approximated LFU.volatile-random -&gt; Remove a random key among the ones with an expire set.allkeys-random -&gt; Remove a random key, any key.volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)noeviction -&gt; Don’t evict anything, just return an error on write operations. Redis数据淘汰机制 原文 原文]]></content>
  </entry>
  <entry>
    <title><![CDATA[List、Set、Map]]></title>
    <url>%2Fjava%2Fdatastructure%2FListSetMap%2F</url>
    <content type="text"><![CDATA[List，Set都是继承自Collection接口 List 元素有放入顺序； 元素可重复； 可以插入多个null元素 ； 常用的实现类有 ArrayList、LinkedList 和 Vector。ArrayList 最为流行，它提供了使用索引的随意访问，而 LinkedList 则对于经常需要从 List 中添加或删除元素的场合更为合适。 Set 元素无放入顺序（注意：元素虽然无放入顺序，但是元素在set中的位置是有该元素的HashCode决定的，其位置其实是固定的） 元素不可重复 只允许一个 null 元素； TreeSet通过 Comparator 或者 Comparable 维护了一个排序顺序 ； Set 接口最流行的几个实现类是 HashSet、LinkedHashSet 以及 TreeSet。最流行的是基于 HashMap 实现的 HashSet；TreeSet 还实现了 SortedSet 接口，因此 TreeSet 是一个根据其 compare() 和 compareTo() 的定义进行排序的有序容器。 HashSet通过HashMap实现12345678public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public boolean add(E e) &#123; // 添加的元素作为 HashMap 的 key return map.put(e, PRESENT)==null;&#125; LinkedHashSet通过LinkedHashMap实现123public LinkedHashSet() &#123; super(16, .75f, true);&#125; 123HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; TreeSet基于TreeMap实现，构造函数中调用TreeMap的构造函数123456789101112131415161718192021TreeSet(NavigableMap&lt;E,Object&gt; m) &#123; this.m = m; &#125; public TreeSet() &#123; // 无参数构造函数 this(new TreeMap&lt;E,Object&gt;()); &#125; public TreeSet(Comparator&lt;? super E&gt; comparator) &#123; // 包含比较器的构造函数 this(new TreeMap&lt;&gt;(comparator)); &#125; public TreeSet(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); &#125; public TreeSet(SortedSet&lt;E&gt; s) &#123; this(s.comparator()); addAll(s); &#125; Map 不是collection的子接口或者实现类，Map是一个接口； TreeMap 也通过 Comparator 或者 Comparable 维护了一个排序顺序。 Map 里你可以拥有随意个 null 值但最多只能有一个 null 键 Map 接口最流行的几个实现类是 HashMap、LinkedHashMap、Hashtable 和 TreeMap。（HashMap、TreeMap最常用） HashMap1.8的变化 引入了红黑树 扩容hash的优化，利用扩容后的位置的特性，不需要像JDK1.7的实现那样重新计算hash。 resize的时候，不想1.7那样需要倒置元素 Java 8系列之重新认识HashMapJava源码分析：HashMap 1.8 相对于1.7 到底更新了什么？HashMap原理-1.8 put12345678910111213141516171819202122232425262728293031323334353637383940414243444546final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) // table为null时，初始化 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) // 表示没有i位置上没有节点，new一个节点 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 找到目标节点 e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key // 找到目标节点并替换原来的值 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e);// 调用子类实现的方法 return oldValue; &#125; &#125; ++modCount;// 标识修改HashMap的次数 if (++size &gt; threshold) resize();// 扩容 afterNodeInsertion(evict);// 调用子类实现的方法 return null;&#125; getget实际上是调用getNode方法：12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode)// 从红黑树上取 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123;// 在链表中取 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 扩容过程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 链表优化重hash的代码块 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;`` Java 8系列之重新认识HashMapHashMap原理-1.8 死锁HashMap的死循环 LinkedHashMapLinkedHashMap 能够做到按照插入顺序或者访问顺序进行迭代，这样在我们以后的开发中遇到相似的问题，才能想到用 LinkedHashMap 来解决，否则就算对其内部结构非常了解，不去使用也是没有什么用的。 put123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; newNode实际上调用的是子类重写的方法123456789101112131415161718Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); linkNodeLast(p); return p;&#125;// 新节点放入末尾，并且是双向的private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125;&#125; afterNodeAccess 和 afterNodeInsertion 也是子类重写的方法1234567891011121314151617181920212223242526272829303132void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // 当accessOrder为true时，move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125;&#125;void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125; foreach遍历时，是通过前后的指针来取出来的，所以是有序的12345678910public void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; if (action == null) throw new NullPointerException(); int mc = modCount; // 根据指针的关系 for (LinkedHashMap.Entry&lt;K,V&gt; e = head; e != null; e = e.after) action.accept(e.key, e.value); if (modCount != mc) throw new ConcurrentModificationException();&#125; TreeMaphttp://shmilyaw-hotmail-com.iteye.com/blog/1836431https://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html彻底看懂 so called 红黑树 使用场景 如果你经常会使用索引来对容器中的元素进行访问，那么 List 是你的正确的选择。如果你已经知道索引了的话，那么 List 的实现类比如 ArrayList 可以提供更快速的访问,如果经常添加删除元素的，那么肯定要选择LinkedList。 如果你想容器中的元素能够按照它们插入的次序进行有序存储，那么还是 List，因为 List 是一个有序容器，它按照插入顺序进行存储。 如果你想保证插入元素的唯一性，也就是你不想有重复值的出现，那么可以选择一个 Set 的实现类，比如 HashSet、LinkedHashSet 或者 TreeSet。所有 Set 的实现类都遵循了统一约束比如唯一性，而且还提供了额外的特性比如 TreeSet 还是一个 SortedSet，所有存储于 TreeSet 中的元素可以使用 Java 里的 Comparator 或者 Comparable 进行排序。LinkedHashSet 也按照元素的插入顺序对它们进行存储。 如果你以键和值的形式进行数据存储那么 Map 是你正确的选择。你可以根据你的后续需要从 Hashtable、HashMap、TreeMap 中进行选择。 注：以上源码基于jdk1.8]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm太慢， 淘宝npm镜像使用方法]]></title>
    <url>%2Fnpm%2F</url>
    <content type="text"><![CDATA[临时使用1npm --registry https://registry.npm.taobao.org install express 持久使用1npm config set registry https://registry.npm.taobao.org 配置后可通过下面方式来验证是否成功 npm config get registry npm info express 通过cnpm使用1npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm install express 设置代理1npm config set proxy http://127.0.0.1:1086 原文]]></content>
      <categories>
        <category>nodejs</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap]]></title>
    <url>%2Fjava%2Fdatastructure%2FConcurrentHashMap%2F</url>
    <content type="text"><![CDATA[putgetresize]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最佳实践]]></title>
    <url>%2F%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[非法的方法1234// 不允许调用方法public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; 空指针校验123// 空指针校验if (key == null) throw new NullPointerException(); 非法参数12345if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException();]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[算法]]></title>
    <url>%2F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序Timsort原理介绍Timsort排序算法]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[收纳]]></title>
    <url>%2F%E6%94%B6%E7%BA%B3%2F</url>
    <content type="text"><![CDATA[不换大衣橱，简单3步解决衣物收纳难题（附叠衣服技巧图） 衣柜如何收纳，能更简洁而且不容易乱？]]></content>
  </entry>
  <entry>
    <title><![CDATA[索引]]></title>
    <url>%2Fmysql%2F%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[简单介绍一下MYSQL的索引分类，并给出几个常见问题，大家自己去探索加深理解，权当抛砖引玉了。 从数据结构角度1、B+树索引2、hash索引3、FULLTEXT索引（InnoDB引擎5.7以后支持）4、R-Tree索引（用于对GIS数据类型创建SPATIAL索引）问题：这些索引的区别跟用途在哪？B+树相比hash的优点在哪？ 从物理存储角度1、聚簇索引（clustered index）2、非聚簇索引（non-clustered index）问题：实现方式有什么差异？ 从逻辑角度1、主键索引2、单列索引3、多列索引4、唯一索引问题：多列索引有什么命中规则？这几种索引对加锁有什么影响？ https://blog.csdn.net/wuxing26jiayou/article/details/76596174]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>index</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql合集]]></title>
    <url>%2Fmysql%2Fmysql%E5%90%88%E9%9B%86%2F</url>
    <content type="text"><![CDATA[limit优化Mysql优化实践（分页优化） 事务MySQL事务隔离级别和Spring事务关系介绍 锁和索引MySQL 加锁处理分析Innodb 中 RR 隔离级别能否防止幻读？MySQL的InnoDB的幻读问题Clustered and Secondary IndexesSQL中的where条件，在数据库中提取与应用浅析 MySQL学习之——锁(行锁、表锁、页锁、乐观锁、悲观锁等) MySQL 索引及查询优化总结 MySQL索引背后的数据结构及算法原理 干货：mysql索引的数据结构 InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。 这里还可能存在另外一个问题，虽然我们对method_name 使用了唯一索引，并且显示使用for update来使用行级锁。但是，MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。 mysql分布式锁]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2Fdesign-pattern%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[创建新模式简单工厂首先将需要创建的各种不同对象（例如各种不同的 Chart 对象）的相关代码封装到不同的类中，这些类称为具体产品类，而将它们公共的代码进行抽象和提取后封装在一个抽象产品类中，每一个具体产品类都是抽象产品类的子类；然后提供一个工厂类用于创建各种产品，在工厂类中提供一个创建产品的工厂方法，该方法可以根据所传入的参数不同创建不同的具体产品对象；客户端只需调用工厂类的工厂方法并传入相应的参数即可得到一个产品对象。]]></content>
  </entry>
  <entry>
    <title><![CDATA[如果看得懂，本篇价值100万]]></title>
    <url>%2Finvest%2F%E9%A3%98%E4%BB%99%2F%E5%A6%82%E6%9E%9C%E7%9C%8B%E5%BE%97%E6%87%82%EF%BC%8C%E6%9C%AC%E7%AF%87%E4%BB%B7%E5%80%BC100%E4%B8%87%2F</url>
    <content type="text"><![CDATA[大周期择时模式依赖于大级别波动，如果没有大波动或者周期太久，就没有大收益。 价投模式依赖于深研，如果没有深研，就容易踩坑或者卖飞。 烟蒂模式依赖于风险偏好不断修正，如果资金越涨越抱团，抄底就很快就没子弹了。 做热点打板模式依赖于傻子多，如果没有傻子，就没人搏傻。 做趋势依赖于主线判断，如果判断错误，就容易两边打脸。 做套利依赖于没人发现套利空间，如果没有套利空间，就没有办法获利。 飘仙尽量不根据大周期对仓位进行显著调节，对企业不深研，不完全捡烟蒂，不参与热门股炒作，不过分判断主线，不专门研究套利，去除以上干扰因子，打造“去依赖”的投资体系，致力于做到吹吹牛、装装逼就把钱挣了。 如果看得懂，本篇价值100万]]></content>
      <categories>
        <category>invest</category>
      </categories>
      <tags>
        <tag>飘仙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[去年下半年以来的两极分化，是A股估值体系的第三次革命性变化]]></title>
    <url>%2Finvest%2F%E9%A3%98%E4%BB%99%2F%E6%8A%95%E8%B5%84%E4%B8%89%E4%B8%A4%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[2016年下半年以来的两极分化，陆续有多种逻辑作为解释，从国家队逻辑、到大消费逻辑、大周期逻辑、白马逻辑，一个个刚好蒙对的逻辑逐渐不适用，真正的主线逻辑终于越来越清晰了。 说白了，去年下半年以来的两极分化，是A股估值体系的第三次革命性变化——暨给予行业龙头竞争性溢价。 历史上，估值体系的革命性变化都伴随着投资者结构的变化。 最早A股是纯散户市，全民看K线时代，完全没有估值体系可言，只有庄家和跟庄，越垃圾的股涨的越多，越好的股反而没人碰。 到了2005年之后，公募基金获得了巨大发展，估值体系出现了第一次革命性变化，也就是开始看业绩了。公募基金的风格是厌恶风险、分散投资、不断填补估值洼地，虽然市场整体仍然呈现齐涨齐跌现象，但是价值投资理念成为一股清流，价值股逐渐出现涨能跟住，跌能顶住的现象。 2010年之后，独立的职业投资人和私募基金数量剧增，他们的风险偏好比公募基金凶悍很多，往往喜欢抱团取暖，恰逢上市公司市值管理风气日盛，外延式收购蛇吞象实现跨越式发展的上市公司层出不穷，所以，此时估值体系出现了第二次革命性变化，也就是给予小盘股成长性溢价。 2016年之后，国际投资者通过港股通持续入场，恰逢全球牛市的大环境，国际投资者持续不断的买入大市值的行业龙头，大市值股票持续不断的挣钱效应终于摘掉了国内投资者的有色眼镜，国内投资者纷纷发现，大市值的行业龙头们业绩增速丝毫不比中小公司慢，甚至竞争力在自我强化，在各自行业逐渐形成寡头垄断，因此估值体系终于出现了第三次革命性变化，也就是给予行业龙头竞争性溢价。 直至当前，行业龙头的竞争性溢价终于得到了全市场的认可，新的投资理念将逐渐成为未来相当长一段时间的指导思想。 现在的问题是，各行业的龙头都高高在上，一旦出现了新行业龙头被证实，市场就会像狼群一样扑过去，例如京东方。所以，以后择股怎么择，就点到为止了。]]></content>
      <categories>
        <category>invest</category>
      </categories>
      <tags>
        <tag>飘仙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm内存模型]]></title>
    <url>%2Fjava%2Fjvm%2Fjvm%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[内存模型 （1）线程私有区： 程序计数器，记录正在执行的虚拟机字节码的地址； 虚拟机栈：方法执行的内存区，每个方法执行时会在虚拟机栈中创建栈帧； 本地方法栈：虚拟机的Native方法执行的内存区； （2）线程共享区： Java堆：对象分配内存的区域； 方法区：存放类信息、常量、静态变量、编译器编译后的代码等数据； 常量池：存放编译器生成的各种字面量和符号引用，是方法区的一部分。 详细模型 程序计数器PC程序计数器PC，当前线程所执行的字节码行号指示器。每个线程都有自己计数器，是私有内存空间，该区域是整个内存中较小的一块。 当线程正在执行一个Java方法时，PC计数器记录的是正在执行的虚拟机字节码的地址；当线程正在执行的一个Native方法时，PC计数器则为空（Undefined）。 虚拟机栈虚拟机栈，生命周期与线程相同，是Java方法执行的内存模型。每个方法(不包含native方法)执行的同时都会创建一个栈帧结构，方法执行过程，对应着虚拟机栈的入栈到出栈的过程。 栈帧(Stack Frame)结构 栈帧是用于支持虚拟机进行方法执行的数据结构，是属性运行时数据区的虚拟机站的栈元素。见上图， 栈帧包括： 局部变量表 (locals大小，编译期确定)，一组变量存储空间， 容量以slot为最小单位。 操作栈(stack大小，编译期确定)，操作栈元素的数据类型必须与字节码指令序列严格匹配 动态连接， 指向运行时常量池中该栈帧所属方法的引用，为了 动态连接使用。 前面的解析过程其实是静态解析； 对于运行期转化为直接引用，称为动态解析。 方法返回地址 正常退出，执行引擎遇到方法返回的字节码，将返回值传递给调用者 异常退出，遇到Exception,并且方法未捕捉异常，那么不会有任何返回值。 额外附加信息，虚拟机规范没有明确规定，由具体虚拟机实现。 因此，一个栈帧的大小不会受到 异常(Exception) Java虚拟机规范规定该区域有两种异常： StackOverFlowError：当线程请求栈深度超出虚拟机栈所允许的深度时抛出 OutOfMemoryError：当Java虚拟机动态扩展到无法申请足够内存时抛出 123456789101112131415161718192021222324// 栈溢出测试源码package com.paddx.test.memory;/** * Created by root on 2/28/17. */public class StackErrorMock &#123; private static int index = 1; public void call() &#123; index++; call(); &#125; public static void main(String[] args) &#123; StackErrorMock mock = new StackErrorMock(); try &#123; mock.call(); &#125; catch(Throwable e) &#123; System.out.println("Stack deep: " + index); e.printStackTrace(); &#125; &#125;&#125; 运行三次，可以看出每次栈的深度都是不一样的，输出结果如下： 本地方法栈本地方法栈则为虚拟机使用到的Native方法提供内存空间，而前面讲的虚拟机栈式为Java方法提供内存空间。有些虚拟机的实现直接把本地方法栈和虚拟机栈合二为一，比如非常典型的Sun HotSpot虚拟机。 异常(Exception)：Java虚拟机规范规定该区域可抛出StackOverFlowError和OutOfMemoryError。 Java堆Java堆，是Java虚拟机管理的最大的一块内存，也是GC的主战场，里面存放的是几乎所有的对象实例和数组数据。JIT编译器有栈上分配、标量替换等优化技术的实现导致部分对象实例数据不存在Java堆，而是栈内存。 从内存回收角度，Java堆被分为新生代和老年代；这样划分的好处是为了更快的回收内存； 从内存分配角度，Java堆可以划分出线程私有的分配缓冲区(Thread Local Allocation Buffer,TLAB)；这样划分的好处是为了更快的分配内存； 对象创建的过程是在堆上分配着实例对象，那么对象实例的具体结构如下： 对于填充数据不是一定存在的，仅仅是为了字节对齐。HotSpot VM的自动内存管理要求对象起始地址必须是8字节的整数倍。对象头本身是8的倍数，当对象的实例数据不是8的倍数，便需要填充数据来保证8字节的对齐。该功能类似于高速缓存行的对齐。 另外，关于在堆上内存分配是并发进行的，虚拟机采用CAS加失败重试保证原子操作，或者是采用每个线程预先分配TLAB内存. 异常(Exception)：Java虚拟机规范规定该区域可抛出OutOfMemoryError。 下面我们简单的模拟一个堆内存溢出的情况： 12345678910111213141516171819202122232425package com.paddx.test.memory;import java.util.ArrayList;import java.util.List;/** * Created by root on 2/28/17. */public class HeapOomMock &#123; public static void main(String[] args) &#123; List&lt;byte[]&gt; list = new ArrayList&lt;byte[]&gt;(); int i = 0; boolean flag = true; while(flag) &#123; try &#123; i++; list.add(new byte[1024 * 1024]); // 每次增加1M大小的数组对象 &#125;catch(Throwable e) &#123; e.printStackTrace(); flag = false; System.out.println("Count = " + i); // 记录运行的次数 &#125; &#125; &#125;&#125; 首先配置运行时虚拟机的启动参数： 然后运行代码，输出结果如下： 注意，这里我们指定了堆内存的大小为16M，所以这个地方显示的Count=13(这个数字不是固定的)，至于为什么会是13或其他数字，需要根据GC日志来判断。 方法区方法区主要存放的是已被虚拟机加载的类信息、常量、静态变量、编译器编译后的代码等数据。GC在该区域出现的比较少。 异常(Exception)：Java虚拟机规范规定该区域可抛出OutOfMemoryError。 运行时常量池运行时常量池也是方法区的一部分，用于存放编译器生成的各种字面量和符号引用。运行时常量池除了编译期产生的Class文件的常量池，还可以在运行期间，将新的常量加入常量池，比较常见的是String类的intern()方法。 字面量：与Java语言层面的常量概念相近，包含文本字符串、声明为final的常量值等。 符号引用：编译语言层面的概念，包括以下3类： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 但是该区域不会抛出OutOfMemoryError异常。 jdk 1.8中的改进PermGen永久代绝大部分Java程序员应该都见过“java.lang.OutOfMemoryError: PremGen space”异常。这里的“PermGen space”其实指的就是方法区。不过方法区和“PermGen space”又有着本质的区别。前者是JVM的规范，而后者则是JVM规范的一种实现，并且只有HotSpot才有“PermGen space”，而对于其他类型的虚拟机，如JRockit(Oracle)、J9(IBM)并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。最典型的场景就是，在JSP页面比较多的情况，容易出现永久代内存溢出。我们现在通过动态生成类来模拟“PermGen space”的内存溢出： 12345678910111213141516171819202122232425package com.paddx.test.memory;import java.io.File;import java.net.URL;import java.net.URLClassLoader;import java.util.ArrayList;import java.util.List;public class PermGenOomMock &#123; public static void main(String[] args) &#123; URL url = null; List&lt;ClassLoader&gt; classLoaderList = new ArrayList&lt;ClassLoader&gt;(); try &#123; url = new File("/tmp").toURI().toURL(); URL[] urls = &#123;url&#125;; while(true) &#123; ClassLoader loader = new URLClassLoader(urls); classLoaderList.add(loader); loader.loadClass("com.paddx.test.memory.Test"); &#125; &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 123package com.paddx.test.memory; public class Test &#123;&#125; 运行结果如下： 本例中使用的JDK版本是1.7，指定的PermGen区的大小为8M。通过每次生成不同URLClassLoader对象加载Test类，从而生成不同的类对象，这样就能看到我们熟悉的“java.lang.OutOfMemoryError: PermGen space”异常了。这里之所以采用JDK 1.7，是因为在JDK 1.8中，HotSpot已经没有“PermGen space”这个区间了，取而代之是一个叫做Metaspace(元空间)的东西。下面我们就来看看Metaspace与PermGen space的区别。 Metaspace(元空间)其实，移除永久代的工作从JDK 1.7就开始了。JDK 1.7中，存储在永久代的部分数据就已经转移到Java Heap或者Native Heap。但永久代仍存在于JDK 1.7中，并没有完全移除，譬如符号引用(Symbols)转移到了native heap；字面量(interned strings)转移到了Java heap；类的静态变量(class statics)转移到了Java heap。我们可以通过一段程序来比较JDK 1.6、JDK 1.7与JDK 1.8的区别，以字符串常量为例： 12345678910111213141516package com.paddx.test.memory;import java.util.ArrayList;import java.util.List;public class StringOomMock &#123; static String base = "string"; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; String str = base + base; base = str; list.add(str.intern()); &#125; &#125;&#125; 这段程序以2的指数级不断的生成新的字符串，这样可以比较快速的消耗内存。我们通过JDK 1.6、JDK 1.7和JDK 1.8分别运行： JDK 1.6的运行结果： JDK 1.7的运行结果： JDK 1.8的运行结果： 从上述结果可以看出，JDK 1.6下，会出现“PermGen space”的内存溢出，而在JDK 1.7和JDK 1.8中，会出现堆内存溢出，并且JDK 1.8中参数PermSize和MaxPermSize已经失效。因此，可以大致验证JDK 1.7和JDK 1.8中将字符串常量由永久代转移到堆中，并且JDK 1.8中已经不存在永久代的结论。现在我们来看一看元空间到底是一个什么东西？ JDK1.8对JVM架构的改造将类元数据放到本地内存中，另外，将常量池和静态变量放到Java堆里。HotSpot VM将会为类的元数据明确分配和释放本地内存。在这种架构下，类元信息就突破了原来-XX:MaxPermSize的限制，现在可以使用更多的本地内存。这样就从一定程度上解决了原来在运行时生成大量类造成经常Full GC问题，如运行时使用反射、代理等。所以升级以后Java堆空间可能会增加。 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间的最大区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但可以通过以下参数指定元空间的大小： -XX:MetaspaceSize，初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对改值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值。 -XX:MaxMetaspaceSize，最大空间，默认是没有限制的。 除了上面的两个指定大小的选项外，还有两个与GC相关的属性： -XX:MinMetaspaceFreeRatio，在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集。 -XX:MaxMetaspaceFreeRatio，在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集。 现在我们在JDK 1.8重新运行一下上面第二部分(PermGen(永久代))的代码，不过这次不再指定PermSize和MaxPermSize。而是制定MetaspaceSize和MaxMetaspaceSize的大小。输出结果如下： 从输出结果，我们可以看出，这次不再出现永久代溢出，而是出现元空间的溢出。 对象分配规则 对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。 大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。 长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，直到达到阀值对象进入老年区。 动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。 空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。 如何通过参数来控制个各个内存区域参考此文章：JVM（2）：JVM内存结构 参考 http://gityuan.com/2016/01/09/java-memory/ http://blog.csdn.net/universe_ant/article/details/58585854 Java —— 运行时栈帧结构]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC]]></title>
    <url>%2Fjava%2Fjvm%2FGC%2F</url>
    <content type="text"><![CDATA[Minor GC触发条件：当Eden区满时，触发Minor GC。 Full GC触发条件： （1）调用System.gc时，系统建议执行Full GC，但是不必然执行 （2）老年代空间不足 （3）方法区空间不足 （4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存 （5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 Jvm怎么判断对象可以回收了 对象没有引用 作用域发生未捕获异常 程序在作用域正常执行完毕 程序执行了System.exit() 程序发生意外终止（被杀进程等） gc算法 计数器算法 难以解决对象之间循环引用的问题 可达性分析算法在Java语言中，GC Roots包括： 虚拟机栈中引用的对象（本地变量表） 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中引用的对象（Native对象） 可达性算法中不可到达的对象需要经历2次标记过程： 1、第一次标记并进行一次筛选。 筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize方法，或者finzlize方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”，对象被回收。 需要执行finalize方法的对象呗放到F-Queue中 2、第二次标记 在GC前执行F-Queue中的finalize方法，如果还是不可到达，则再次标记，之后会被收集。 方法区（Hotspot中的永久代）的回收条件非常苛刻，只有同时满足以下三个条件才会被回收！ 所有实例被回收 加载该类的ClassLoader被回收 Class对象无法通过任何途径访问(包括反射) 即使满足了上面3个条件，也不一定必然回收。HotSpot提供参数来控制对类的回收。 在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 垃圾收集算法1、标记-清除算法 标记-清除算法采用从根集合进行扫描，对存活的对象对象标记，标记完毕后，再扫描整个空间中未被标记的对象，进行回收，如上图所示。 标记-清除算法不需要进行对象的移动，并且仅对不存活的对象进行处理，在存活对象比较多的情况下极为高效，但由于标记-清除算法直接回收不存活的对象，因此会造成内存碎片！ 2、复制算法 复制算法采用从根集合扫描，并将存活对象复制到一块新的，没有使用过的空间中，这种算法当控件存活的对象比较少时，极为高效，但是带来的成本是需要一块内存交换空间用于进行对象的移动。也就是我们前面提到的s0 s1等空间。 当回首时，将Eden和Survivor中还存活的对象一次性复制到另一块Survivor空间中，最后清理Eden和Survivor。HotSpot默认Eden和Survivor的大小比为8 : 1。当Survivor空间不足，需要老年代进行担保。 3、标记-整理算法 整理算法采用标记-清除算法一样的方式进行对象的标记，但在清除时不同，在回收不存活的对象占用的空间后，会将所有的存活对象往左端空闲空间移动，并更新对应的指针。标记-整理算法是在标记-清除算法的基础上，又进行了对象的移动，因此成本更高，但是却解决了内存碎片的问题。 我们知道，JVM为了优化内存的回收，进行了分代回收的方式，对于新生代内存的回收（minor GC）主要采用复制算法，对于老年代的回首采用“标记-清理”或“标记-整理”算法。下图展示了minor GC的执行过程。 安全点详解 垃圾收集器 新生代 老年代 Serial Serial Old Serial CMS ParNew Serial Old ParNew CMS Parralell Scavenge Serial Old Parralell Scavenge Parralell Old Serial收集器 串行收集器是一个单线程收集器，当JVM需要进行垃圾回收的时候，需要中断所有的用户线程，知道它回收结束为止，因此又号称“Stop The World” 的垃圾回收器。注意，JVM中文名称为java虚拟机，因此它就像一台虚拟的电脑一样在工作，而其中的每一个线程就被认为是JVM的一个处理器，因此大家看到图中的CPU0、CPU1实际为用户的线程，而不是真正机器的CPU，大家不要误解哦。 串行回收方式适合低端机器，是Client模式下的默认收集器，对CPU和内存的消耗不高，适合用户交互比较少，后台任务较多的系统。 Serial收集器默认新旧生代的回收器搭配为Serial+SerialOld ParNew收集器ParNew收集器其实就是多线程版本的Serial收集器，其运行示意图如下 同样有Stop The World的问题，他是多CPU模式下的首选回收器（该回收器在单CPU的环境下回收效率远远低于Serial收集器，所以一定要注意场景哦），也是Server模式下的默认收集器。 Parallel ScavengeParallelScavenge又被称为是吞吐量优先的收集器，器运行示意图如下 ParallelScavenge所提到的吞吐量=程序运行时间/(JVM执行回收的时间+程序运行时间),假设程序运行了100分钟，JVM的垃圾回收占用1分钟，那么吞吐量就是99%。在当今网络告诉发达的今天，良好的响应速度是提升用户体验的一个重要指标，多核并行云计算的发展要求程序尽可能的使用CPU和内存资源，尽快的计算出最终结果，因此在交互不多的云端，比较适合使用该回收器。 ParallelOldParallelOld是老生代并行收集器的一种，使用标记整理算法、是老生代吞吐量优先的一个收集器。这个收集器是JDK1.6之后刚引入的一款收集器，我们看之前那个图之间的关联关系可以看到，早期没有ParallelOld之前，吞吐量优先的收集器老生代只能使用串行回收收集器，大大的拖累了吞吐量优先的性能，自从JDK1.6之后，才能真正做到较高效率的吞吐量优先。其运行示意图如下 SerialOldSerialOld是旧生代Client模式下的默认收集器，单线程执行；在JDK1.6之前也是ParallelScvenge回收新生代模式下旧生代的默认收集器，同时也是并发收集器CMS回收失败后的备用收集器。其运行示意图如下 CMSCMS又称响应时间优先(最短回收停顿)的回收器，使用并发模式回收垃圾，使用标记-清除算法，CMS对CPU是非常敏感的，它的回收线程数=（CPU+3）/4，因此当CPU是2核的时候，回收线程将占用的CPU资源的50%，而当CPU核心数为4时仅占用25%。他的运行示意图如下 CMS模式主要分为4个过程 初始标记：仅仅标记一下GC Roots能直接关联到的对象，速度很快，需要中断所有用户线程 并发标记：进行GC Roots Tracing的过程 重新标记：为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分的标记记录 并发清除：清除操作 初始标记和重新标记仍然需要 stop the world。 缺点： 1、对CPU资源非常敏感。 2、在并发标记阶段，用户线程和标记线程并发执行，而在这个过程中，随着内存引用关系的变化，可能会发生原来标记的对象被释放，进而引发新的垃圾，因此可能会产生一系列的浮动垃圾，不能被回收。 CMS 为了确保能够扫描到所有的对象，避免在InitialMarking 中还有未标识到的对象，采用的方法为找到标记了的对象，并将这些对象放入Stack 中，扫描时寻找此对象依赖的对象，如果依赖的对象的地址在其之前，则将此对象进行标记，并同时放入Stack 中，如依赖的对象地址在其之后，则仅标记该对象。 在进行ConcurrentMarking 时minor GC 也可能会同时进行，这个时候很容易造成旧生代对象引用关系改变，CMS 为了应对这样的并发现象，提供了一个Mod UnionTable 来进行记录，在这个Mod Union Table中记录每次minor GC 后修改了的Card 的信息。这也是ParallelScavenge不能和CMS一起使用的原因。 CMS产生浮动垃圾的情况请见如下示意图 在运行回收过后，c就变成了浮动垃圾。 由于CMS会产生浮动垃圾，当回收过后，浮动垃圾如果产生过多，同时因为使用标记-清除算法会产生碎片，可能会导致回收过后的连续空间仍然不能容纳新生代移动过来或者新创建的大资源，因此会导致CMS回收失败，进而触发另外一次FULL GC，而这时候则采用SerialOld进行二次回收。 同时CMS因为可能产生浮动垃圾，而CMS在执行回收的同时新生代也有可能在进行回收操作，为了保证旧生代能够存放新生代转移过来的数据，CMS在旧生代内存到达全部容量的68%就触发了CMS的回收！ 3、大量空间碎片的产生 GarbageFirst（G1）g1 gc 回收策略1、优先在Edon上分配对象 对于新生代和旧生代，JVM可使用很多种垃圾回收器进行垃圾回收，下图展示了不同生代不通垃圾回收器，其中两个回收器之间有连线表示这两个回收器可以同时使用。 而这些垃圾回收器又分为串行回收方式、并行回收方式合并发回收方式执行，分别运用于不同的场景。如下图所示 2、大对象直接进入老生代 3、年长者(长期存活对象)进入老生代 4、群体效应(大批中年对象进入老生代) 5、担保GC(担保minorGC) 担保GC就是担保minorGC能够满足当前的存储空间，而无需触发老生代的回收，由于大部分对象都是朝生夕死的，因此，在实际开发中这种很起效，但是也有可能会发生担保失败的情况，当担保失败的时候会触发FullGC，但是失败毕竟是少数，因此这种一般是很划算的 Partial GC：并不收集整个GC堆的模式 Young GC：只收集young gen的GC Old GC：只收集old gen的GC。只有CMS的concurrent collection是这个模式 Mixed GC：收集整个young gen以及部分old gen的GC。只有G1有这个模式 Full GC：收集整个堆，包括young gen、old gen、perm gen（如果存在的话）等所有部分的模式。 Full GC定义是相对明确的，就是针对整个新生代、老生代、元空间（metaspace，java8以上版本取代perm gen）的全局范围的GC； Minor GC和Major GC是俗称，在Hotspot JVM实现的Serial GC, Parallel GC, CMS, G1 GC中大致可以对应到某个Young GC和Old GC算法组合； 最重要是搞明白上述Hotspot JVM实现中几种GC算法组合到底包含了什么。 Serial GC算法：Serial Young GC ＋ Serial Old GC （敲黑板！敲黑板！敲黑板！实际上它是全局范围的Full GC）； Parallel GC算法：Parallel Young GC ＋ 非并行的PS MarkSweep GC / 并行的Parallel Old GC（敲黑板！敲黑板！敲黑板！这俩实际上也是全局范围的Full GC），选PS MarkSweep GC 还是 Parallel Old GC 由参数UseParallelOldGC来控制； CMS算法：ParNew（Young）GC + CMS（Old）GC （piggyback on ParNew的结果／老生代存活下来的object只做记录，不做compaction）＋ Full GC for CMS算法（应对核心的CMS GC某些时候的不赶趟，开销很大）； G1 GC：Young GC + mixed GC（新生代，再加上部分老生代）＋ Full GC for G1 GC算法（应对G1 GC算法某些时候的不赶趟，开销很大）； 搞清楚了上面这些组合，我们再来看看各类GC算法的触发条件。简单说，触发条件就是某GC算法对应区域满了，或是预测快满了。比如， 各种Young GC的触发原因都是eden区满了； Serial Old GC／PS MarkSweep GC／Parallel Old GC的触发则是在要执行Young GC时候预测其promote的object的总size超过老生代剩余size； CMS GC的initial marking的触发条件是老生代使用比率超过某值； G1 GC的initial marking的触发条件是Heap使用比率超过某值，跟4.3 heuristics 类似； Full GC for CMS算法和Full GC for G1 GC算法的触发原因很明显，就是4.3 和 4.4 的fancy算法不赶趟了，只能全局范围大搞一次GC了（相信我，这很慢！这很慢！这很慢！）；5 题主说的 “Full GC会先触发一次Minor GC” － 指的应该是 （说错了，我删了） PS MarkSweep GC／Parallel Old GC（Full GC）之前会跑一次Parallel Young GC；原因就是减轻Full GC 的负担。哇～整个picture 是有点乱，希望我整理的还算清楚：） 对象分配规则 对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。 大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。 长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，直到达到阀值对象进入老年区。 动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。 空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。 如何通过参数来控制个各个内存区域参考此文章：JVM（2）：JVM内存结构]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>gc</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[没事看看]]></title>
    <url>%2Flinks%2F</url>
    <content type="text"><![CDATA[Sql ParseTiDB SQL Parser 的实现 Fork/Joinjdk1.8-ForkJoin框架剖析 数据结构红黑树红黑树深入剖析及Java实现红黑树并没有我们想象的那么难(上) 红黑树详细分析，看了都说好 红黑树的变色与旋转 http://shmilyaw-hotmail-com.iteye.com/blog/1836431https://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html javaCollection衍生类源码分析 年底啦，java后台面试题整理 JVM 之 OopMap 和 RememberedSet找出栈上的指针/引用VM博客 https://www.zhihu.com/question/60949531/answer/182115799 ThreadLocalThreadLocal内存泄漏详解ThreadLocal详解ThreadLocal与WeakReference 创业三个步骤，帮你找到合适的创业想法 聊天高情商的人都知道如何聊天聊天的两种能力 投资指数https://xueqiu.com/4776750571/57394021https://xueqiu.com/4776750571/58965236 分级A手把手玩转分级A（上）手把手玩转分级A（中）手把手玩转分级A（下） 可转债转债投资入门（一）：什么是可转债转债投资入门（二）：转债投资四要素 书籍村上春树epub合集https://bbs.feng.com/read-htm-tid-11180611.html]]></content>
      <categories>
        <category>interesting</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[各种概念]]></title>
    <url>%2Fshit%2F%E7%83%82%E8%BD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[IaaS：就是台服务器。 PaaS：就是Tomcat加MySQL。 SaaS：就是三千块一套的加个Logo就能开业的电商网站。 BaaS：Backend as a Service]]></content>
      <categories>
        <category>shit</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Executor框架]]></title>
    <url>%2Fjava%2FExecutor%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[简介Executor两级调用模型 Executor的结构和成员 Executor框架的使用 ThreadPoolExecutorThreadPoolExecutor执行execute： 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（需要获取全局锁）。 如果运行的线程等于或多余corePoolSize，则将任务加入BlockingQueue 如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（需要获取全局锁）。 如果创建新线程将使当前运行的线程超过maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。 FixedThreadPoolFixedThreadPool适用于为了满足管理资源的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 其corePoolSize和maximumPoolSize都被设为nThreads的值。当线程池中的线程数大于corePoolSize时，keepAliveTime为多余的空闲线程等待新任务的最长时间，超过这个时间后多余的线程将被终止。具体在FixedThreadPool的执行过程如下： 如果当前运行的线程数少于corePoolSize，就创建新的线程执行任务 在线程池如果当前运行的线程数等于corePoolSize时，将任务加入到LinkedBlockingQueue等待执行 线程执行完1中的任务后，会在循环中反复从LinkedBlockingQueue获取任务来执行 由于LinkedBlockingQueue使用的无界队列，所以线程池中线程数不会超过corePoolSize，因此不断加入线程池中的任务将被执行，因为不会马上被执行的任务都加入到LinkedBlockingQueue等待了。 SingleThreadExecutorSingleThreadExecutor适用于需要保证顺序地执行各个任务，并且在任意时间点不会有多个线程在活动的场景。 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; corePoolSize和maximumPoolSize都为1，且工作队列为无界队列，所以，当启动了一个线程后，以后所有的工作直接加入工作队列中。 CachedThreadPoolCachedThreadPool是大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者负载比较轻的服务器;是一个根据需要创建线程的线程池 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; CachedThreadPool的corePoolSize为0，maximumPoolSize为Integer.MAX_VALUE，keepAliveTime为60L，意味着多余的空闲线程等待新任务的执行时间为60秒。CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列（SynchronousQueue是一个没有容量的阻塞队列，每个插入操作必须等待另一个线程的对应移除操作），但是CachedThreadPool的maximumPool是无界的。这就意味着如果线程的提交速度高于线程的处理速度，CachedThreadPool会不断创建线程，极端情况是因为创建线程过多耗尽CPU和内存资源。 ScheduledThreadPoolExecutor使用的DelayedWorkQueue是一个无界队列，所以maximumPoolSize参数无效。创建一个支持定时及周期性的任务执行的线程池，多数情况下可用来替代Timer类。ScheduledThreadPoolExecutor适用于需要在多个后台线程执行周期任务，同时为了满足资源管理需求需要限制后台线程数量的应用场景。 ScheduledThreadPoolExecutor123456789101112131415161718public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;public ScheduledThreadPoolExecutor(int corePoolSize) &#123; // 使用的DelayedWorkQueue是一个无界队列，所以maximumPoolSize参数无效。 super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; SingleThreadScheduledExecutor12345678910public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1));&#125;public ScheduledThreadPoolExecutor(int corePoolSize) &#123; // 使用的DelayedWorkQueue是一个无界队列 super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125; DelayedWorkQueueDelayedWorkQueue是一个基于堆的数据结构，类似于DelayQueue和PriorityQueue。在执行定时任务的时候，每个任务的执行时间都不同，所以DelayedWorkQueue的工作就是按照执行时间的升序来排列，执行时间距离当前时间越近的任务在队列的前面（注意：这里的顺序并不是绝对的，堆中的排序只保证了子节点的下次执行时间要比父节点的下次执行时间要大，而叶子节点之间并不一定是顺序的，下文中会说明）。 可见，DelayedWorkQueue是一个基于最小堆结构的队列。堆结构可以使用数组表示，可以转换成如下的数组： 在这种结构中，可以发现有如下特性： 假设，索引值从0开始，子节点的索引值为k，父节点的索引值为p，则： 一个节点的左子节点的索引为：k = p * 2 + 1； 一个节点的右子节点的索引为：k = (p + 1) * 2； 一个节点的父节点的索引为：p = (k - 1) / 2。 offer既然是阻塞队列，入队的操作如add和put方法都调用了offer方法，下面查看一下offer方法：12345678910111213141516171819202122232425262728293031public boolean offer(Runnable x) &#123; if (x == null) throw new NullPointerException(); RunnableScheduledFuture&lt;?&gt; e = (RunnableScheduledFuture&lt;?&gt;)x; final ReentrantLock lock = this.lock; lock.lock(); try &#123; int i = size; // queue是一个RunnableScheduledFuture类型的数组，如果容量不够需要扩容 if (i &gt;= queue.length) grow(); size = i + 1; // i == 0 说明堆中还没有数据 if (i == 0) &#123; queue[0] = e; setIndex(e, 0); &#125; else &#123; // i != 0 时，需要对堆进行重新排序 siftUp(i, e); &#125; // 如果传入的任务已经是队列的第一个节点了，这时available需要发出信号 if (queue[0] == e) &#123; // leader设置为null为了使在take方法中的线程在通过available.signal();后会执行available.awaitNanos(delay); leader = null; available.signal(); &#125; &#125; finally &#123; lock.unlock(); &#125; return true;&#125; siftUp1234567891011121314151617181920// 基于二叉树的实现private void siftUp(int k, RunnableScheduledFuture&lt;?&gt; key) &#123; while (k &gt; 0) &#123; // 找到父节点的索引 int parent = (k - 1) &gt;&gt;&gt; 1; // 获取父节点 RunnableScheduledFuture&lt;?&gt; e = queue[parent]; // 如果key节点的执行时间大于父节点的执行时间，不需要再排序了 if (key.compareTo(e) &gt;= 0) break; // 如果key.compareTo(e) &lt; 0，说明key节点的执行时间小于父节点的执行时间，需要把父节点移到后面 queue[k] = e; // 设置索引为k setIndex(e, k); k = parent; &#125; // key设置为排序后的位置中 queue[k] = key; setIndex(key, k);&#125; 代码很好理解，就是循环的根据key节点与它的父节点来判断，如果key节点的执行时间小于父节点，则将两个节点交换，使执行时间靠前的节点排列在队列的前面。 假设新入队的节点的延迟时间（调用getDelay()方法获得）是5，执行过程如下： 先将新的节点添加到数组的尾部，这时新节点的索引k为7： 计算新父节点的索引：parent = (k - 1) &gt;&gt;&gt; 1，parent = 3，那么queue[3]的时间间隔值为8，因为 5 &lt; 8 ，将执行queue[7] = queue[3]： 这时将k设置为3，继续循环，再次计算parent为1，queue[1]的时间间隔为3，因为 5 &gt; 3 ，这时退出循环，最终k为3： 可见，每次新增节点时，只是根据父节点来判断，而不会影响兄弟节点。 另外，setIndex方法只是设置了ScheduledFutureTask中的heapIndex属性：1234private void setIndex(RunnableScheduledFuture&lt;?&gt; f, int idx) &#123; if (f instanceof ScheduledFutureTask) ((ScheduledFutureTask)f).heapIndex = idx;&#125; take方法12345678910111213141516171819202122232425262728293031323334353637383940public RunnableScheduledFuture&lt;?&gt; take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; RunnableScheduledFuture&lt;?&gt; first = queue[0]; if (first == null) available.await(); else &#123; // 计算当前时间到执行时间的时间间隔 long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) return finishPoll(first); first = null; // don't retain ref while waiting // leader不为空，阻塞线程 if (leader != null) available.await(); else &#123; // leader为空，则把leader设置为当前线程， Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; // 阻塞到执行时间 available.awaitNanos(delay); &#125; finally &#123; // 设置leader = null，让其他线程执行available.awaitNanos(delay); if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; // 如果leader不为空，则说明leader的线程正在执行available.awaitNanos(delay); // 如果queue[0] == null，说明队列为空 if (leader == null &amp;&amp; queue[0] != null) available.signal(); lock.unlock(); &#125;&#125; take方法是什么时候调用的呢？在深入理解Java线程池：ThreadPoolExecutor中，介绍了getTask方法，工作线程会循环地从workQueue中取任务。但定时任务却不同，因为如果一旦getTask方法取出了任务就开始执行了，而这时可能还没有到执行的时间，所以在take方法中，要保证只有在到指定的执行时间的时候任务才可以被取走。 再来说一下leader的作用，这里的leader是为了减少不必要的定时等待，当一个线程成为leader时，它只等待下一个节点的时间间隔，但其它线程无限期等待。 leader线程必须在从take（）或poll（）返回之前signal其它线程，除非其他线程成为了leader。 举例来说，如果没有leader，那么在执行take时，都要执行available.awaitNanos(delay)，假设当前线程执行了该段代码，这时还没有signal，第二个线程也执行了该段代码，则第二个线程也要被阻塞。多个这时执行该段代码是没有作用的，因为只能有一个线程会从take中返回queue[0]（因为有lock），其他线程这时再返回for循环执行时取的queue[0]，已经不是之前的queue[0]了，然后又要继续阻塞。 所以，为了不让多个线程频繁的做无用的定时等待，这里增加了leader，如果leader不为空，则说明队列中第一个节点已经在等待出队，这时其它的线程会一直阻塞，减少了无用的阻塞（注意，在finally中调用了signal()来唤醒一个线程，而不是signalAll()）。 finishPoll1234567891011121314private RunnableScheduledFuture&lt;?&gt; finishPoll(RunnableScheduledFuture&lt;?&gt; f) &#123; // 数组长度-1 int s = --size; // 取出最后一个节点 RunnableScheduledFuture&lt;?&gt; x = queue[s]; // 删除最后一个元素 queue[s] = null; // 长度不为0，则从第一个元素开始排序，目的是通过排序最后一个元素，来替换第一个节点 if (s != 0) // 用最有一个元素替换第一个元素，引起二叉树重新平衡，进而删除出第一个元素 siftDown(0, x); setIndex(f, -1); return f;&#125; remove类似finishPoll：1234567891011121314151617181920212223242526// 替换指定位置的元素，即重新平衡二叉树进而移除元素public boolean remove(Object x) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; int i = indexOf(x); if (i &lt; 0) return false; setIndex(queue[i], -1); int s = --size; RunnableScheduledFuture&lt;?&gt; replacement = queue[s];// 取最后一个元素进行替换 queue[s] = null; if (s != i) &#123; siftDown(i, replacement);// 对i位置进行替换 if (queue[i] == replacement) // 如果queue[i] == replacement，说明i是叶子节点 // 如果是这种情况，不能保证子节点的下次执行时间比父节点的大 // 这时需要进行一次向上调整 siftUp(i, replacement); &#125; return true; &#125; finally &#123; lock.unlock(); &#125;&#125; siftDown出队列时，调用siftDown：123456789101112131415161718192021222324252627// 指定位置元素的值设为k，并进行比较、下移；可用于替换指定位置的元素private void siftDown(int k, RunnableScheduledFuture&lt;?&gt; key) &#123; // 根据二叉树的特性，数组长度除以2，表示取有子节点的索引 int half = size &gt;&gt;&gt; 1; // 判断索引为k的节点是否有子节点 while (k &lt; half) &#123; // 左子节点的索引 int child = (k &lt;&lt; 1) + 1; RunnableScheduledFuture&lt;?&gt; c = queue[child]; // 右子节点的索引 int right = child + 1; // 如果有右子节点并且左子节点的时间间隔大于右子节点，取时间间隔最小的节点 if (right &lt; size &amp;&amp; c.compareTo(queue[right]) &gt; 0) c = queue[child = right]; // 如果key的时间间隔小于等于c的时间间隔，跳出循环 if (key.compareTo(c) &lt;= 0) break; // 将字节点上移 queue[k] = c; setIndex(c, k); // 设置索引 k = child; &#125; // 将key放入索引为k的位置 queue[k] = key; setIndex(key, k);&#125; FutureTaskjdk1.6基于AQS来实现的，从jdk1.7开始是基于volatile来实现的。 123public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt;// 由于实现了Runnable接口，所以可作为任务public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 另外，使用线程池submit的task，实际上被包裹成FutureTask：12345678910public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125; Constructor123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * The run state of this task, initially NEW. The run state * transitions to a terminal state only in methods set, * setException, and cancel. During completion, state may take on * transient values of COMPLETING (while outcome is being set) or * INTERRUPTING (only while interrupting the runner to satisfy a * cancel(true)). Transitions from these intermediate to final * states use cheaper ordered/lazy writes because values are unique * and cannot be further modified. * * Possible state transitions: * NEW -&gt; COMPLETING -&gt; NORMAL * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL * NEW -&gt; CANCELLED * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED */// 基于volatile来实现private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1; // 在set、setException中，会预先置为COMPLETINGprivate static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6;public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125;protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion(); &#125;&#125;protected void setException(Throwable t) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = t; UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state finishCompletion(); &#125;&#125; run123456789101112131415161718192021222324252627282930313233343536373839public void run() &#123; // 1. 状态如果不是NEW，说明任务或者已经执行过，或者已经被取消，直接返回 // 2. 状态如果是NEW，则尝试把当前执行线程保存在runner字段中 // 如果赋值失败则直接返回 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; // 3. 执行任务 result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; // 4. 任务异常 setException(ex); &#125; if (ran) // 4. 任务正常执行完毕 set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; // 5. 如果任务被中断，执行中断处理 if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; run()方法首先会 判断当前任务的state是否等于NEW,如果不为NEW则说明任务或者已经执行过，或者已经被取消，直接返回。 如果状态为NEW则接着会通过unsafe类把任务执行线程引用CAS的保存在runner字段中，如果保存失败，则直接返回。 执行任务。 如果任务执行发生异常，则调用setException()方法保存异常信息。setException()方法如下： get1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); // 任务未完成时，其他线程调用get将被阻塞 return report(s);&#125;private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; // 1. 判断阻塞线程是否被中断,如果被中断则在等待队 // 列中删除该节点并抛出InterruptedException异常 if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; // 2. 获取当前状态，如果状态大于COMPLETING // 说明任务已经结束(要么正常结束，要么异常结束，要么被取消) // 则把thread显示置空，并返回结果 int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; // 3. 如果状态处于中间状态COMPLETING // 表示任务已经结束但是任务执行线程还没来得及给outcome赋值 // 这个时候让出执行权让其他线程优先执行 else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) // 4. 如果等待节点为空，则构造一个等待节点 q = new WaitNode(); else if (!queued) // 5. 如果还没有入队列，则把当前节点加入waiters首节点并替换原来waiters queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; // 如果需要等待特定时间，则先计算要等待的时间 // 如果已经超时，则删除对应节点并返回对应的状态 nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; // 6. 阻塞等待特定时间 LockSupport.parkNanos(this, nanos); &#125; else // 6. 阻塞等待直到被其他线程唤醒 LockSupport.park(this); &#125;&#125; awaitDone()中有个死循环，每一次循环都会 判断调用get()的线程是否被其他线程中断，如果是的话则在等待队列中删除对应节点然后抛出InterruptedException异常。 获取任务当前状态，如果当前任务状态大于COMPLETING则表示任务执行完成，则把thread字段置null并返回结果。 如果任务处于COMPLETING状态，则表示任务已经处理完成(正常执行完成或者执行出现异常)，但是执行结果或者异常原因还没有保存到outcome字段中。这个时候调用线程让出执行权让其他线程优先执行。 如果等待节点为空，则构造一个等待节点WaitNode。 如果第四步中新建的节点还没如队列，则CAS的把该节点加入waiters队列的首节点。 阻塞等待。 假设当前state=NEW且waiters为NULL,也就是说还没有任何一个线程调用get()获取执行结果，这个时候有两个线程threadA和threadB先后调用get()来获取执行结果。再假设这两个线程在加入阻塞队列进行阻塞等待之前任务都没有执行完成且threadA和threadB都没有被中断的情况下(因为如果threadA和threadB在进行阻塞等待结果之前任务就执行完成或线程本身被中断的话，awaitDone()就执行结束返回了)，执行过程是这样的，以threadA为例: 第一轮for循环，执行的逻辑是q == null,所以这时候会新建一个节点q。第一轮循环结束。 第二轮for循环，执行的逻辑是!queue，这个时候会把第一轮循环中生成的节点的netx指针指向waiters，然后CAS的把节点q替换waiters。也就是把新生成的节点添加到waiters链表的首节点。如果替换成功，queued=true。第二轮循环结束。 第三轮for循环，进行阻塞等待。要么阻塞特定时间，要么一直阻塞知道被其他线程唤醒。 cancel(boolean)1234567891011121314151617181920212223public boolean cancel(boolean mayInterruptIfRunning) &#123; // 1. 如果任务已经结束，则直接返回false if (state != NEW) return false; // 2. 如果需要中断任务执行线程 if (mayInterruptIfRunning) &#123; // 2.1. 把任务状态从NEW转化到INTERRUPTING if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, INTERRUPTING)) return false; Thread t = runner; // 2.2. 中断任务执行线程 if (t != null) t.interrupt(); // 2.3. 修改状态为INTERRUPTED UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); // final state &#125; // 3. 如果不需要中断任务执行线程，则直接把状态从NEW转化为CANCELLED else if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, CANCELLED)) return false; // 4. finishCompletion(); return true;&#125; cancel()方法会做下面几件事: 判断任务当前执行状态，如果任务状态不为NEW，则说明任务或者已经执行完成，或者执行异常，不能被取消，直接返回false表示执行失败。 判断需要中断任务执行线程，则把任务状态从NEW转化到INTERRUPTING。这是个中间状态。中断任务执行线程。修改任务状态为INTERRUPTED。这个转换过程对应上图中的四。 如果不需要中断任务执行线程，直接把任务状态从NEW转化为CANCELLED。如果转化失败则返回false表示取消失败。这个转换过程对应上图中的四。 调用finishCompletion()。 当调用cancel(true)方法的时候，实际执行还是Thread.interrupt()方法，而interrupt()方法只是设置中断标志位，如果被中断的线程处于sleep()、wait()或者join()逻辑中则会抛出InterruptedException异常。 finishCompletion()根据前面的分析，不管是任务执行异常还是任务正常执行完毕，或者取消任务，最后都会调用finishCompletion()方法，该方法实现如下:123456789101112131415161718192021222324private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; done(); callable = null; // to reduce footprint&#125; 这个方法的实现比较简单，依次遍历waiters链表，唤醒节点中的线程，然后把callable置空。被唤醒的线程会各自从awaitDone()方法中的LockSupport.park*()阻塞中返回，然后会进行新一轮的循环。在新一轮的循环中会返回执行结果(或者更确切的说是返回任务的状态)。 ThreadPoolExecutor详解深入理解Java线程池：ThreadPoolExecutor]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java中的线程池]]></title>
    <url>%2Fjava%2FJava%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[实现原理ThreadPoolExecutor执行execute： 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（需要获取全局锁）。 如果运行的线程等于或多余corePoolSize，则将任务加入BlockingQueue 如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（需要获取全局锁）。 如果创建新线程将使当前运行的线程超过maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。 线程池的使用创建123456public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler); workQueue：任务队列(ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、PriorityBlockingQueue)maximumPoolSize: 如果使用了无界的任务队列这个参数就没哟什么效果RejectedExecutionHandler： 饱和策略 提交任务execute： 无返回值sumbit：有返回值1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125;/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;&#125;/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125; 通过线程池submit的任务，最终都被包裹成FutureTask，并且FutureTask实现了Runnable接口。在调用execute方法后，将任务添加到工作队列中。 关闭线程池(shutdown、shutdownNow)原理：遍历线程池中的工作线程，逐个调用线程的interrupt方法来终端，所以无法响应中断的任务可能永远无法终止。区别：shutdown将线程池状态设为SHUTDOWN，然后中断所有没在执行的任务；shutdownNow首先将线程池的状态设为STOP，然后尝试停止所有正在执行或暂停任务的线程，并返回等待执行任务的列表。 合理配置线程池任务特性 性质：CPU密集型任务、IO密集型任务、混合型任务 优先级：高中低 执行时间： 长、短 依赖性：依赖其他资源，入数据库连接 CPU密集型任务应配置尽可能小的线程，如配置coreNum + 1个线程的线程池。IO密集型应配置尽可能多的线程，如2coreNum，由于不是一直在执行任务。混合型的任务，如何可以拆分，将其拆分为一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量。如果这两个执行时间相差太大，则没必要进行分解。可以通过Runtime.getRuntime().availableProcessors()来获取当前设备的CPU个数。建议使用有界队列，防止撑爆内存，拖垮系统，影响其他的任务。 线程池的监控通过自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任务执行前、后和线程池给关闭前执行一些代码来进行监控。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发容器和框架]]></title>
    <url>%2Fjava%2FJava%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E5%92%8C%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[主要介绍ConcurrentHashMap、ConcurrentLinkedQueue、阻塞队列、Fork/Join框架 ConcurrentHashMapConcurrentLinkedQueue阻塞队列 阻塞队列是一个支持两个附加操作的队列。这两个附加的操作支持阻塞地插入和移除方法。 支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。 支持阻塞地移除方法：意思是当队列空时，获取元素的线程会等待队列变空。 接口方法12345678910111213141516171819202122232425public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; &#123; boolean add(E e); boolean offer(E e); void put(E e) throws InterruptedException; boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException; E take() throws InterruptedException; E poll(long timeout, TimeUnit unit) throws InterruptedException; int remainingCapacity(); boolean remove(Object o); public boolean contains(Object o); int drainTo(Collection&lt;? super E&gt; c); int drainTo(Collection&lt;? super E&gt; c, int maxElements);&#125; 方法/处理方式 抛出异常 返回特殊值 一直阻塞 超时退出 插入 add(e) offer(e) put(e) offer(e, time, unit) 移除 remove() poll () take() poll(time, unit) 检查 element() peek() 不可用 不可用 实现原理使用通知模式实现。以ArrayBlockingQueue为例：123456789101112131415161718192021222324252627282930313233/** Main lock guarding all access */final ReentrantLock lock;/** Condition for waiting takes */private final Condition notEmpty;/** Condition for waiting puts */private final Condition notFull;public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125;public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; 队列 ArrayBlockingQueue LinkedBlockingQueue PriorityBlockingQueue DelayQueue DelayedWorkQueue SynchronousQueue LinkedTransferQueue LinkedBlockingDeque https://javadoop.com/post/java-concurrent-queue Fork/Join框架]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发工具类]]></title>
    <url>%2Fjava%2FJava%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[CountDownLatch依赖于AbstractQueuedSynchronizer实现的共享同步器 123456789101112131415161718192021222324252627private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125;&#125; await12345678910111213141516public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;// 当state不等于0，返回-1，则加入等待队列中protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; countDown1234567891011121314151617181920212223public void countDown() &#123; sync.releaseShared(1);&#125;public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared();// 唤醒等待节点 return true; &#125; return false;&#125;protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; 实例12345678910111213141516171819202122232425262728293031323334353637383940public class Test &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(2); new Thread()&#123; public void run() &#123; try &#123; System.out.println("子线程"+Thread.currentThread().getName()+"正在执行"); Thread.sleep(3000); System.out.println("子线程"+Thread.currentThread().getName()+"执行完毕"); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; try &#123; System.out.println("子线程"+Thread.currentThread().getName()+"正在执行"); Thread.sleep(3000); System.out.println("子线程"+Thread.currentThread().getName()+"执行完毕"); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); try &#123; System.out.println("等待2个子线程执行完毕..."); latch.await(); System.out.println("2个子线程已经执行完毕"); System.out.println("继续执行主线程"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; CyclicBarrier利用ReentrantLock和Condition，来阻塞调用await方法的线程。当满足一定条件，自动唤醒所有的线程。1234/** The lock for guarding barrier entry */private final ReentrantLock lock = new ReentrantLock();/** Condition to wait on until tripped */private final Condition trip = lock.newCondition(); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen &#125;&#125;/** * Main barrier code, covering the various policies. */private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; final Generation g = generation; if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; breakBarrier(); throw new InterruptedException(); &#125; int index = --count; if (index == 0) &#123; // tripped，当最后一个线程调用await时，唤醒所有线程 boolean ranAction = false; try &#123; final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; nextGeneration(); return 0; &#125; finally &#123; if (!ranAction) breakBarrier();// 唤醒所有线程 &#125; &#125; // loop until tripped, broken, interrupted, or timed out for (;;) &#123; try &#123; if (!timed) trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // "belong" to subsequent execution. Thread.currentThread().interrupt(); &#125; &#125; if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125;private void breakBarrier() &#123; generation.broken = true; count = parties; trip.signalAll();// 唤醒所有线程&#125; 实例1234567891011121314151617181920212223242526public class CyclicBarrierTest &#123; static CyclicBarrier c = new CyclicBarrier(2); public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; c.await(); &#125; catch (Exception e) &#123; &#125; System.out.println(1); &#125; &#125;).start(); try &#123; c.await(); &#125; catch (Exception e) &#123; &#125; System.out.println(2); &#125;&#125; CountDownLatch和CyclicBarrier的区别 CountDownLatch只能用一次，CyclicBarrier可以使用reset()方法重置。 … Semaphore 用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。 semapthore依赖于AbstractQueuedSynchronizer实现的同步器。可以用来做流量控制。123456Semaphore s = new Semaphore(10);s.acquire();......s.release(); 实例12345678910111213141516171819202122232425262728293031public class SemaphoreTest &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newCachedThreadPool(); final Semaphore sp = new Semaphore(3); for (int i = 0; i &lt; 10; i++) &#123; Runnable runnable = new Runnable() &#123; public void run() &#123; try &#123; sp.acquire(); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("线程" + Thread.currentThread().getName() + "进入，当前已有" + (3 - sp.availablePermits()) + "个并发"); try &#123; Thread.sleep((long) (Math.random() * 10000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("线程" + Thread.currentThread().getName() + "即将离开"); sp.release(); //下面代码有时候执行不准确，因为其没有和上面的代码合成原子单元 System.out.println("线程" + Thread.currentThread().getName() + "已离开，当前已有" + (3 - sp.availablePermits()) + "个并发"); &#125; &#125;; service.execute(runnable); &#125; &#125;&#125; Exchanger 用于线程间的数据交换。它提供一个同步点，两个线程可以交换彼此数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.concurrent.Exchanger;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/**` * @author joyo * @date 2018/3/15 */public class ExchangerTest &#123; private static final Exchanger&lt;String&gt; exgr = new Exchanger&lt;&gt;(); private static ExecutorService threadPool = Executors.newFixedThreadPool(2); public static void main(String[] args) &#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; String A = "银行流水A"; exgr.exchange(A); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); threadPool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; String B = "银行流水A"; String A = exgr.exchange(B); System.out.println("A和B数据是否一致：" + A.equals(B) + ", A录入的是：" + A + "， B录入的是:" + B); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); threadPool.shutdown(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁]]></title>
    <url>%2Fjava%2F%E9%94%81%2F</url>
    <content type="text"><![CDATA[Lock1234567Lock lock = new ReentrantLock();lock.lock();try&#123; ...&#125;finally&#123; lock.unlock();&#125; 1、灵活2、尝试非阻塞地获取锁123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; 3、能被中断地获取锁1234// 中断获取的一部分，parkAndCheckInterrupt 调用的是LockSupport.park(this); LockSupport 具有中断返回的特性。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); 4、能超时获取锁1lock.tryLock(1, TimeUnit.SECONDS); 5、独占或共享的方式 队列同步器 模板方法 volatile int 状态变量 CAS 同步队列（FIFO双向队列） 共享、独占获取同步状态 123456// overrideprotected boolean tryAcquire(int arg)protected boolean tryRelease(int arg)protected int tryAcquireShared(int arg)protected boolean tryReleaseShared(int arg)protected boolean isHeldExclusively() 1234// 可用方法getState()setState(int newState)compareAndSetState(int expect, int update) 123456789101112131415// 提供的模板方法// 独占、超时void acquire(int arg)void acquireInterruptibly(int arg)boolean tryAcquireNanos(int arg, long nanos)// 共享、超时void acquireShared(int arg)void acquireSharedInterruptibly(int arg)boolean tryAcquireSharedNanos(int arg)boolean release(int arg)boolean releaseShared(int arg)Collection&lt;Thread&gt; getQueuedThreads() 独占式获取1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public final void acquire(long arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;//同步队列：含有头尾节点的 FIFO 的双向队列private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; // 快速尝试一次添加尾节点，如果失败则通过enq(node)循环加入 node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 快速尝试失败后 enq(node); return node;&#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125;// 自旋，通过判断前驱pred 是否为head节点，来获取同步状态final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 进入wait状态 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;// 将前驱pred 的状态设为SIGNAL 后，返回trueprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 释放12345678910111213141516171819202122232425262728293031323334353637public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125;private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; // s 为空或者s 的状态为CANCEL 时，从尾到头找到第一个正常状态的节点s if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 共享式获取12345678910111213141516171819202122232425262728293031323334public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; // 类似于acquireQueued，开始自旋 boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; // p 节点非head 节点时，进入wait 状态，等待后续前驱节点的唤醒 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 释放1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared();// 多线程释放，需要通过CAS来保证 return true; &#125; return false;&#125; 独占式 共享式 超时获取 同步队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; /** * Performs &#123;@link Lock#lock&#125;. The main reason for subclassing * is to allow fast path for nonfair version. */ abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125; protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; protected final boolean isHeldExclusively() &#123; // While we must in general read state before owner, // we don't need to do so to check if current thread is owner return getExclusiveOwnerThread() == Thread.currentThread(); &#125; final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // Methods relayed from outer class final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; final boolean isLocked() &#123; return getState() != 0; &#125; /** * Reconstitutes the instance from a stream (that is, deserializes it). */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125;&#125; ReentrantLockAQS的唤醒机制是从队列中取出head节点的下一个节点来唤醒。咋一看，好像公平锁和非公平锁的实现逻辑是一样的。其实，非公平锁在唤醒下一个节点后，释放锁的节点或者新加入线程会和被唤醒的节点同时来竞争锁，并且释放锁的节点很大几率是成功的，所以不是FIFO，即非公平锁。而公平锁，由于在获取的时候添加了判断hasQueuedPredecessors()，即使当前新线程并没有在队列中，也会生成一个新的节点插入队尾，并不会和唤醒节点竞争。因此是严格FIFO。 获取锁非公平锁12345678910111213141516171819202122232425262728293031323334353637final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125;// AQS模板方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;// 子类重写的方法protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125; final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;// 支持可重入 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 公平锁12345678910111213141516171819202122232425262728293031final void lock() &#123; acquire(1);&#125;// AQS模板方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;// 子类重写的方法protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;// 支持可重入 int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 释放锁1234567891011121314151617181920212223public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; // fair and nofair is sameprotected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; ReentrantReadWriteLock通过按位切割使用，在一个整型变量上维护多种状态。高16位表示读。低16位表示写。 写锁的获取与释放12345678910111213141516171819202122232425262728293031protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error("Maximum lock count exceeded"); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true;&#125; 存在读锁时，不能获取写锁。 读锁的获取与释放123456789101112131415161718192021222324252627282930313233343536373839404142protected final int tryAcquireShared(int unused) &#123; /* * Walkthrough: * 1. If write lock held by another thread, fail. * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 写锁没有被其他线程获取或者被自己获取，则获取读锁成功；否则失败。 锁降级 拥有写锁，再获取读锁，随后释放写锁的过程。 LockSupport1234void park()void parkNanos(long nanos)void parkUntil(long deadline)void unpark(Thread thread) LockSupport.part()方法是响应中断地，当线程中断后，会从park方法返回执行后续逻辑，所以，LockSupport中的对中断地响应可以灵活控制。1234567891011121314151617181920212223242526272829/** * @author joyo * @date 2018/4/16 */public class LockSupportInterruptTest &#123; public static void main(String[] args) throws InterruptedException &#123; ReentrantLock lock = new ReentrantLock(); Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; lock.lock(); try &#123; LockSupport.park(); System.out.println("come back here"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;); thread.start(); Thread.sleep(2000); thread.interrupt(); &#125;&#125; 最终输出结果：come back here，而不是打印异常栈。 而Object.wait()方法并没有这个特性，会直接抛出中断异常。 Condition condition包含一个等待队列，有收尾节点组成。 await：生成节点放入等待队列 signal：将节点从等待队列中放入到sync中的同步队列末尾，等待后续竞争锁，恢复执行。唤醒时，是从头结点开始一个一个唤醒的。 ConditionObject是AQS的内部类，当唤醒Condition等待队列的节点时，会加入到AQS的同步队列的尾巴。 1234567public final void await()public final long awaitNanos(long nanosTimeout)public final boolean awaitUntil(Date deadline)public final boolean await(long time, TimeUnit unit)public final void signal()public final void signalAll() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// 队头、队尾private transient Node firstWaiter;private transient Node lastWaiter;public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125;// 新增等待节点，放入队尾private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125;public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125;private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; // 将节点从等待队列移到同步队列末尾 (first = firstWaiter) != null);&#125;final boolean transferForSignal(Node node) &#123; /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ Node p = enq(node);// 将节点放入sync中的同步队列 int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程基础]]></title>
    <url>%2Fjava%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[线程的状态 名称 说明 NEW 初始状态，线程被构建，但还没有调用start()方法 RUNNABLE 运行状态，java线程将操作系统中的就绪和运行统称为运行中 BLOCKED 阻塞状态，表示线程阻塞于锁 WAITING 等待状态，当前线程需要等待其他线程做出一些特定动作（通知或中断） TIME_WAITING 超时等待状态，不同于WAITING，它可以在指定的时间自行返回的 TERMINATED 终止状态 Daemon线程线程默认不是daemon线程，需要setDaemon(true)。daemon线程的finally方法，不一定有机会执行。 启动和终止suspend()、resume()和stop()suspend方法在调用后，线程不会释放已经占有的资源，而是占用资源进入睡眠状态。同样，stop方法在中介一个线程时不会保证线程的资源正常释放，通常是没有给予线程完成资源释放工作的机会。 进程间通信volatile和synchronized的方式通过共享变量的方式 等待/通知机制wait/notify(notifyAll)指线程A调用了对象O的wait方法进入等待状态，而线程B通过调用对象O的notify或者notifyAll方法来唤醒A线程，A线程从wait方法返回继续执行。 调用waie、notify、notifyAll方法时，需要先对调用对象加锁 调用wait后，释放锁。线程状态由running变为waiting notify、notifyAll释放所之后，wait的线程才能获取锁。 调用notify、notifyAll后，等待线程从等待队列中移到同步队列中，被移动的线程的状态由WATING变为BLOCKED 使用方式： Thread.join 线程池 数据库连接池 LockSupport Condition(await、signal、signalAll) AbstractQueuedSynchronizer ReentrantLock CountDownLatch … ThreadLocal线程应用实例等待超时模式123456long future = System.currentTimeMillis() + mills;long remaining = mills;while(remaining &gt; 0)&#123; wait(remaing); remaining = future - System.currentTimeMillis();&#125; 线程池123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141package com.iforfee.common.thread;import java.util.ArrayList;import java.util.Collections;import java.util.LinkedList;import java.util.List;import java.util.concurrent.atomic.AtomicLong;/** * @author joyo * @date 2018/3/14 */public class DefaultThreadPool&lt;Job extends Runnable&gt; implements ThreadPool&lt;Job&gt; &#123; private static final int MAX_WORKER_NUMBERS = 10; private static final int DEFAULT_WORKER_NUMBERS = 5; private static final int MIN_WORKER_NUMBERS = 1; private final LinkedList&lt;Job&gt; jobs = new LinkedList&lt;Job&gt;(); private final List&lt;Worker&gt; workers = Collections.synchronizedList(new ArrayList&lt;Worker&gt;()); private int workerNum = DEFAULT_WORKER_NUMBERS; private AtomicLong threadNum = new AtomicLong(); public DefaultThreadPool() &#123; initializeWokers(DEFAULT_WORKER_NUMBERS); &#125; public DefaultThreadPool(int num) &#123; workerNum = num &gt; MAX_WORKER_NUMBERS ? MAX_WORKER_NUMBERS : num &lt; MIN_WORKER_NUMBERS ? MIN_WORKER_NUMBERS : num; initializeWokers(workerNum); &#125; @Override public void execute(Job job) &#123; if (job != null) &#123; synchronized (jobs) &#123; jobs.addLast(job); jobs.notify(); &#125; &#125; &#125; @Override public void shutdown() &#123; workers.forEach(job -&gt; job.shutdown()); &#125; @Override public void addWorkers(int num) &#123; synchronized (jobs) &#123; if (num + this.workerNum &gt; MAX_WORKER_NUMBERS) &#123; num = MAX_WORKER_NUMBERS - this.workerNum; &#125; initializeWokers(num); this.workerNum += num; &#125; &#125; @Override public void removeWorker(int num) &#123; synchronized (jobs) &#123; if (num &gt;= this.workerNum) &#123; throw new IllegalArgumentException(&quot;beyond workerNum&quot;); &#125; int count = 0; while (count &lt; num) &#123; Worker worker = workers.get(count); if (workers.remove(worker)) &#123; worker.shutdown(); count++; &#125; this.workerNum -= count; &#125; &#125; &#125; @Override public int getJobSize() &#123; return jobs.size(); &#125; private void initializeWokers(int num) &#123; for (int i = 0; i &lt; num; i++) &#123; Worker worker = new Worker(); workers.add(worker); Thread thread = new Thread(worker, &quot;ThreadPool-Worker-&quot; + threadNum.incrementAndGet()); thread.start(); &#125; &#125; class Worker implements Runnable &#123; private volatile boolean running = true; @Override public void run() &#123; while (running) &#123; Job job = null; synchronized (jobs) &#123; while (jobs.isEmpty()) &#123; try &#123; jobs.wait(); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); return; &#125; &#125; job = jobs.removeFirst(); &#125; if (job != null) &#123; try &#123; job.run(); &#125; catch (Exception ex) &#123; //ignore exception from job &#125; &#125; &#125; &#125; public void shutdown() &#123; running = false; &#125; &#125;&#125;interface ThreadPool&lt;Job extends Runnable&gt; &#123; void execute(Job job); void shutdown(); void addWorkers(int num); void removeWorker(int num); int getJobSize();&#125; 数据库连接池web服务器]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文竹养育]]></title>
    <url>%2Ftree%2Fwenzhu%2F</url>
    <content type="text"><![CDATA[常见叶子发黄的原因 【文竹小枝发黄但不脱离】是因为盆土硬实，通气差根系的活力减退。所以要疏松盆土表面 【文竹叶尖枯黄或脱落】主要是浇水少，盆土偏干。应保持盆土湿润，并经常向植株喷洒水分，摆放在空气湿度大的地方。 【文竹枝梢颜色暗黄或呈黄绿色】是因强光照射或浇水过多所致。应将其移至荫蔽处或是有窗帘的窗边，避免强光直接照射，同时注意浇水不要太多。]]></content>
  </entry>
  <entry>
    <title><![CDATA[安全驾驶]]></title>
    <url>%2Fcommon-sense%2F%E5%AE%89%E5%85%A8%E9%A9%BE%E9%A9%B6%2F</url>
    <content type="text"><![CDATA[驾驶安全最关键的是在极端情况下的车辆控制，包括爆胎、雪天车辆打滑的情况。只有保证自己在极端情况下，具有控制车辆的能力，才能称得上是一个合格的驾驶者。 坐姿刹车 刹车速度（km/h） 刹车距离（m） 20 1 40 5 80 25 车辆速度过大时（100km/h），这个时候急转就是go die。先刹车到车辆极限速度，保证安全后再进行躲避，否则宁愿直接装上去。 握姿3、9点握法 电子控制系统 VSA、ESP等通过对个别轮胎进行点刹等操作来控制车辆 电子系统不能改变转弯极限 安全距离 2秒守则 刹车时，注意前后是否有大车 大车的挂车，可能会横过来，注意保持距离 湿滑路面如何急刹 ABS：一脚刹车 无ABS： 刹车、缓脚 如何转弯 前驱车：降速后带油门过弯 后驱车：降速后惯性过弯 如何起步 2档/L档/S档起步 换路面起步 推头understeer造成原因： 速度过快 弯中刹车 速度过快 缓松油门（突然松油门、降档都会讲车辆重心前移，导致失去抓地力） 稍回方向 弯中刹车 释放刹车 稍回方向 甩尾oversteer：造成原因： 弯中轰油门 弯中刹车 不踩刹车，完全失控可以刹车 想侧滑方向同步转动方向盘 避免惊慌和纠正过度 雪天驾驶 漂移的方式 甩尾漂移 推头漂移 重心漂移 手刹漂移]]></content>
      <tags>
        <tag>drive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java内存模型]]></title>
    <url>%2Fjava%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[JMMJava内存模型定义了多线程之间共享变量的可见性以及如何在需要的时候对共享变量进行同步。 Java内存模型定义了volatile和synchronized的行为，更重要的是保证了同步的java程序在所有的处理器架构下面都能正确的运行。 并发编程模型的两个关键问题线程之间如何通信和同步。 如何通信 共享内存 消息传递 如何同步 显式 隐式 在共享内存并发模型中，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接受之前，因此同步是隐式进行的。 JMM的抽象结构线程之间的共享变量存储在主内存，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。 happens-beforehappens-before规则是JMM为了保证程序的正确结果。 重排序为了提高性能，需要对指令进行重排序。重排序分类： 编译器 处理器 指令级并行重排序 内存系统重排序 happens-beforehappens-before是JMM最核心的概念。 一个happens-before规则对应于一个或多个编译器和处理器重排序规则。 定义 1.如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 2.两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须按照happens-before关系执行的顺序来执行。 定义1是JMM对程序员的承诺；定义2是JMM对编译器和处理器重排序的约束原则。 happens-before和as-if-serial是一回事，都有两重意思。从程序员的角度来说，好像是顺序执行的，但是只要不破坏结果，处理器和编译器怎么优化都可以 as-is-serial语义保证单线程内程序的执行结果不变，happens-before语义保证正确同步的多线程程序执行结果不变。 as-is-serial语义给程序员一个幻境：单线程程序是按照程序的顺序来执行的。happens-before关系给编写正确同步的程序员一个幻境：正确同步的多线程程序是按照happens-before指定的顺序来执行的。 happens-before规则 程序顺序规则 监视器锁规则 volatile变量规则 传递性 start()规则：如果线程A执行操作ThreatB.start()，那么A线程的ThreadB.start()操作happens-before于B线程中的任意操作。 join()规则：线程A执行ThreadB.join()并成功返回，那么线程B中任意操作happens-before于线程A从ThreadB.join()操作成功返回。 重排序 happens-before依赖于重排序的实现。一个happens-before对应多个重排序。 1. 数据依赖性数据依赖的操作不可重排序 2. as-if-serial语义不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器和处理器不会对存在数据依赖的操作重排序 顺序一致性内存模型顺序一致行内存模型是一个理论参考模型，在设计的时候，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参照 特性 JMM对正确同步的多线程程序的内存一致性做了如下保证：如果程序是正确同步的，程序的执行将具有顺序一致性。即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。 一个线程中的所有操作必须按照程序的顺序来执行，即不进行重排序 （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。 volatile的内存语义特性 可见性 原子性 内存语义 当写一个volatile变量时，JMM会把线程对应的本地内存中的共享变量值刷新到主内存。 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来从主内存中读取共享变量。 如何实现 在指令序列中插入内存屏障来禁止特定类型的处理器排序。 比如storestore屏障可以保证volatile之前的普通写操作，在volatile变量写入之前，被刷新到主内存。 JSR-33为什么要增强volatile的语义 为了提供一种比锁更轻量级的线程之间通信的机制。 在JSR—33之前，普通变量和volatile可以重排序，会导致普通变量没有写入刷新到主内存。 锁的内存语义内存语义 当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到内存中。 当线程获取锁时，JMM会把该线程对应的本地内存置为无效。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jmm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git基本操作]]></title>
    <url>%2Fgit%2Fgit%2F</url>
    <content type="text"><![CDATA[创建一个叫做“feature_x”的分支，并切换过去：1git checkout -b feature_x，(git checkout -b feature_x origin/master 在远程origin/master的分支基础上，创建feature_x分支) 切换回主分支：1git checkout master 再把新建的分支删掉：1git branch -d feature_x 除非你将分支推送到远端仓库，不然该分支就是 不为他人所见的：1git push origin &lt;branch&gt; 替换本地改动12git checkout -- &lt;filename&gt;此命令会使用 HEAD 中的最新内容替换掉你的工作目录中的文件。已添加到缓存区的改动，以及新文件，都不受影响。 丢弃本地改动和提交12git fetch origingit reset --hard origin/master 拉取创建所有分支123git branch -r | grep -v &apos;\-&gt;&apos; | while read remote; do git branch --track &quot;$&#123;remote#origin/&#125;&quot; &quot;$remote&quot;; donegit fetch --allgit pull --all 删除远程分支1git push origin :branch_name]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Aggregation Template]]></title>
    <url>%2FAggregation-Template%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;range&quot;: &#123; &quot;start&quot;: &#123; &quot;gte&quot;: 1506009600000 &#125; &#125; &#125; ] &#125; &#125;, &quot;aggs&quot;: &#123; &quot;stat_over_time&quot;: &#123; &quot;date_histogram&quot;: &#123; &quot;field&quot;: &quot;start&quot;, &quot;interval&quot;: &quot;week&quot;, &quot;offset&quot;: &quot;-8h&quot; &#125;, &quot;aggs&quot;: &#123; &quot;terms_over_name&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;service&quot;, &quot;size&quot;: 1, &quot;order&quot;: &#123; &quot;sum_over_count&quot;: &quot;desc&quot; &#125; &#125;, &quot;aggs&quot;: &#123; &quot;sum_over_count&quot;: &#123; &quot;sum&quot;: &#123; &quot;field&quot;: &quot;times&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>aggregation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在sum aggregation，进行过滤]]></title>
    <url>%2Ffilter-after-sum-aggregation%2F</url>
    <content type="text"><![CDATA[Bucket Selector AggregationNote: The bucket_selector aggregation, like all pipeline aggregations, executions after all other sibling aggregations. This means that using the bucket_selector aggregation to filter the returned buckets in the response does not save on execution time running the aggregations.对sum的结果进行过滤123456789101112131415161718192021222324252627282930313233343536373839404142434445GET stat/service/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;range&quot;: &#123; &quot;start&quot;: &#123; &quot;gte&quot;: 1505975853000 &#125; &#125; &#125;, &#123; &quot;range&quot;: &#123; &quot;end&quot;: &#123; &quot;lte&quot;: 1506062253000 &#125; &#125; &#125; ] &#125; &#125;, &quot;aggs&quot;: &#123; &quot;sd&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;service&quot;, &quot;size&quot;: 10 &#125;, &quot;aggs&quot;: &#123; &quot;ds&quot;: &#123; &quot;sum&quot;: &#123; &quot;field&quot;: &quot;times&quot; &#125; &#125;, &quot;sales_bucket_filter&quot;: &#123; &quot;bucket_selector&quot;: &#123; &quot;buckets_path&quot;: &#123; &quot;totalSales&quot;: &quot;ds&quot; &#125;, &quot;script&quot;: &quot;params.totalSales &gt; 1&quot; &#125; &#125; &#125; &#125; &#125;&#125; Date Histogram AggregationDates are represented in elasticsearch internally as long values.]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop shuffle]]></title>
    <url>%2Fhadoop%20shuffle%2F</url>
    <content type="text"><![CDATA[提交的任务，经过map后（形成key/value对，还包括partition，partition表示为map片段分配对应的reducer）存入内存缓冲区，并做了一些预排序。 当缓存大小超过限制（默认：分配的内存的80%），开始进行spill spill会进行sort，会在partitions之间进行排序以及对相同的partition里面的元素进行排序。 spill时，默认将元素组成&lt;key, value-list&gt;的形式（简单的将values放到一起），如果定义了conbiner的话，会对values进行操作，如何在word count中，会将value相加。 map阶段结束时，会将所有的spills， merge为一个，并通知jobtracker。 reducer通过联系jobstracker，知道某个map的任务完成了，进而将map结果复制过来。相同的key的map，会传到同一个reducer。 将不同的map结果，进行merge，如果有conbiner也会执行。 将合并后的结果，作为输入传给reducer。 参考http://zheming.wang/blog/2015/05/19/3AFF5BE8-593C-4F76-A72A-6A40FB140D4D/]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue]]></title>
    <url>%2Fvue%2F</url>
    <content type="text"><![CDATA[如果在实例创建之后添加新的属性到实例上，它不会触发视图更新。我们将在后面详细讨论响应系统。 1234&lt;!-- 完整语法 --&gt;&lt;a v-bind:href=&quot;url&quot;&gt;&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a :href=&quot;url&quot;&gt;&lt;/a&gt; 1234&lt;!-- 完整语法 --&gt;&lt;a v-on:click=&quot;doSomething&quot;&gt;&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a @click=&quot;doSomething&quot;&gt;&lt;/a&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
</search>
