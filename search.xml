<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[G1 GC]]></title>
    <url>%2Fjava%2FG1GC%2F</url>
    <content type="text"><![CDATA[GarbageFirst（G1）G1（Garbage-First）收集器是当今收集器技术发展最前沿的成果之一，它是一款面向服务端应用的垃圾收集器，HotSpot开发团队赋予它的使命是（在比较长期的）未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点： 并行与并发 G1 能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短“Stop The World”停顿时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。 分代收集 与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同方式去处理新创建的对象和已存活一段时间、熬过多次GC的旧对象来获取更好的收集效果。 空间整合 G1从整体来看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的。这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。 可预测的停顿 这是G1相对CMS的一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了降低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。 内存划分RegionG1算法将堆划分为若干个区域（Region），它仍然属于分代收集器。不过，这些区域的一部分包含新生代，新生代的垃圾收集依然采用暂停所有应用线程的方式，将存活对象拷贝到老年代或者Survivor空间。老年代也分成很多区域，G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有cms内存碎片问题的存在了。 在G1中，还有一种特殊的区域，叫Humongous区域。 如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。 PS：在java 8中，持久代也移动到了普通的堆内存空间中，改为元空间。 对象分配策略 说起大对象的分配，我们不得不谈谈对象的分配策略。它分为3个阶段： TLAB(Thread Local Allocation Buffer)线程本地分配缓冲区 Eden区中分配 Humongous区分配 TLAB为线程本地分配缓冲区，它的目的为了使对象尽可能快的分配出来。如果对象在一个共享的空间中分配，我们需要采用一些同步机制来管理这些空间内的空闲空间指针。在Eden空间中，每一个线程都有一个固定的分区用于分配对象，即一个TLAB。分配对象时，线程之间不再需要进行任何的同步。 对TLAB空间中无法分配的对象，JVM会尝试在Eden空间中进行分配。如果Eden空间无法容纳该对象，就只能在老年代中进行分配空间。 建立可预测的时间模型 G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 避免全堆扫描——Remembered Set G1把Java堆分为多个Region，就是“化整为零”。但是Region不可能是孤立的，一个对象分配在某个Region中，可以与整个Java堆任意的对象发生引用关系。在做可达性分析确定对象是否存活的时候，需要扫描整个Java堆才能保证准确性，这显然是对GC效率的极大伤害。 为了避免全堆扫描的发生，虚拟机为G1中每个Region维护了一个与之对应的Remembered Set。虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set之中。当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全堆扫描也不会有遗漏。 如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为以下几个步骤： 初始标记（Initial Marking） 仅仅只是标记一下GC Roots 能直接关联到的对象，并且修改TAMS（Nest Top Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可以的Region中创建对象，此阶段需要停顿线程，但耗时很短。 并发标记（Concurrent Marking） 从GC Root 开始对堆中对象进行可达性分析，找到存活对象，此阶段耗时较长，但可与用户程序并发执行。 最终标记（Final Marking） 为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。 筛选回收（Live Data Counting and Evacuation） 首先对各个Region中的回收价值和成本进行排序，根据用户所期望的GC 停顿是时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 GC模式G1 Young GCYoung GC主要是对Eden区进行GC，它在Eden空间耗尽时会被触发。在这种情况下，Eden空间的数据移动到Survivor空间中，如果Survivor空间不够，Eden空间的部分数据会直接晋升到年老代空间。Survivor区的数据移动到新的Survivor区中，也有部分数据晋升到老年代空间中。最终Eden空间的数据为空，GC停止工作，应用线程继续执行。 这时，我们需要考虑一个问题，如果仅仅GC 新生代对象，我们如何找到所有的根对象呢？ 老年代的所有对象都是根么？那这样扫描下来会耗费大量的时间。于是，G1引进了RSet的概念。它的全称是Remembered Set，作用是跟踪指向某个heap区内的对象引用。 在CMS中，也有RSet的概念，在老年代中有一块区域用来记录指向新生代的引用。这是一种point-out，在进行Young GC时，扫描根时，仅仅需要扫描这一块区域，而不需要扫描整个老年代。 但在G1中，并没有使用point-out，这是由于一个分区太小，分区数量太多，如果是用point-out的话，会造成大量的扫描浪费，有些根本不需要GC的分区引用也扫描了。于是G1中使用point-in来解决。point-in的意思是哪些分区引用了当前分区中的对象。这样，仅仅将这些对象当做根来扫描就避免了无效的扫描。由于新生代有多个，那么我们需要在新生代之间记录引用吗？这是不必要的，原因在于每次GC时，所有新生代都会被扫描，所以只需要记录老年代到新生代之间的引用即可。 需要注意的是，如果引用的对象很多，赋值器需要对每个引用做处理，赋值器开销会很大，为了解决赋值器开销这个问题，在G1 中又引入了另外一个概念，卡表（Card Table）。一个Card Table将一个分区在逻辑上划分为固定大小的连续区域，每个区域称之为卡。卡通常较小，介于128到512字节之间。Card Table通常为字节数组，由Card的索引（即数组下标）来标识每个分区的空间地址。默认情况下，每个卡都未被引用。当一个地址空间被引用时，这个地址空间对应的数组索引的值被标记为”0″，即标记为脏被引用，此外RSet也将这个数组下标记录下来。一般情况下，这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。 Young GC 阶段： 阶段1：根扫描静态和本地对象被扫描 阶段2：更新RS处理dirty card队列更新RS 阶段3：处理RS检测从年轻代指向年老代的对象 阶段4：对象拷贝拷贝存活的对象到survivor/old区域 阶段5：处理引用队列软引用，弱引用，虚引用处理 G1 Mix GCMix GC是伴随着Young GC一起发生的。 Mix GC不仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的老年代分区。 它的GC步骤分2步： 全局并发标记（global concurrent marking） 拷贝存活对象（evacuation） 在进行Mix GC之前，会先进行global concurrent marking（全局并发标记）。 global concurrent marking的执行过程是怎样的呢？ 在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为五个步骤： Phase Description (1) Initial Mark(Stop the World Event)初始标记 This is a stop the world event. With G1, it is piggybacked on a normal young GC. Mark survivor regions (root regions) which may have references to objects in old generation.是STW的事件，并且依赖于young GC的发生。标记survivor regions作为root regions，因为它可能有指向老年代的引用。 (2) Root Region Scanningroot region 扫描 Scan survivor regions for references into the old generation. This happens while the application continues to run. The phase must be completed before a young GC can occur.扫描survivor regions 中指向 old generation 的引用。同时，应用还在继续执行。这个阶段必须在young GC发生之前完成。 (3) Concurrent Marking并发标记 Find live objects over the entire heap. This happens while the application is running. This phase can be interrupted by young generation garbage collections.找到整个heap 中存活的对象。同时，应用程序继续执行。这个阶段可以被young GC中断。 (4) Remark(Stop the World Event)最终标记 Completes the marking of live object in the heap. Uses an algorithm called snapshot-at-the-beginning (SATB) which is much faster than what was used in the CMS collector.使用SATB算法完成heap中活对象的标记。 (5) Cleanup(Stop the World Event and Concurrent) - Performs accounting on live objects and completely free regions. (Stop the world)- Scrubs the Remembered Sets. (Stop the world)- Reset the empty regions and return them to the free list. (Concurrent)- 计算存活对象和完全空闲的regions。- 重置remember set。 - 重置空闲regions，并放入空闲列表中。 () Copying(Stop the World Event)* These are the stop the world pauses to evacuate or copy live objects to new unused regions. This can be done with young generation regions which are logged as [GC pause (young)]. Or both young and old generation regions which are logged as [GC Pause (mixed)].计算并拷贝存活对象到新的regions中。这个阶段可能发生在yong GC 和mixed GC 中。 三色标记算法 提到并发标记，我们不得不了解并发标记的三色标记算法。它是描述追踪式回收器的一种有用的方法，利用它可以推演回收器的正确性。 首先，我们将对象分成三种类型的。 黑色:根对象，或者该对象与它的子对象都被扫描 灰色:对象本身被扫描,但还没扫描完该对象中的子对象 白色:未被扫描对象，扫描完成所有对象之后，最终为白色的为不可达对象，即垃圾对象 当GC开始扫描对象时，按照如下图步骤进行对象的扫描： 根对象被置为黑色，子对象被置为灰色。 继续由灰色遍历,将已扫描了子对象的对象置为黑色。 遍历了所有可达的对象后，所有可达的对象都变成了黑色。不可达的对象即为白色，需要被清理。 这看起来很美好，但是如果在标记过程中，应用程序也在运行，那么对象的指针就有可能改变。这样的话，我们就会遇到一个问题：对象丢失问题 我们看下面一种情况，当垃圾收集器扫描到下面情况时： 这时候应用程序执行了以下操作： A.c=CB.c=null 这样，对象的状态图变成如下情形： 这时候垃圾收集器再标记扫描的时候就会下图成这样： 很显然，此时C是白色，被认为是垃圾需要清理掉，显然这是不合理的。那么我们如何保证应用程序在运行的时候，GC标记的对象不丢失呢？有如下2中可行的方式： 在插入的时候记录对象 在删除的时候记录对象 刚好这对应CMS和G1的2种不同实现方式： 在CMS采用的是增量更新（Incremental update），只要在写屏障（write barrier）里发现要有一个白对象的引用被赋值到一个黑对象 的字段里，那就把这个白对象变成灰色的。即插入的时候记录下来。 在G1中，使用的是STAB（snapshot-at-the-beginning）的方式，删除的时候记录所有的对象，它有3个步骤： 1，在开始标记的时候生成一个快照图标记存活对象 2，在并发标记的时候所有被改变的对象入队（在write barrier里把所有旧的引用所指向的对象都变成非白的） 3，可能存在游离的垃圾，将在下次被收集 这样，G1到现在可以知道哪些老的分区可回收垃圾最多。 当全局并发标记完成后，在某个时刻，就开始了Mix GC。这些垃圾回收被称作“混合式”是因为他们不仅仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的分区。混合式垃圾收集如下图： 混合式GC也是采用的复制的清理策略，当GC完成后，会重新释放空间。 至此，混合式GC告一段落了。下一小节我们讲进入调优实践。 G1 Full GC如果对象内存分配速度过快，mixed gc来不及回收，导致老年代被填满，就会触发一次full gc，G1的full gc算法就是单线程执行的serial old gc，会导致异常长时间的暂停时间，需要进行不断的调优，尽可能的避免full gc. 关键技术Remember Set和Card TableRS(Remember Set)是一种抽象概念，用于记录从非收集部分指向收集部分的指针的集合。在传统的分代垃圾回收算法里面，RS(Remember Set)被用来记录分代之间的指针。在G1回收器里面，RS被用来记录从其他Region指向一个Region的指针情况。因此，一个Region就会有一个RS。这种记录可以带来一个极大的好处：在回收一个Region的时候不需要执行全堆扫描，只需要检查它的RS就可以找到外部引用，而这些引用就是initial mark的根之一。 那么，如果一个线程修改了Region内部的引用，就必须要去通知RS，更改其中的记录。为了达到这种目的，G1回收器引入了一种新的结构，CT(Card Table)——卡表。每一个Region，又被分成了固定大小的若干张卡(Card)。每一张卡，都用一个Byte来记录是否修改过。卡表即这些byte的集合。实际上，如果把RS理解成一个概念模型，那么CT就可以说是RS的一种实现方式。 从第一感觉，或者出于直觉的考虑，使用一个bit来记录一张卡是否被修改过，就已经足够了。而使用一个byte会造成更多的空间开销。但是实际上，使用一个byte来记录一张卡是否被修改过，会比使用一个bit来记录效率更高。更多细节参阅资料3。 在RS的修改上也会遇到并发的问题。因为一个Region可能有多个线程在并发修改，因此它们也会并发修改RS。为了避免这样一种冲突，G1垃圾回收器进一步把RS划分成了多个哈希表。每一个线程都在各自的哈希表里面修改。最终，从逻辑上来说，RS就是这些哈希表的集合。哈希表是实现RS的一种通常的方式之一。它有一个极大的好处就是能够去除重复。这意味着，RS的大小将和修改的指针数量相当。而在不去重的情况下，RS的数量和写操作的数量相当。 整个关系如下： Remember Set 图中RS的虚线表名的是，RS并不是一个和Card Table独立的，不同的数据结构，而是指RS是一个概念模型。实际上，Card Table是RS的一种实现方式。 Remember Set的写屏障写屏障是指，在改变特定内存的值（实际上也就是写入内存）的时候额外执行的一些动作。在大多数的垃圾回收算法中，都利用到了写屏障。写屏障通常用于在运行时探测并记录回收相关指针(interesting pointer)，在回收器只回收堆中部分区域的时候，任何来自该区域外的指针都需要被写屏障捕获，这些指针将会在垃圾回收的时候作为标记开始的根。JAVA使用的其余的分代的垃圾回收器，都有写屏障。举例来说，每一次将一个老年代对象的引用修改为指向年轻代对象，都会被写屏障捕获，并且记录下来。因此在年轻代回收的时候，就可以避免扫描整个老年代来查找根。 G1垃圾回收器的写屏障和RS是相辅相成的，也就是记录Region内部的指针。这种记录发生在写操作之后。对于一个写屏障来说，过滤掉不必要的写操作是十分有必要的。这种过滤既能加快赋值器的速度，也能减轻回收器的负担。G1垃圾回收器采用的双重过滤 过滤掉同一个Region内部引用； 过滤掉空引用； 过滤掉这两个部分之后，可以使RS的大小大大减小。 G1的垃圾回收器的写屏障使用一种两级的log buffer结构： global set of filled buffer：所有线程共享的一个全局的，存放填满了的log buffer的集合； thread log buffer：每个线程自己的log buffer。所有的线程都会把写屏障的记录先放进去自己的log buffer中，装满了之后，就会把log buffer放到 global set of filled buffer中，而后再申请一个log buffer； Collect SetCollect Set(CSet)是指，在Evacuation阶段，由G1垃圾回收器选择的待回收的Region集合。G1垃圾回收器的软实时的特性就是通过CSet的选择来实现的。对应于算法的两种模式fully-young generational mode和partially-young mode，CSet的选择可以分成两种： 在fully-young generational mode下：顾名思义，该模式下CSet将只包含young的Region。G1将调整young的Region的数量来匹配软实时的目标； 在partially-young mode下：该模式会选择所有的young region，并且选择一部分的old region。old region的选择将依据在Marking cycle phase中对存活对象的计数。G1选择存活对象最少的Region进行回收。 SATB(snapshot-at-the-beginning)SATB(snapshot-at-the-beginning)，是最开始用于实时垃圾回收器的一种技术。G1垃圾回收器使用该技术在标记阶段记录一个存活对象的快照(“logically takes a snapshot of the set of live objects in the heap at the start of marking cycle”)。然而在并发标记阶段，应用可能修改了原本的引用，比如删除了一个原本的引用。这就会导致并发标记结束之后的存活对象的快照和SATB不一致。G1是通过在并发标记阶段引入一个写屏障来解决这个问题的：每当存在引用更新的情况，G1会将修改之前的值写入一个log buffer（这个记录会过滤掉原本是空引用的情况），在最终标记(final marking phase)阶段扫描SATB，修正SATB的误差。 SATB的log buffer如RS的写屏障使用的log buffer一样，都是两级结构，作用机制也是一样的。 细节可以参阅资料2，6 Marking bitmaps和TAMSMarking bitmap是一种数据结构，其中的每一个bit代表的是一个可用于分配给对象的起始地址。举例来说： 其中addrN代表的是一个对象的起始地址。绿色的块代表的是在该起始地址处的对象是存活对象，而其余白色的块则代表了垃圾对象。G1使用了两个bitmap，一个叫做previous bitmap，另外一个叫做next bitmap。previous bitmap记录的是上一次的标记阶段完成之后的构造的bitmap；next bitmap则是当前正在标记阶段正在构造的bitmap。在当前标记阶段结束之后，当前标记的next bitmap就变成了下一次标记阶段的previous bitmap。TAMS(top at mark start)变量，是一对用于区分在标记阶段新分配对象的变量，分别被称为previous TAMS和next TAMS。在previous TAMS和next TAMS之间的对象则是本次标记阶段时候新分配的对象。如图： 白色region代表的是空闲空间，绿色region代表是存活对象，橙色region代表的在此次标记阶段新分配的对象。注意的是，在橙色区域的对象，并不能确保它们都事实上是存活的。 算法详解整个算法可以分成两大部分： Marking cycle phase：标记阶段，该阶段是不断循环进行的； Evacuation phase：该阶段是负责把一部分region的活对象拷贝到空Region里面去，然后回收原本的Region空间，该阶段是STW(stop-the-world)的； 而算法也可以分成两种模式： fully-young generational mode：有时候也会被称为young GC，该模式只会回收young region，算法是通过调整young region的数量来达到软实时目标的； partially-young mode：也被称为Mixed GC，该阶段会回收young region和old region，算法通过调整old region的数量来达到软实时目标； 有趣的地方是不论处在何种模式之下，yong region都在被回收的范围内。而old region只能期望于Mixed GC。但是，如同在CMS垃圾回收器中遇到的困境一样，Mixed GC可能来不及回收old region。也就说，在需要分配老年代的对象的时候，并没有足够的空间。这个时候就只能触发一次full GC。 算法会自动在young GC和mixed GC之间切换，并且定期触发Marking cycle phase。HotSpot的G1实现允许指定一个参数InitiatingHeapOccupancyPercent，在达到该参数的情况下，就会执行marking cycle phase。 算法并不使用在对象头增加字段来标记该对象，而是采用bitmap的方式来记录一个对象被标记的情况。这种记录方法的好处就是在使用这些标记信息的时候，仅仅需要扫描bitmap而已。G1统计一个region的存活的对象，就是依赖于bitmap的标记。 调优实践MaxGCPauseMillis调优 前面介绍过使用GC的最基本的参数： -XX:+UseG1GC -Xmx32g -XX:MaxGCPauseMillis=200 前面2个参数都好理解，后面这个MaxGCPauseMillis参数该怎么配置呢？这个参数从字面的意思上看，就是允许的GC最大的暂停时间。G1尽量确保每次GC暂停的时间都在设置的MaxGCPauseMillis范围内。 那G1是如何做到最大暂停时间的呢？这涉及到另一个概念，CSet(collection set)。它的意思是在一次垃圾收集器中被收集的区域集合。 Young GC：选定所有新生代里的region。通过控制新生代的region个数来控制young GC的开销。 Mixed GC：选定所有新生代里的region，外加根据global concurrent marking统计得出收集收益高的若干老年代region。在用户指定的开销目标范围内尽可能选择收益高的老年代region。 在理解了这些后，我们再设置最大暂停时间就好办了。 首先，我们能容忍的最大暂停时间是有一个限度的，我们需要在这个限度范围内设置。但是应该设置的值是多少呢？我们需要在吞吐量跟MaxGCPauseMillis之间做一个平衡。如果MaxGCPauseMillis设置的过小，那么GC就会频繁，吞吐量就会下降。如果MaxGCPauseMillis设置的过大，应用程序暂停时间就会变长。G1的默认暂停时间是200毫秒，我们可以从这里入手，调整合适的时间。 其他调优参数 -XX:G1HeapRegionSize=n 设置的 G1 区域的大小。值是 2 的幂，范围是 1 MB 到 32 MB 之间。目标是根据最小的 Java 堆大小划分出约 2048 个区域。 -XX:ParallelGCThreads=n 设置 STW 工作线程数的值。将 n 的值设置为逻辑处理器的数量。n 的值与逻辑处理器的数量相同，最多为 8。 如果逻辑处理器不止八个，则将 n 的值设置为逻辑处理器数的 5/8 左右。这适用于大多数情况，除非是较大的 SPARC 系统，其中 n 的值可以是逻辑处理器数的 5/16 左右。 -XX:ConcGCThreads=n 设置并行标记的线程数。将 n 设置为并行垃圾回收线程数 (ParallelGCThreads) 的 1/4 左右。 -XX:InitiatingHeapOccupancyPercent=45 设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。 避免使用以下参数： 避免使用 -Xmn 选项或 -XX:NewRatio 等其他相关选项显式设置年轻代大小。固定年轻代的大小会覆盖暂停时间目标。 触发Full GC 在某些情况下，G1触发了Full GC，这时G1会退化使用Serial收集器来完成垃圾的清理工作，它仅仅使用单线程来完成GC工作，GC暂停时间将达到秒级别的。整个应用处于假死状态，不能处理任何请求，我们的程序当然不希望看到这些。那么发生Full GC的情况有哪些呢？ 并发模式失败 G1启动标记周期，但在Mix GC之前，老年代就被填满，这时候G1会放弃标记周期。这种情形下，需要增加堆大小，或者调整周期（例如增加线程数-XX:ConcGCThreads等）。 晋升失败或者疏散失败 G1在进行GC的时候没有足够的内存供存活对象或晋升对象使用，由此触发了Full GC。可以在日志中看到(to-space exhausted)或者（to-space overflow）。解决这种问题的方式是： a,增加 -XX:G1ReservePercent 选项的值（并相应增加总的堆大小），为“目标空间”增加预留内存量。 b,通过减少 -XX:InitiatingHeapOccupancyPercent 提前启动标记周期。 c,也可以通过增加 -XX:ConcGCThreads 选项的值来增加并行标记线程的数目。 巨型对象分配失败 当巨型对象找不到合适的空间进行分配时，就会启动Full GC，来释放空间。这种情况下，应该避免分配大量的巨型对象，增加内存或者增大-XX:G1HeapRegionSize，使巨型对象不再是巨型对象。 由于篇幅有限，G1还有很多调优实践，在此就不一一列出了，大家在平常的实践中可以慢慢探索。最后，期待java 9能正式发布，默认使用G1为垃圾收集器的java性能会不会又提高呢？ 使用场景The first focus of G1 is to provide a solution for users running applications that require large heaps with limited GC latency. This means heap sizes of around 6GB or larger, and stable and predictable pause time below 0.5 seconds. Applications running today with either the CMS or the ParallelOldGC garbage collector would benefit switching to G1 if the application has one or more of the following traits. Full GC durations are too long or too frequent. The rate of object allocation rate or promotion varies significantly. Undesired long garbage collection or compaction pauses (longer than 0.5 to 1 second) 总结 regions 划分：Eden、Survivor、Old、Humongous young gc 和 mixed gc remember set、card table、satb(snapshot-at-the-beginning) 参考https://crowhawk.github.io/2017/08/15/jvm_3/http://blog.jobbole.com/109170/https://www.jianshu.com/p/8bd15969a641http://www.importnew.com/27793.htmlhttps://tech.meituan.com/g1.htmlhttp://www.oracle.com/technetwork/tutorials/tutorials-1876574.htmlhttps://blog.csdn.net/renfufei/article/details/41897113https://www.jianshu.com/p/870abddaba41]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[G1Gc]]></title>
    <url>%2Fjava%2FG1Gc%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[虚拟机字节码执行引擎]]></title>
    <url>%2Fjava%2Fjvm%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[多态性实现机制——静态分派与动态分派方法解析Class 文件的编译过程中不包含传统编译中的连接步骤，一切方法调用在 Class 文件里面存储的都只是符号引用，而不是方法在实际运行时内存布局中的入口地址。这个特性给 Java 带来了更强大的动态扩展能力，使得可以在类运行期间才能确定某些目标方法的直接引用，称为动态连接，也有一部分方法的符号引用在类加载阶段或第一次使用时转化为直接引用，这种转化称为静态解析。这在前面的“Java 内存区域与内存溢出”一文中有提到。 静态解析成立的前提是：方法在程序真正执行前就有一个可确定的调用版本，并且这个方法的调用版本在运行期是不可改变的。换句话说，调用目标在编译器进行编译时就必须确定下来，这类方法的调用称为解析。 在 Java 语言中，符合“编译器可知，运行期不可变”这个要求的方法主要有静态方法和私有方法两大类，前者与类型直接关联，后者在外部不可被访问，这两种方法都不可能通过继承或别的方式重写出其他的版本，因此它们都适合在类加载阶段进行解析。 Java 虚拟机里共提供了四条方法调用字节指令，分别是： invokestatic：调用静态方法。 invokespecial：调用实例构造器方法、私有方法和父类方法。 invokevirtual：调用所有的虚方法。 invokeinterface：调用接口方法，会在运行时再确定一个实现此接口的对象。 只要能被 invokestatic 和 invokespecial 指令调用的方法，都可以在解析阶段确定唯一的调用版本，符合这个条件的有静态方法、私有方法、实例构造器和父类方法四类，它们在类加载时就会把符号引用解析为该方法的直接引用。这些方法可以称为非虚方法（还包括 final 方法），与之相反，其他方法就称为虚方法（final 方法除外）。这里要特别说明下 final 方法，虽然调用 final 方法使用的是 invokevirtual 指令，但是由于它无法覆盖，没有其他版本，所以也无需对方发接收者进行多态选择。Java 语言规范中明确说明了 final 方法是一种非虚方法。 解析调用一定是个静态过程，在编译期间就完全确定，在类加载的解析阶段就会把涉及的符号引用转化为可确定的直接引用，不会延迟到运行期再去完成。而分派调用则可能是静态的也可能是动态的，根据分派依据的宗量数（方法的调用者和方法的参数统称为方法的宗量）又可分为单分派和多分派。两类分派方式两两组合便构成了静态单分派、静态多分派、动态单分派、动态多分派四种分派情况。 静态分派所有依赖静态类型来定位方法执行版本的分派动作，都称为静态分派，静态分派的最典型应用就是多态性中的方法重载。静态分派发生在编译阶段，因此确定静态分配的动作实际上不是由虚拟机来执行的。下面通过一段方法重载的示例程序来更清晰地说明这种分派机制： 123456789101112131415161718192021222324252627class Human&#123; &#125; class Man extends Human&#123; &#125; class Woman extends Human&#123; &#125; public class StaticPai&#123; public void say(Human hum)&#123; System.out.println("I am human"); &#125; public void say(Man hum)&#123; System.out.println("I am man"); &#125; public void say(Woman hum)&#123; System.out.println("I am woman"); &#125; public static void main(String[] args)&#123; Human man = new Man(); Human woman = new Woman(); StaticPai sp = new StaticPai(); sp.say(man); sp.say(woman); &#125; &#125; 上面代码的执行结果如下： 12I am humanI am human 以上结果的得出应该不难分析。在分析为什么会选择参数类型为 Human 的重载方法去执行之前，先看如下代码： 1Human man = new Man（）; 我们把上面代码中的“Human”称为变量的静态类型，后面的“Man”称为变量的实际类型。静态类型和实际类型在程序中都可以发生一些变化，区别是静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且最终的静态类型是在编译期可知的，而实际类型变化的结果在运行期才可确定。 回到上面的代码分析中，在调用 say()方法时，方法的调用者（回忆上面关于宗量的定义，方法的调用者属于宗量）都为 sp 的前提下，使用哪个重载版本，完全取决于传入参数的数量和数据类型（方法的参数也是属于宗量）。代码中刻意定义了两个静态类型相同、实际类型不同的变量，可见编译器（不是虚拟机，因为如果是根据静态类型做出的判断，那么在编译期就确定了）在重载时是通过参数的静态类型而不是实际类型作为判定依据的。并且静态类型是编译期可知的，所以在编译阶段，javac 编译器就根据参数的静态类型决定使用哪个重载版本。这就是静态分派最典型的应用。 动态分派动态分派与多态性的另一个重要体现——方法覆写有着很紧密的关系。向上转型后调用子类覆写的方法便是一个很好地说明动态分派的例子。这种情况很常见，因此这里不再用示例程序进行分析。很显然，在判断执行父类中的方法还是子类中覆盖的方法时，如果用静态类型来判断，那么无论怎么进行向上转型，都只会调用父类中的方法，但实际情况是，根据对父类实例化的子类的不同，调用的是不同子类中覆写的方法，很明显，这里是要根据变量的实际类型来分派方法的执行版本的。而实际类型的确定需要在程序运行时才能确定下来，这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。 单分派和多分派前面给出：方法的接受者（亦即方法的调用者）与方法的参数统称为方法的宗量。单分派是根据一个宗量对目标方法进行选择，多分派是根据多于一个宗量对目标方法进行选择。 为了方便理解，下面给出一段示例代码： 12345678910111213141516171819202122232425262728293031class Eat&#123; &#125; class Drink&#123; &#125; class Father&#123; public void doSomething(Eat arg)&#123; System.out.println("爸爸在吃饭"); &#125; public void doSomething(Drink arg)&#123; System.out.println("爸爸在喝水"); &#125; &#125; class Child extends Father&#123; public void doSomething(Eat arg)&#123; System.out.println("儿子在吃饭"); &#125; public void doSomething(Drink arg)&#123; System.out.println("儿子在喝水"); &#125; &#125; public class SingleDoublePai&#123; public static void main(String[] args)&#123; Father father = new Father(); Father child = new Child(); father.doSomething(new Eat()); child.doSomething(new Drink()); &#125; &#125; 运行结果应该很容易预测到，如下： 12爸爸在吃饭儿子在喝水 我们首先来看编译阶段编译器的选择过程，即静态分派过程。这时候选择目标方法的依据有两点：一是方法的接受者（即调用者）的静态类型是 Father 还是 Child，二是方法参数类型是 Eat 还是 Drink。因为是根据两个宗量进行选择，所以 Java 语言的静态分派属于多分派类型。 再来看运行阶段虚拟机的选择，即动态分派过程。由于编译期已经了确定了目标方法的参数类型（编译期根据参数的静态类型进行静态分派），因此唯一可以影响到虚拟机选择的因素只有此方法的接受者的实际类型是 Father 还是 Child。因为只有一个宗量作为选择依据，所以 Java 语言的动态分派属于单分派类型。 根据以上论证，我们可以总结如下：目前的Java 语言（JDK1.6）是一门静态多分派、动态单分派的语言。 虚拟机动态分派的实现其实上面的叙述已经把虚拟机重写与重载的本质讲清楚了，那么Java虚拟机是如何做到这点的呢？ 由于动态分派是非常频繁的操作，实际实现中不可能真正如此实现。Java虚拟机是通过“稳定优化”的手段——在方法区中建立一个虚方法表（Virtual Method Table），通过使用方法表的索引来代替元数据查找以提高性能。虚方法表中存放着各个方法的实际入口地址（由于Java虚拟机自己建立并维护的方法表，所以没有必要使用符号引用，那不是跟自己过不去嘛），如果子类没有覆盖父类的方法，那么子类的虚方法表里面的地址入口与父类是一致的；如果重写父类的方法，那么子类的方法表的地址将会替换为子类实现版本的地址。 方法表是在类加载的连接阶段（验证、准备、解析）进行初始化，准备了子类的初始化值后，虚拟机会把该类的虚方法表也进行初始化。 动态类型语言支持https://my.oschina.net/itblog/blog/538748 https://blog.souche.com/invokedynamic/]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SPI和DriverManager]]></title>
    <url>%2Fjava%2FSPI%E5%92%8CDriverManager%2F</url>
    <content type="text"><![CDATA[Java中SPI机制深入及源码解析真正理解线程上下文类加载器（多案例分析）]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spi</tag>
        <tag>driver manager</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LockSupport]]></title>
    <url>%2Fjava%2FLockSupport%2F</url>
    <content type="text"><![CDATA[LockSupport 用法简介LockSupport是用来创建锁和其他同步类的基本线程阻塞原语。LockSupport 提供park()和unpark()方法实现阻塞线程和解除线程阻塞，LockSupport和每个使用它的线程都与一个许可(permit)关联。permit相当于1，0的开关，默认是0，调用一次unpark就加1变成1，调用一次park会消费permit, 也就是将1变成0，同时park立即返回。再次调用park会变成block（因为permit为0了，会阻塞在这里，直到permit变为1）, 这时调用unpark会把permit置为1。每个线程都有一个相关的permit, permit最多只有一个，重复调用unpark也不会积累。 park()和unpark()不会有 “Thread.suspend和Thread.resume所可能引发的死锁” 问题，由于许可的存在，调用 park 的线程和另一个试图将其 unpark 的线程之间的竞争将保持活性。 如果调用线程被中断，则park方法会返回。同时park也拥有可以设置超时时间的版本。 三种形式的 park 还各自支持一个 blocker 对象参数。此对象在线程受阻塞时被记录，以允许监视工具和诊断工具确定线程受阻塞的原因。（这样的工具可以使用方法 getBlocker(java.lang.Thread) 访问 blocker。）建议最好使用这些形式，而不是不带此参数的原始形式。在锁实现中提供的作为 blocker 的普通参数是 this。看下线程dump的结果来理解blocker的作用。 LockSupport 源码解读 LockSupport中主要的两个成员变量： 123// Hotspot implementation via intrinsics APIprivate static final sun.misc.Unsafe UNSAFE;private static final long parkBlockerOffset; 再来看parkBlockerOffset:parkBlocker就是第一部分说到的用于记录线程被谁阻塞的，用于线程监控和分析工具来定位原因的，可以通过LockSupport的getBlocker获取到阻塞的对象。 12345678static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; tk = Thread.class; parkBlockerOffset = UNSAFE.objectFieldOffset (tk.getDeclaredField("parkBlocker")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125; 从这个静态语句块可以看的出来，先是通过反射机制获取Thread类的parkBlocker字段对象。然后通过sun.misc.Unsafe对象的objectFieldOffset方法获取到parkBlocker在内存里的偏移量，parkBlockerOffset的值就是这么来的. JVM的实现可以自由选择如何实现Java对象的“布局”，也就是在内存里Java对象的各个部分放在哪里，包括对象的实例字段和一些元数据之类。 sun.misc.Unsafe里关于对象字段访问的方法把对象布局抽象出来，它提供了objectFieldOffset()方法用于获取某个字段相对 Java对象的“起始地址”的偏移量，也提供了getInt、getLong、getObject之类的方法可以使用前面获取的偏移量来访问某个Java 对象的某个字段。 为什么要用偏移量来获取对象？干吗不要直接写个get，set方法。多简单？仔细想想就能明白，这个parkBlocker就是在线程处于阻塞的情况下才会被赋值。线程都已经阻塞了，如果不通过这种内存的方法，而是直接调用线程内的方法，线程是不会回应调用的。 2.LockSupport的方法： 可以看到，LockSupport中主要是park和unpark方法以及设置和读取parkBlocker方法。 1234private static void setBlocker(Thread t, Object arg) &#123; // Even though volatile, hotspot doesn't need a write barrier here. UNSAFE.putObject(t, parkBlockerOffset, arg); &#125; 对给定线程t的parkBlocker赋值。 12345public static Object getBlocker(Thread t) &#123; if (t == null) throw new NullPointerException(); return UNSAFE.getObjectVolatile(t, parkBlockerOffset);&#125; 从线程t中获取它的parkBlocker对象，即返回的是阻塞线程t的Blocker对象。 接下来主查两类方法，一类是阻塞park方法，一类是解除阻塞unpark方法 阻塞线程 park() 123public static void park() &#123; UNSAFE.park(false, 0L);&#125; 调用native方法阻塞当前线程。 parkNanos(long nanos) 1234public static void parkNanos(long nanos) &#123; if (nanos &gt; 0) UNSAFE.park(false, nanos);&#125; 阻塞当前线程，最长不超过nanos纳秒，返回条件在park()的基础上增加了超时返回。 parkUntil(long deadline) 123public static void parkUntil(long deadline) &#123; UNSAFE.park(true, deadline);&#125; 阻塞当前线程，知道deadline时间（deadline - 毫秒数）。 JDK1.6引入这三个方法对应的拥有Blocker版本。 park(Object blocker) 123456public static void park(Object blocker) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null);&#125; 1) 记录当前线程等待的对象（阻塞对象）；2) 阻塞当前线程；3) 当前线程等待对象置为null。 parkNanos(Object blocker, long nanos) 12345678public static void parkNanos(Object blocker, long nanos) &#123; if (nanos &gt; 0) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, nanos); setBlocker(t, null); &#125;&#125; 阻塞当前线程，最长等待时间不超过nanos毫秒，同样，在阻塞当前线程的时候做了记录当前线程等待的对象操作。 parkUntil(Object blocker, long deadline) 123456public static void parkUntil(Object blocker, long deadline) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(true, deadline); setBlocker(t, null);&#125; 阻塞当前线程直到deadline时间，相同的，也做了阻塞前记录当前线程等待对象的操作。 唤醒线程 unpark(Thread thread) 1234public static void unpark(Thread thread) &#123; if (thread != null) UNSAFE.unpark(thread);&#125; 唤醒处于阻塞状态的线程Thread。 Locksupport 底层在Linux系统下，是用的Posix线程库pthread中的mutex（互斥量），condition（条件变量）来实现的。mutex和condition保护了一个_counter的变量，当park时，这个变量被设置为0，当unpark时，这个变量被设置为1。 看看Locksupport的源码中的注释可知，Locksupport是实现别的锁和同步类的基本原语。 123456789101112131415class Parker : public os::PlatformParker &#123;private: volatile int _counter ; ...public: void park(bool isAbsolute, jlong time); void unpark(); ...&#125;class PlatformParker : public CHeapObj&lt;mtInternal&gt; &#123; protected: pthread_mutex_t _mutex [1] ; pthread_cond_t _cond [1] ; ...&#125; 可以看到Parker类实际上用Posix的mutex，condition来实现的。在Parker类里的_counter字段，就是用来记录“许可”的。 park 过程 当调用park时，先尝试能否直接拿到“许可”，即_counter&gt;0时，如果成功，则把_counter设置为0，并返回： 1234567891011void Parker::park(bool isAbsolute, jlong time) &#123; // Ideally we'd do something useful while spinning, such // as calling unpackTime(). // Optional fast-path check: // Return immediately if a permit is available. // We depend on Atomic::xchg() having full barrier semantics // since we are doing a lock-free update to _counter. if (Atomic::xchg(0, &amp;_counter) &gt; 0) return; 如果不成功，则构造一个ThreadBlockInVM，然后检查_counter是不是&gt;0，如果是，则把_counter设置为0，unlock mutex并返回： 1234ThreadBlockInVM tbivm(jt); if (_counter &gt; 0) &#123; // no wait needed _counter = 0; status = pthread_mutex_unlock(_mutex); 否则，再判断等待的时间，然后再调用pthread_cond_wait函数等待，如果等待返回，则把_counter设置为0，unlock mutex并返回： 1234567if (time == 0) &#123; status = pthread_cond_wait (_cond, _mutex) ; &#125; _counter = 0 ; status = pthread_mutex_unlock(_mutex) ; assert_status(status == 0, status, "invariant") ; OrderAccess::fence(); unpark 过程 当unpark时，则简单多了，直接设置_counter为1，再unlock mutex返回。如果_counter之前的值是0，则还要调用pthread_cond_signal唤醒在park中等待的线程： 1234567891011121314151617181920212223void Parker::unpark() &#123; int s, status ; status = pthread_mutex_lock(_mutex); assert (status == 0, "invariant") ; s = _counter; _counter = 1; if (s &lt; 1) &#123; if (WorkAroundNPTLTimedWaitHang) &#123; status = pthread_cond_signal (_cond) ; assert (status == 0, "invariant") ; status = pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; &#125; else &#123; status = pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; status = pthread_cond_signal (_cond) ; assert (status == 0, "invariant") ; &#125; &#125; else &#123; pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; &#125; &#125; LockSupport的特性先释放许可，再获取许可1234567public static void main(String[] args)&#123; Thread thread = Thread.currentThread(); LockSupport.unpark(thread);//释放许可 LockSupport.park();// 获取许可 System.out.println("b");&#125; 不可重入123456789101112public static void main(String[] args) throws Exception&#123; Thread thread = Thread.currentThread(); LockSupport.unpark(thread); System.out.println("a"); LockSupport.park(); System.out.println("b"); LockSupport.park(); System.out.println("c");&#125; 这段代码打印出a和b，不会打印c，因为第二次调用park的时候，线程无法获取许可出现死锁。 中断响应LockSupport.part()方法是响应中断地，当线程中断后，会从park方法返回执行后续逻辑，所以，LockSupport中的对中断地响应可以灵活控制。1234567891011121314151617181920212223242526272829/** * @author joyo * @date 2018/4/16 */public class LockSupportInterruptTest &#123; public static void main(String[] args) throws InterruptedException &#123; ReentrantLock lock = new ReentrantLock(); Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; lock.lock(); try &#123; LockSupport.park(); System.out.println("come back here"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;); thread.start(); Thread.sleep(2000); thread.interrupt(); &#125;&#125; 最终输出结果：come back here，而不是打印异常栈。 而Object.wait()方法并没有这个特性，会直接抛出中断异常。 LockSupport 和 Object的区别两者区别总结如下： Object.wait和notify都是针对对象的，notify实际上是不知道唤醒具体哪个线程的，而Locksupport支持指定线程唤醒 实现原理不同，Locksupport是基于Unsafe.park来实现的。具体可以见参考资料3 Locksupport功能更加强大些： 基于“许可”的同步实现，提供parkBlocker来监视锁的持有等。而Object.wait方法来完成同步，需要依赖监视器锁。 JDK1.6之后针对synchrnized引入了分级的锁，根据后面的代码示例发现两类同步原语的开销是差不多的 两者相同点： park和wait都会阻塞线程，释放锁 虽然响应中断行动不同，但是都会更改中断标志位 功能上其实相近，但是为了易用性和功能妥协，park和unpark基本可以替代Object.wait和notify等 从区别上来看可知，使用Locksupport能更加精细、灵活地控制线程的同步，利于实现各种同步工具和锁。精细体现在针对线程的同步控制，灵活体现在通过“许可”获取的方式来保证活性。 参考https://segmentfault.com/a/1190000008420938https://www.jianshu.com/p/e3afe8ab8364https://blog.csdn.net/u013851082/article/details/70242395https://kaimingwan.com/post/java/javabing-fa-yu-suo/liao-liao-locksupport]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>LockSupport</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2Fjava%2Fdatastructure%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[Example123456789101112131415161718192021222324252627public class ThreadLocalExample &#123; public static class MyRunnable implements Runnable &#123; private ThreadLocal threadLocal = new ThreadLocal(); @Override public void run() &#123; threadLocal.set((int) (Math.random() * 100D)); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; &#125; System.out.println(threadLocal.get()); &#125; &#125; public static void main(String[] args) &#123; MyRunnable sharedRunnableInstance = new MyRunnable(); Thread thread1 = new Thread(sharedRunnableInstance); Thread thread2 = new Thread(sharedRunnableInstance); thread1.start(); thread2.start(); &#125;&#125; get and Set123456789101112131415161718192021222324252627282930313233343536373839/** * Sets the current thread's copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the &#123;@link #initialValue&#125; * method to set the values of thread-locals. * * @param value the value to be stored in the current thread's copy of * this thread-local. */public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;/** * Returns the value in the current thread's copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread's value of this thread-local*/public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; hash冲突当set发生hash冲突时，获取数组中下一个可插入的位置：12345678910111213141516171819202122232425262728293031323334private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; // 走到这里，说明key不相等，即发生了key的冲突，通过nextIndex 获取下一个可用的位置 &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; 内存泄露ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 深入分析 ThreadLocal 内存泄漏问题ThreadLocal 内存泄露的实例分析]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis缓存]]></title>
    <url>%2Fredis%2Fredis%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[缓存穿透什么是缓存穿透？一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如DB）。如果key对应的value是一定不存在的，并且对该key并发请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。 如何避免？1：对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key对应的数据insert了之后清理缓存。2：对一定不存在的key进行过滤。可以把所有的可能存在的key放到一个大的Bitmap中，查询时通过该bitmap过滤。【感觉应该用的不多吧】 开发提示：有关布隆过滤器的相关知识，可以参考：https://en.wikipedia.org/wiki/Bloom_filter可以利用 Redis 的 Bitmaps 实现布隆过滤器，GitHub 上已经开源了类似的方案，读者可以进行参考：https://github.com/erikdubbelboer/Redis-Lua-scaling-bloom-filter 缓存雪崩什么是缓存雪崩？当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。 如何避免？ 预防 保证缓存层服务高可用性（多个节点） 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。 从缓存层面来看，不设置过期时间，每个 value 设置一个逻辑过期时间 可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存 做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期 提前演练 事后处理 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 依赖隔离组件为后端限流并降级 缓存预热缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样避免，用户请求的时候，再去加载相关的数据。 解决思路： 直接写个缓存刷新页面，上线时手工操作下。 数据量不大，可以在WEB系统启动的时候加载。 定时刷新缓存 缓存数据的淘汰缓存淘汰的策略有两种： (1) 定时去清理过期的缓存。 （2）当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂，具体用哪种方案，大家可以根据自己的应用场景来权衡。 淘汰机制 LRU TTL Redis数据淘汰机制 参考缓存穿透与缓存雪崩Redis架构之防雪崩设计：网站不宕机背后的兵法]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis事务]]></title>
    <url>%2Fredis%2Fredis%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Redis 通过 MULTI 、 DISCARD 、 EXEC 和 WATCH 四个命令来实现事务功能， 本章首先讨论使用 MULTI 、 DISCARD 和 EXEC 三个命令实现的一般事务， 然后再来讨论带有 WATCH 的事务的实现。 因为事务的安全性也非常重要， 所以本章最后通过常见的 ACID 性质对 Redis 事务的安全性进行了说明。 事务事务提供了一种“将多个命令打包， 然后一次性、按顺序地执行”的机制， 并且事务在执行的期间不会主动中断 —— 服务器在执行完事务中的所有命令之后， 才会继续处理其他客户端的其他命令。 以下是一个事务的例子， 它先以 MULTI 开始一个事务， 然后将多个命令入队到事务中， 最后由 EXEC 命令触发事务， 一并执行事务中的所有命令： 12345678910111213141516171819202122redis&gt; MULTIOKredis&gt; SET book-name &quot;Mastering C++ in 21 days&quot;QUEUEDredis&gt; GET book-nameQUEUEDredis&gt; SADD tag &quot;C++&quot; &quot;Programming&quot; &quot;Mastering Series&quot;QUEUEDredis&gt; SMEMBERS tagQUEUEDredis&gt; EXEC1) OK2) &quot;Mastering C++ in 21 days&quot;3) (integer) 34) 1) &quot;Mastering Series&quot; 2) &quot;C++&quot; 3) &quot;Programming&quot; 一个事务从开始到执行会经历以下三个阶段： 开始事务。 命令入队。 执行事务。 下文将分别介绍事务的这三个阶段。 开始事务MULTI 命令的执行标记着事务的开始： 12redis&gt; MULTIOK 这个命令唯一做的就是， 将客户端的 REDIS_MULTI 选项打开， 让客户端从非事务状态切换到事务状态。 命令入队当客户端处于非事务状态下时， 所有发送给服务器端的命令都会立即被服务器执行： 12345redis&gt; SET msg &quot;hello moto&quot;OKredis&gt; GET msg&quot;hello moto&quot; 但是， 当客户端进入事务状态之后， 服务器在收到来自客户端的命令时， 不会立即执行命令， 而是将这些命令全部放进一个事务队列里， 然后返回 QUEUED ， 表示命令已入队： 12345678redis&gt; MULTIOKredis&gt; SET msg &quot;hello moto&quot;QUEUEDredis&gt; GET msgQUEUED 以下流程图展示了这一行为： 事务队列是一个数组， 每个数组项是都包含三个属性： 要执行的命令（cmd）。 命令的参数（argv）。 参数的个数（argc）。 举个例子， 如果客户端执行以下命令： 1234567891011121314redis&gt; MULTIOKredis&gt; SET book-name &quot;Mastering C++ in 21 days&quot;QUEUEDredis&gt; GET book-nameQUEUEDredis&gt; SADD tag &quot;C++&quot; &quot;Programming&quot; &quot;Mastering Series&quot;QUEUEDredis&gt; SMEMBERS tagQUEUED 那么程序将为客户端创建以下事务队列： 数组索引 cmd argv argc 0 SET [&quot;book-name&quot;, &quot;Mastering C++ in 21 days&quot;] 2 1 GET [&quot;book-name&quot;] 1 2 SADD [&quot;tag&quot;, &quot;C++&quot;, &quot;Programming&quot;, &quot;Mastering Series&quot;] 4 3 SMEMBERS [&quot;tag&quot;] 1 执行事务前面说到， 当客户端进入事务状态之后， 客户端发送的命令就会被放进事务队列里。 但其实并不是所有的命令都会被放进事务队列， 其中的例外就是 EXEC 、 DISCARD 、 MULTI 和 WATCH 这四个命令 —— 当这四个命令从客户端发送到服务器时， 它们会像客户端处于非事务状态一样， 直接被服务器执行： 如果客户端正处于事务状态， 那么当 EXEC 命令执行时， 服务器根据客户端所保存的事务队列， 以先进先出（FIFO）的方式执行事务队列中的命令： 最先入队的命令最先执行， 而最后入队的命令最后执行。 比如说，对于以下事务队列： 数组索引 cmd argv argc 0 SET [&quot;book-name&quot;, &quot;Mastering C++ in 21 days&quot;] 2 1 GET [&quot;book-name&quot;] 1 2 SADD [&quot;tag&quot;, &quot;C++&quot;, &quot;Programming&quot;, &quot;Mastering Series&quot;] 4 3 SMEMBERS [&quot;tag&quot;] 1 程序会首先执行 SET 命令， 然后执行 GET 命令， 再然后执行 SADD 命令， 最后执行 SMEMBERS 命令。 执行事务中的命令所得的结果会以 FIFO 的顺序保存到一个回复队列中。 比如说，对于上面给出的事务队列，程序将为队列中的命令创建如下回复队列： 数组索引 回复类型 回复内容 0 status code reply OK 1 bulk reply &quot;Mastering C++ in 21 days&quot; 2 integer reply 3 3 multi-bulk reply [&quot;Mastering Series&quot;, &quot;C++&quot;, &quot;Programming&quot;] 当事务队列里的所有命令被执行完之后， EXEC 命令会将回复队列作为自己的执行结果返回给客户端， 客户端从事务状态返回到非事务状态， 至此， 事务执行完毕。 事务的整个执行过程可以用以下伪代码表示： 12345678910111213141516171819202122def execute_transaction(): # 创建空白的回复队列 reply_queue = [] # 取出事务队列里的所有命令、参数和参数数量 for cmd, argv, argc in client.transaction_queue: # 执行命令，并取得命令的返回值 reply = execute_redis_command(cmd, argv, argc) # 将返回值追加到回复队列末尾 reply_queue.append(reply) # 清除客户端的事务状态 clear_transaction_state(client) # 清空事务队列 clear_transaction_queue(client) # 将事务的执行结果返回给客户端 send_reply_to_client(client, reply_queue) 在事务和非事务状态下执行命令无论在事务状态下， 还是在非事务状态下， Redis 命令都由同一个函数执行， 所以它们共享很多服务器的一般设置， 比如 AOF 的配置、RDB 的配置，以及内存限制，等等。 不过事务中的命令和普通命令在执行上还是有一点区别的，其中最重要的两点是： 非事务状态下的命令以单个命令为单位执行，前一个命令和后一个命令的客户端不一定是同一个； 而事务状态则是以一个事务为单位，执行事务队列中的所有命令：除非当前事务执行完毕，否则服务器不会中断事务，也不会执行其他客户端的其他命令。 在非事务状态下，执行命令所得的结果会立即被返回给客户端； 而事务则是将所有命令的结果集合到回复队列，再作为 EXEC 命令的结果返回给客户端。 事务状态下的 DISCARD 、 MULTI 和 WATCH 命令除了 EXEC 之外， 服务器在客户端处于事务状态时， 不加入到事务队列而直接执行的另外三个命令是 DISCARD 、 MULTI 和 WATCH。 DISCARD 命令用于取消一个事务， 它清空客户端的整个事务队列， 然后将客户端从事务状态调整回非事务状态， 最后返回字符串 OK 给客户端， 说明事务已被取消。 Redis 的事务是不可嵌套的， 当客户端已经处于事务状态， 而客户端又再向服务器发送 MULTI 时， 服务器只是简单地向客户端发送一个错误， 然后继续等待其他命令的入队。 MULTI 命令的发送不会造成整个事务失败， 也不会修改事务队列中已有的数据。 WATCH 只能在客户端进入事务状态之前执行， 在事务状态下发送 WATCH 命令会引发一个错误， 但它不会造成整个事务失败， 也不会修改事务队列中已有的数据（和前面处理 MULTI 的情况一样）。 带 WATCH 的事务WATCH 命令用于在事务开始之前监视任意数量的键： 当调用 EXEC 命令执行事务时， 如果任意一个被监视的键已经被其他客户端修改了， 那么整个事务不再执行， 直接返回失败。 以下示例展示了一个执行失败的事务例子： 1234567891011redis&gt; WATCH nameOKredis&gt; MULTIOKredis&gt; SET name peterQUEUEDredis&gt; EXEC(nil) 以下执行序列展示了上面的例子是如何失败的： 时间 客户端 A 客户端 B T1 WATCH name T2 MULTI T3 SET name peter T4 SET name john T5 EXEC 在时间 T4 ，客户端 B 修改了 name 键的值， 当客户端 A 在 T5 执行 EXEC 时，Redis 会发现 name 这个被监视的键已经被修改， 因此客户端 A 的事务不会被执行，而是直接返回失败。 下文就来介绍 WATCH 的实现机制，并且看看事务系统是如何检查某个被监视的键是否被修改，从而保证事务的安全性的。 WATCH 命令的实现在每个代表数据库的 redis.h/redisDb 结构类型中， 都保存了一个 watched_keys 字典， 字典的键是这个数据库被监视的键， 而字典的值则是一个链表， 链表中保存了所有监视这个键的客户端。 比如说，以下字典就展示了一个 watched_keys 字典的例子： 其中， 键 key1 正在被 client2 、 client5 和 client1 三个客户端监视， 其他一些键也分别被其他别的客户端监视着。 WATCH 命令的作用， 就是将当前客户端和要监视的键在 watched_keys 中进行关联。 举个例子， 如果当前客户端为 client10086 ， 那么当客户端执行 WATCH key1 key2 时， 前面展示的 watched_keys 将被修改成这个样子： 通过 watched_keys 字典， 如果程序想检查某个键是否被监视， 那么它只要检查字典中是否存在这个键即可； 如果程序要获取监视某个键的所有客户端， 那么只要取出键的值（一个链表）， 然后对链表进行遍历即可。 WATCH 的触发在任何对数据库键空间（key space）进行修改的命令成功执行之后 （比如 FLUSHDB 、 SET 、 DEL 、 LPUSH 、 SADD 、 ZREM ，诸如此类）， multi.c/touchWatchedKey 函数都会被调用 —— 它检查数据库的 watched_keys 字典， 看是否有客户端在监视已经被命令修改的键， 如果有的话， 程序将所有监视这个/这些被修改键的客户端的 REDIS_DIRTY_CAS 选项打开： 当客户端发送 EXEC 命令、触发事务执行时， 服务器会对客户端的状态进行检查： 如果客户端的 REDIS_DIRTY_CAS 选项已经被打开，那么说明被客户端监视的键至少有一个已经被修改了，事务的安全性已经被破坏。服务器会放弃执行这个事务，直接向客户端返回空回复，表示事务执行失败。 如果 REDIS_DIRTY_CAS 选项没有被打开，那么说明所有监视键都安全，服务器正式执行事务。 可以用一段伪代码来表示这个检查： 123456789101112def check_safety_before_execute_trasaction(): if client.state &amp; REDIS_DIRTY_CAS: # 安全性已破坏，清除事务状态 clear_transaction_state(client) # 清空事务队列 clear_transaction_queue(client) # 返回空回复给客户端 send_empty_reply(client) else: # 安全性完好，执行事务 execute_transaction() 举个例子，假设数据库的 watched_keys 字典如下图所示： 如果某个客户端对 key1 进行了修改（比如执行 DEL key1 ）， 那么所有监视 key1 的客户端， 包括 client2 、 client5 和 client1 的 REDIS_DIRTY_CAS 选项都会被打开， 当客户端 client2 、 client5 和 client1 执行 EXEC 的时候， 它们的事务都会以失败告终。 最后，当一个客户端结束它的事务时，无论事务是成功执行，还是失败， watched_keys 字典中和这个客户端相关的资料都会被清除。 事务的 ACID 性质勘误：Redis 的事务是保证原子性的，本节的内容将原子性和回滚功能混淆了，等待修复中。 —— 2013.6.23 在传统的关系式数据库中，常常用 ACID 性质来检验事务功能的安全性。 Redis 事务保证了其中的一致性（C）和隔离性（I），但并不保证原子性（A）和持久性（D）。 以下四小节是关于这四个性质的详细讨论。 原子性（Atomicity）单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。 如果一个事务队列中的所有命令都被成功地执行，那么称这个事务执行成功。 另一方面，如果 Redis 服务器进程在执行事务的过程中被停止 —— 比如接到 KILL 信号、宿主机器停机，等等，那么事务执行失败。 当事务失败时，Redis 也不会进行任何的重试或者回滚动作。 一致性（Consistency）Redis 的一致性问题可以分为三部分来讨论：入队错误、执行错误、Redis 进程被终结。 入队错误在命令入队的过程中，如果客户端向服务器发送了错误的命令，比如命令的参数数量不对，等等， 那么服务器将向客户端返回一个出错信息， 并且将客户端的事务状态设为 REDIS_DIRTY_EXEC 。 当客户端执行 EXEC 命令时， Redis 会拒绝执行状态为 REDIS_DIRTY_EXEC 的事务， 并返回失败信息。 1234567891011redis 127.0.0.1:6379&gt; MULTIOKredis 127.0.0.1:6379&gt; set key(error) ERR wrong number of arguments for &apos;set&apos; commandredis 127.0.0.1:6379&gt; EXISTS keyQUEUEDredis 127.0.0.1:6379&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors. 因此，带有不正确入队命令的事务不会被执行，也不会影响数据库的一致性。 执行错误如果命令在事务执行的过程中发生错误，比如说，对一个不同类型的 key 执行了错误的操作， 那么 Redis 只会将错误包含在事务的结果中， 这不会引起事务中断或整个失败，不会影响已执行事务命令的结果，也不会影响后面要执行的事务命令， 所以它对事务的一致性也没有影响。 Redis 进程被终结如果 Redis 服务器进程在执行事务的过程中被其他进程终结，或者被管理员强制杀死，那么根据 Redis 所使用的持久化模式，可能有以下情况出现： 内存模式：如果 Redis 没有采取任何持久化机制，那么重启之后的数据库总是空白的，所以数据总是一致的。 RDB 模式：在执行事务时，Redis 不会中断事务去执行保存 RDB 的工作，只有在事务执行之后，保存 RDB 的工作才有可能开始。所以当 RDB 模式下的 Redis 服务器进程在事务中途被杀死时，事务内执行的命令，不管成功了多少，都不会被保存到 RDB 文件里。恢复数据库需要使用现有的 RDB 文件，而这个 RDB 文件的数据保存的是最近一次的数据库快照（snapshot），所以它的数据可能不是最新的，但只要 RDB 文件本身没有因为其他问题而出错，那么还原后的数据库就是一致的。 AOF 模式：因为保存 AOF 文件的工作在后台线程进行，所以即使是在事务执行的中途，保存 AOF 文件的工作也可以继续进行，因此，根据事务语句是否被写入并保存到 AOF 文件，有以下两种情况发生： 1）如果事务语句未写入到 AOF 文件，或 AOF 未被 SYNC 调用保存到磁盘，那么当进程被杀死之后，Redis 可以根据最近一次成功保存到磁盘的 AOF 文件来还原数据库，只要 AOF 文件本身没有因为其他问题而出错，那么还原后的数据库总是一致的，但其中的数据不一定是最新的。 2）如果事务的部分语句被写入到 AOF 文件，并且 AOF 文件被成功保存，那么不完整的事务执行信息就会遗留在 AOF 文件里，当重启 Redis 时，程序会检测到 AOF 文件并不完整，Redis 会退出，并报告错误。需要使用 redis-check-aof 工具将部分成功的事务命令移除之后，才能再次启动服务器。还原之后的数据总是一致的，而且数据也是最新的（直到事务执行之前为止）。 隔离性（Isolation）Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。 持久性（Durability）因为事务不过是用队列包裹起了一组 Redis 命令，并没有提供任何额外的持久性功能，所以事务的持久性由 Redis 所使用的持久化模式决定： 在单纯的内存模式下，事务肯定是不持久的。 在 RDB 模式下，服务器可能在事务执行之后、RDB 文件更新之前的这段时间失败，所以 RDB 模式下的 Redis 事务也是不持久的。 在 AOF 的“总是 SYNC ”模式下，事务的每条命令在执行成功之后，都会立即调用 fsync 或 fdatasync 将事务数据写入到 AOF 文件。但是，这种保存是由后台线程进行的，主线程不会阻塞直到保存成功，所以从命令执行成功到数据保存到硬盘之间，还是有一段非常小的间隔，所以这种模式下的事务也是不持久的。 其他 AOF 模式也和“总是 SYNC ”模式类似，所以它们都是不持久的。 小结 事务提供了一种将多个命令打包，然后一次性、有序地执行的机制。 事务在执行过程中不会被中断，所有事务命令执行完之后，事务才能结束。 多个命令会被入队到事务队列中，然后按先进先出（FIFO）的顺序执行。 带 WATCH 命令的事务会将客户端和被监视的键在数据库的 watched_keys 字典中进行关联，当键被修改时，程序会将所有监视被修改键的客户端的 REDIS_DIRTY_CAS 选项打开。 只有在客户端的 REDIS_DIRTY_CAS 选项未被打开时，才能执行事务，否则事务直接返回失败。 Redis 的事务保证了 ACID 中的一致性（C）和隔离性（I），但并不保证原子性（A）和持久性（D）。 参考事务]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的几种实现方式]]></title>
    <url>%2Fredis%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[目前几乎很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。分布式的CAP理论告诉我们“任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。 在很多场景中，我们为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。有的时候，我们需要保证一个方法在同一时间内只能被同一个线程执行。在单机环境中，Java中其实提供了很多并发处理相关的API，但是这些API在分布式场景中就无能为力了。也就是说单纯的Java Api并不能提供分布式锁的能力。所以针对分布式锁的实现目前有多种方案。 针对分布式锁的实现，目前比较常用的有以下几种方案： 基于数据库实现分布式锁 基于缓存（redis，memcached，tair）实现分布式锁 基于Zookeeper实现分布式锁 在分析这几种实现方案之前我们先来想一下，我们需要的分布式锁应该是怎么样的？（这里以方法锁为例，资源锁同理） 可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。 这把锁要是一把可重入锁（避免死锁） 这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条） 有高可用的获取锁和释放锁功能 获取锁和释放锁的性能要好 基于数据库实现分布式锁基于数据库表要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。 当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。 创建这样一张数据库表： 12345678CREATE TABLE `methodLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `method_name` varchar(64) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;锁定的方法名&apos;, `desc` varchar(1024) NOT NULL DEFAULT &apos;备注信息&apos;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;保存数据时间，自动生成&apos;, PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;锁定中的方法&apos;; 当我们想要锁住某个方法时，执行以下SQL： 1insert into methodLock(method_name,desc) values (‘method_name’,‘desc’) 因为我们对method_name做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。 当方法执行完毕之后，想要释放锁的话，需要执行以下Sql: 1delete from methodLock where method_name =&apos;method_name&apos; 上面这种简单的实现有以下几个问题： 1、这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。 2、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。 3、这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。 4、这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。 当然，我们也可以有其他方式解决上面的问题。 数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。 没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。 非阻塞的？搞一个while循环，直到insert成功再返回成功。 非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。 基于数据库排他锁除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。 我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。 基于MySql的InnoDB引擎，可以使用以下方法来实现加锁操作： 123456789101112131415public boolean lock()&#123; connection.setAutoCommit(false) while(true)&#123; try&#123; result = select * from methodLock where method_name=xxx for update; if(result==null)&#123; return true; &#125; &#125;catch(Exception e)&#123; &#125; sleep(1000); &#125; return false;&#125; 在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给method_name添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。 我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁： 123public void unlock()&#123; connection.commit();&#125; 通过connection.commit()操作来释放锁。 这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。 阻塞锁？ for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。 锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。 但是还是无法直接解决数据库单点和可重入问题。 这里还可能存在另外一个问题，虽然我们对method_name 使用了唯一索引，并且显示使用for update来使用行级锁。但是，MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。如果发生这种情况就悲剧了。。。 还有一个问题，就是我们要使用排他锁来进行分布式锁的lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆 总结总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。 数据库实现分布式锁的优点 直接借助数据库，容易理解。 数据库实现分布式锁的缺点 会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。 操作数据库需要一定的开销，性能问题需要考虑。 使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。 基于缓存实现分布式锁相比较于基于数据库实现分布式锁的方案来说，基于缓存来实现在性能方面会表现的更好一点。而且很多缓存是可以集群部署的，可以解决单点问题。 目前有很多成熟的缓存产品，包括Redis，memcached以及我们公司内部的Tair。 这里以Tair为例来分析下使用缓存实现分布式锁的方案。关于Redis和memcached在网络上有很多相关的文章，并且也有一些成熟的框架及算法可以直接使用。 基于Tair的实现分布式锁其实和Redis类似，其中主要的实现方式是使用TairManager.put方法来实现。 12345678910public boolean trylock(String key) &#123; ResultCode code = ldbTairManager.put(NAMESPACE, key, "This is a Lock.", 2, 0); if (ResultCode.SUCCESS.equals(code)) return true; else return false;&#125;public boolean unlock(String key) &#123; ldbTairManager.invalid(NAMESPACE, key);&#125; 以上实现方式同样存在几个问题： 1、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在tair中，其他线程无法再获得到锁。 2、这把锁只能是非阻塞的，无论成功还是失败都直接返回。 3、这把锁是非重入的，一个线程获得锁之后，在释放锁之前，无法再次获得该锁，因为使用到的key在tair中已经存在。无法再执行put操作。 当然，同样有方式可以解决。 没有失效时间？tair的put方法支持传入失效时间，到达时间之后数据会自动删除。 非阻塞？while重复执行。 非可重入？在一个线程获取到锁之后，把当前主机信息和线程信息保存起来，下次再获取之前先检查自己是不是当前锁的拥有者。 但是，失效时间我设置多长时间为好？如何设置的失效时间太短，方法没等执行完，锁就自动释放了，那么就会产生并发问题。如果设置的时间太长，其他获取锁的线程就可能要平白的多等一段时间。这个问题使用数据库实现分布式锁同样存在 总结可以使用缓存来代替数据库来实现分布式锁，这个可以提供更好的性能，同时，很多缓存服务都是集群部署的，可以避免单点问题。并且很多缓存服务都提供了可以用来实现分布式锁的方法，比如Tair的put方法，redis的setnx方法等。并且，这些缓存服务也都提供了对数据的过期自动删除的支持，可以直接设置超时时间来控制锁的释放。 使用缓存实现分布式锁的优点 性能好，实现起来较为方便。 使用缓存实现分布式锁的缺点 通过超时时间来控制锁的失效时间并不是十分的靠谱。 基于Zookeeper实现分布式锁基于zookeeper临时有序节点可以实现的分布式锁。 大致思想即为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。 来看下Zookeeper能不能解决前面提到的问题。 锁无法释放？使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。 非阻塞锁？使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。 不可重入？使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。 单点问题？使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。 可以直接使用zookeeper第三方库Curator客户端，这个客户端中封装了一个可重入的锁服务。 123456789101112131415161718public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; try &#123; return interProcessMutex.acquire(timeout, unit); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return true;&#125;public boolean unlock() &#123; try &#123; interProcessMutex.release(); &#125; catch (Throwable e) &#123; log.error(e.getMessage(), e); &#125; finally &#123; executorService.schedule(new Cleaner(client, path), delayTimeForClean, TimeUnit.MILLISECONDS); &#125; return true;&#125; Curator提供的InterProcessMutex是分布式锁的实现。acquire方法用户获取锁，release方法用于释放锁。 使用ZK实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。 其实，使用Zookeeper也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端可ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。） 总结使用Zookeeper实现分布式锁的优点 有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。 使用Zookeeper实现分布式锁的缺点 性能上不如使用缓存实现分布式锁。 需要对ZK的原理有所了解。 三种方案的比较上面几种方式，哪种方式都无法做到完美。就像CAP一样，在复杂性、可靠性、性能等方面无法同时满足，所以，根据不同的应用场景选择最适合自己的才是王道。 从理解的难易程度角度（从低到高）数据库 &gt; 缓存 &gt; Zookeeper 从实现的复杂性角度（从低到高）Zookeeper &gt;= 缓存 &gt; 数据库 从性能角度（从高到低）缓存 &gt; Zookeeper &gt;= 数据库 从可靠性角度（从高到低）Zookeeper &gt; 缓存 &gt; 数据库 原文]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis合集]]></title>
    <url>%2Fredis%2Fredis%E5%90%88%E9%9B%86%2F</url>
    <content type="text"><![CDATA[分布式锁Redis RedLock 完美的分布式锁么？ 聊一聊分布式锁的设计 redis分布式锁实现 分布式锁的几种实现方式 Redis 学习教程 redis并发问题 redis下并发问题解决方案 事务事务 持久化持久化 分区Redis分区实现原理 https://mp.weixin.qq.com/s/Ime_GyDkAJMTird1nWRNUA http://mp.weixin.qq.com/s__biz=MzIwNDU2MTI4NQ==&amp;mid=2247483728&amp;idx=1&amp;sn=c2076dbc98de6fbd40b87236f2033925&amp;chksm=973f0fbaa04886ac83c975b7046885f7171be8d26695d23fcab974124ce054a65d10caea3db5&amp;scene=21#wechat_redirect]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java IO]]></title>
    <url>%2Fjava%2FJava%20IO%2F</url>
    <content type="text"><![CDATA[也谈BIO | NIO | AIO （Java版） Java NIO浅析]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>io</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty相关概念]]></title>
    <url>%2Fnetty%2Fnetty%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[怎样理解阻塞非阻塞与同步异步的区别？ 也谈BIO | NIO | AIO （Java版） 通俗地讲，Netty 能做什么？ Netty的核心组件 Netty入门教程——认识NettyNetty入门教程2——动手搭建HttpServerNetty入门教程3——Decoder和EncoderNetty笔记4-如何实现长连接Essential Netty in Action 《Netty 实战(精髓)》Way Lau’s Open Souce Books 源码源码之下无秘密 ── 做最好的 Netty 源码分析教程 zero copyNetty的零拷贝体现在三个方面： Netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才写入Socket中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。 Netty提供了组合Buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个Buffer那样方便的对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。 Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。 Netty中的零拷贝对于 Netty ByteBuf 的零拷贝(Zero Copy) 的理解 概述Netty概述 Java NIO浅析]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql索引及查询优化]]></title>
    <url>%2Fmysql%2Fmysql%E7%B4%A2%E5%BC%95%E5%8F%8A%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[建索引的几大原则 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录 索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’); 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可 慢查询优化基本步骤 先运行看看是否真的很慢，注意设置SQL_NO_CACHE where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高 explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询） order by limit 形式的sql语句让排序的表优先查 了解业务方使用场景 加索引时参照建索引的几大原则 观察结果，不符合预期继续从0分析 常用索引优化 有索引但未被用到的情况（不建议） Like的参数以通配符开头时，将导致全表扫描 where条件不符合最左前缀原则时 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。优化器将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行 索引列参与计算 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描。可以在num上设置默认值0，确保表中num列没有null值 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描 避免select * order by 语句优化 GROUP BY语句优化 用 exists 代替 in 使用 varchar/nvarchar 代替 char/nchar 能用DISTINCT的就不用GROUP BY 能用UNION ALL就不要用UNION 在Join表的时候使用相当类型的例，并将其索引 MYSQL性能优化的最佳20+条经验MySQL 索引及查询优化总结 参考MySQL 索引及查询优化总结MySQL索引原理及慢查询优化]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[感悟]]></title>
    <url>%2F%E6%84%9F%E6%82%9F%2F</url>
    <content type="text"><![CDATA[当想找到一种通用的解决策略时，可以先列出所有的情况，然后再找统一的策略。 每天至少做3件事，长时间关注于一件事，容易迷茫。]]></content>
  </entry>
  <entry>
    <title><![CDATA[彻底看懂 so called 红黑树]]></title>
    <url>%2Fjava%2Fdatastructure%2Ftreemap%2F</url>
    <content type="text"><![CDATA[为了理解 TreeMap 的底层实现，必须先介绍排序二叉树和红黑树这两种数据结构。其中红黑树又是一种特殊的排序二叉树。 排序二叉树排序二叉树是一种特殊结构的二叉树，可以非常方便地对树中所有节点进行排序和检索。 排序二叉树要么是一棵空二叉树，要么是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若它的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 它的左、右子树也分别为排序二叉树。 图 1 显示了一棵排序二叉树： 对排序二叉树，若按中序遍历就可以得到由小到大的有序序列。如图 1 所示二叉树，中序遍历得： {2，3，4，8，9，9，10，13，15，18} 排序二叉树的中序遍历，最终结果是从小到大的升序排列。 添加节点创建排序二叉树的步骤，也就是不断地向排序二叉树添加节点的过程，向排序二叉树添加节点的步骤如下： 以根节点当前节点开始搜索。 拿新节点的值和当前节点的值比较。 如果新节点的值更大，则以当前节点的右子节点作为新的当前节点；如果新节点的值更小，则以当前节点的左子节点作为新的当前节点。 重复 2、3 两个步骤，直到搜索到合适的叶子节点为止。 将新节点添加为第 4 步找到的叶子节点的子节点；如果新节点更大，则添加为右子节点；否则添加为左子节点。 删除节点当程序从排序二叉树中删除一个节点之后，为了让它依然保持为排序二叉树，程序必须对该排序二叉树进行维护。维护可分为如下几种情况： （1）被删除的节点是叶子节点，则只需将它从其父节点中删除即可。 （2）被删除节点 p 只有左子树，将 p 的左子树 pL 添加成 p 的父节点的左子树即可；被删除节点 p 只有右子树，将 p 的右子树 pR 添加成 p 的父节点的右子树即可。 （3）若被删除节点 p 的左、右子树均非空，有两种做法： 将 pL 设为 p 的父节点 q 的左或右子节点（取决于 p 是其父节点 q 的左、右子节点），将 pR 设为 p 节点的中序前趋节点 s 的右子节点（s 是 pL 最右下的节点，也就是 pL 子树中最大的节点）。 以 p 节点的中序前趋或后继替代 p 所指节点，然后再从原排序二叉树中删去中序前趋或后继节点即可。（也就是用大于 p 的最小节点或小于 p 的最大节点代替 p 节点即可）。 图 2. 被删除节点只有左子树 图 3 显示了被删除节点只有右子树的示意图： 图 4 显示了被删除节点既有左子节点，又有右子节点的情形，此时我们采用到是第一种方式进行维护： 图 5 显示了被删除节点既有左子树，又有右子树的情形，此时我们采用到是第二种方式进行维护： TreeMapTreeMap的添加和删除节点，是在二叉排序树的添加、删除的基础上，进行旋转和变色。 添加节点掌握上面理论之后，下面我们来分析 TreeMap 添加节点（TreeMap 中使用 Entry 内部类代表节点）的实现，TreeMap 集合的 put(K key, V value) 方法实现了将 Entry 放入排序二叉树中，下面是该方法的源代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public V put(K key, V value) &#123; // 先以 t 保存链表的 root 节点 Entry&lt;K,V&gt; t = root; // 如果 t==null，表明是一个空链表，即该 TreeMap 里没有任何 Entry if (t == null) &#123; // 将新的 key-value 创建一个 Entry，并将该 Entry 作为 root root = new Entry&lt;K,V&gt;(key, value, null); // 设置该 Map 集合的 size 为 1，代表包含一个 Entry size = 1; // 记录修改次数为 1 modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; Comparator&lt;? super K&gt; cpr = comparator; // 如果比较器 cpr 不为 null，即表明采用定制排序 if (cpr != null) &#123; do &#123; // 使用 parent 上次循环后的 t 所引用的 Entry parent = t; // 拿新插入 key 和 t 的 key 进行比较 cmp = cpr.compare(key, t.key); // 如果新插入的 key 小于 t 的 key，t 等于 t 的左边节点 if (cmp &lt; 0) t = t.left; // 如果新插入的 key 大于 t 的 key，t 等于 t 的右边节点 else if (cmp &gt; 0) t = t.right; // 如果两个 key 相等，新的 value 覆盖原有的 value， // 并返回原有的 value else return t.setValue(value); &#125; while (t != null); &#125; else &#123; if (key == null) throw new NullPointerException(); Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; // 使用 parent 上次循环后的 t 所引用的 Entry parent = t; // 拿新插入 key 和 t 的 key 进行比较 cmp = k.compareTo(t.key); // 如果新插入的 key 小于 t 的 key，t 等于 t 的左边节点 if (cmp &lt; 0) t = t.left; // 如果新插入的 key 大于 t 的 key，t 等于 t 的右边节点 else if (cmp &gt; 0) t = t.right; // 如果两个 key 相等，新的 value 覆盖原有的 value， // 并返回原有的 value else return t.setValue(value); &#125; while (t != null); &#125; // 将新插入的节点作为 parent 节点的子节点 Entry&lt;K,V&gt; e = new Entry&lt;K,V&gt;(key, value, parent); // 如果新插入 key 小于 parent 的 key，则 e 作为 parent 的左子节点 if (cmp &lt; 0) parent.left = e; // 如果新插入 key 小于 parent 的 key，则 e 作为 parent 的右子节点 else parent.right = e; // 修复红黑树 fixAfterInsertion(e); // ① size++; modCount++; return null; &#125; 每当程序希望添加新节点时：系统总是从树的根节点开始比较 —— 即将根节点当成当前节点，如果新增节点大于当前节点、并且当前节点的右子节点存在，则以右子节点作为当前节点；如果新增节点小于当前节点、并且当前节点的左子节点存在，则以左子节点作为当前节点；如果新增节点等于当前节点，则用新增节点覆盖当前节点，并结束循环 —— 直到找到某个节点的左、右子节点不存在，将新节点添加该节点的子节点 —— 如果新节点比该节点大，则添加为右子节点；如果新节点比该节点小，则添加为左子节点。 删除节点TreeMap 删除节点采用图 5 所示右边的情形进行维护（中序遍历顺序的后继节点）——也就是用被删除节点的右子树中最小节点与被删节点交换的方式进行维护。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private void deleteEntry(Entry&lt;K,V&gt; p) &#123; modCount++; size--; // 如果被删除节点的左子树、右子树都不为空 if (p.left != null &amp;&amp; p.right != null) &#123; // 用 p 节点的中序后继节点代替 p 节点，且p必然为叶子节点（可参考中序遍历的顺序），所以p.left == null, p.right == null Entry&lt;K,V&gt; s = successor (p); p.key = s.key; p.value = s.value; p = s; &#125; // 如果 p 节点的左节点存在，replacement 代表左节点；否则代表右节点。 Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right); if (replacement != null) // p 只有一个节点（如果 p 有两个节点，那么 replacement 为 null） &#123; replacement.parent = p.parent; // 如果 p 没有父节点，则 replacemment 变成父节点 if (p.parent == null) root = replacement; // 如果 p 节点是其父节点的左子节点 else if (p == p.parent.left) p.parent.left = replacement; // 如果 p 节点是其父节点的右子节点 else p.parent.right = replacement; p.left = p.right = p.parent = null; // 修复红黑树 if (p.color == BLACK) // 当 p 为黑色时，由于 p 被删除，那么少了一个黑色节点，需要重新平衡 fixAfterDeletion(replacement); // ① &#125; // 如果 p 节点没有父节点 else if (p.parent == null) &#123; root = null; &#125; else &#123; // 删除子节点 if (p.color == BLACK) // 修复红黑树 fixAfterDeletion(p); // ② if (p.parent != null) &#123; // 如果 p 是其父节点的左子节点 if (p == p.parent.left) p.parent.left = null; // 如果 p 是其父节点的右子节点 else if (p == p.parent.right) p.parent.right = null; p.parent = null; &#125; &#125; &#125; 红黑树红黑树在原有的排序二叉树增加了如下几个要求： 性质 1：每个节点要么是红色，要么是黑色。 性质 2：根节点永远是黑色的。 性质 3：所有的叶节点都是空节点（即 null），并且是黑色的。 性质 4：每个红色节点的两个子节点都是黑色。（从每个叶子到根的路径上不会有两个连续的红色节点，但是黑色节点可以连续） 性质 5：从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点。 注意：上面的性质 3 中指定红黑树的每个叶子节点都是空节点，而且并叶子节点都是黑色。但 Java 实现的红黑树将使用 null 来代表空节点，因此遍历红黑树时将看不到黑色的叶子节点，反而看到每个叶子节点都是红色的。 Java 中实现的红黑树可能有如图 6 所示结构： 备注：本文中所有关于红黑树中的示意图采用白色代表红色。黑色节点还是采用了黑色表示。 根据性质 5：红黑树从根节点到每个叶子节点的路径都包含相同数量的黑色节点，因此从根节点到叶子节点的路径中包含的黑色节点数被称为树的“黑色高度（black-height）”。 性质 4 则保证了从根节点到叶子节点的最长路径的长度不会超过任何其他路径的两倍。假如有一棵黑色高度为 3 的红黑树：从根节点到叶节点的最短路径长度是 2，该路径上全是黑色节点（黑节点 - 黑节点 - 黑节点）。最长路径也只可能为 4，在每个黑色节点之间插入一个红色节点（黑节点 - 红节点 - 黑节点 - 红节点 - 黑节点），性质 4 保证绝不可能插入更多的红色节点。由此可见，红黑树中最长路径就是一条红黑交替的路径。 由此我们可以得出结论：对于给定的黑色高度为 N 的红黑树，从根到叶子节点的最短路径长度为 N-1，最长路径长度为 2 * (N-1)。 提示：排序二叉树的深度直接影响了检索的性能，正如前面指出，当插入节点本身就是由小到大排列时，排序二叉树将变成一个链表，这种排序二叉树的检索性能最低：N 个节点的二叉树深度就是 N-1。 红黑树通过上面这种限制来保证它大致是平衡的——因为红黑树的高度不会无限增高，这样保证红黑树在最坏情况下都是高效的，不会出现普通排序二叉树的情况。 由于红黑树只是一个特殊的排序二叉树，因此对红黑树上的只读操作与普通排序二叉树上的只读操作完全相同，只是红黑树保持了大致平衡，因此检索性能比排序二叉树要好很多。 但在红黑树上进行插入操作和删除操作会导致树不再符合红黑树的特征，因此插入操作和删除操作都需要进行一定的维护，以保证插入节点、删除节点后的树依然是红黑树。 注意：红黑树并不是真正的平衡二叉树，但在实际应用中，红黑树的统计性能要高于平衡二叉树，但极端性能略差。 添加节点后的修复上面 put(K key, V value) 方法中①`号代码处使用fixAfterInsertion(e) 方法来修复红黑树——因此每次插入节点后必须进行简单修复，使该排序二叉树满足红黑树的要求。` 插入操作按如下步骤进行： （1）以排序二叉树的方法插入新节点，并将它设为红色。 （2）进行颜色调换和树旋转。 在插入操作中，红黑树的性质 1 和性质 3 两个永远不会发生改变，因此无需考虑红黑树的这两个特性。 这种颜色调用和树旋转就比较复杂了，下面将分情况进行介绍。在介绍中，我们把新插入的节点定义为 N 节点，N 节点的父节点定义为 P 节点，P 节点的兄弟节点定义为 U 节点，P 节点父节点定义为 G 节点。 下面分成不同情形来分析插入操作 情形 1：新节点 N 是树的根节点，没有父节点 在这种情形下，直接将它设置为黑色以满足性质 2。 情形 2：新节点的父节点 P 是黑色 在这种情况下，新插入的节点是红色的，因此依然满足性质 4。而且因为新节点 N 有两个黑色叶子节点；但是由于新节点 N 是红色，通过它的每个子节点的路径依然保持相同的黑色节点数，因此依然满足性质 5。 情形 3：如果父节点 P 和父节点的兄弟节点 U 都是红色 在这种情况下，程序应该将 P 节点、U 节点都设置为黑色，并将 P 节点的父节点设为红色（用来保持性质 5）。现在新节点 N 有了一个黑色的父节点 P。由于从 P 节点、U 节点到根节点的任何路径都必须通过 G 节点，在这些路径上的黑节点数目没有改变（原来有叶子和 G 节点两个黑色节点，现在有叶子和 P 两个黑色节点）。 经过上面处理后，红色的 G 节点的父节点也有可能是红色的，这就违反了性质 4，因此还需要对 G 节点递归地进行整个过程（把 G 当成是新插入的节点进行处理即可）。 图 7 显示了这种处理过程： 备注：虽然图 11.28 绘制的是新节点 N 作为父节点 P 左子节点的情形，其实新节点 N 作为父节点 P 右子节点的情况与图 11.28 完全相同。 情形 4：父节点 P 是红色、而其兄弟节点 U 是黑色或缺少；且新节点 N 是父节点 P 的右子节点，而父节点 P 又是其父节点 G 的左子节点。 在这种情形下，我们进行一次左旋转对新节点和其父节点进行，接着按情形 5 处理以前的父节点 P（也就是把 P 当成新插入的节点即可）。这导致某些路径通过它们以前不通过的新节点 N 或父节点 P 的其中之一，但是这两个节点都是红色的，因此不会影响性质 5。 图 8 显示了对情形 4 的处理： 备注：图 11.29 中 P 节点是 G 节点的左子节点，如果 P 节点是其父节点 G 节点的右子节点，那么上 面的处理情况应该左、右对调一下。 情形 5：父节点 P 是红色、而其兄弟节点 U 是黑色或缺少；且新节点 N 是其父节点的左子节点，而父节点 P 又是其父节点 G 的左子节点。 在这种情形下，需要对节点 G 的一次右旋转，在旋转产生的树中，以前的父节点 P 现在是新节点 N 和节点 G 的父节点。由于以前的节点 G 是黑色，否则父节点 P 就不可能是红色，我们切换以前的父节点 P 和节点 G 的颜色，使之满足性质 4，性质 5 也仍然保持满足，因为通过这三个节点中任何一个的所有路径以前都通过节点 G，现在它们都通过以前的父节点 P。在各自的情形下，这都是三个节点中唯一的黑色节点。 图 9 显示了情形 5 的处理过程： 备注：图 11.30 中 P 节点是 G 节点的左子节点，如果 P 节点是其父节点 G 节点的右子节点，那么上面的处理情况应该左、右对调一下。 情形 4 和情形 5 中的新插入的N节点，貌似会破坏红黑树的性质5（从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点），实际上，新节点N是由于变色而来的，其内部是包含一个黑色节点的。 TreeMap 为插入节点后的修复操作由 fixAfterInsertion(Entry&lt;K,V&gt; x) 方法提供，该方法的源代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// 插入节点后修复红黑树private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123; x.color = RED; // 直到 x 节点的父节点不是根，且 x 的父节点不是红色 while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; // 如果 x 的父节点是其父节点的左子节点 if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123; // 获取 x 的父节点的兄弟节点 Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x))); // 如果 x 的父节点的兄弟节点是红色 if (colorOf(y) == RED) &#123; // 将 x 的父节点设为黑色 setColor(parentOf(x), BLACK); // 将 x 的父节点的兄弟节点设为黑色 setColor(y, BLACK); // 将 x 的父节点的父节点设为红色 setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); &#125; // 如果 x 的父节点的兄弟节点是黑色 else &#123; // 如果 x 是其父节点的右子节点 if (x == rightOf(parentOf(x))) &#123; // 将 x 的父节点设为 x x = parentOf(x); rotateLeft(x); &#125; // 把 x 的父节点设为黑色 setColor(parentOf(x), BLACK); // 把 x 的父节点的父节点设为红色 setColor(parentOf(parentOf(x)), RED); rotateRight(parentOf(parentOf(x))); &#125; &#125; // 如果 x 的父节点是其父节点的右子节点 else &#123; // 获取 x 的父节点的兄弟节点 Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x))); // 如果 x 的父节点的兄弟节点是红色 if (colorOf(y) == RED) &#123; // 将 x 的父节点设为黑色。 setColor(parentOf(x), BLACK); // 将 x 的父节点的兄弟节点设为黑色 setColor(y, BLACK); // 将 x 的父节点的父节点设为红色 setColor(parentOf(parentOf(x)), RED); // 将 x 设为 x 的父节点的节点 x = parentOf(parentOf(x)); &#125; // 如果 x 的父节点的兄弟节点是黑色 else &#123; // 如果 x 是其父节点的左子节点 if (x == leftOf(parentOf(x))) &#123; // 将 x 的父节点设为 x x = parentOf(x); rotateRight(x); &#125; // 把 x 的父节点设为黑色 setColor(parentOf(x), BLACK); // 把 x 的父节点的父节点设为红色 setColor(parentOf(parentOf(x)), RED); rotateLeft(parentOf(parentOf(x))); &#125; &#125; &#125; // 将根节点设为黑色 root.color = BLACK; &#125; 删除节点后的修复与添加节点之后的修复类似的是，TreeMap 删除节点之后也需要进行类似的修复操作，通过这种修复来保证该排序二叉树依然满足红黑树特征。大家可以参考插入节点之后的修复来分析删除之后的修复。TreeMap 在删除之后的修复操作由 fixAfterDeletion(Entry&lt;K,V&gt; x) 方法提供，该方法源代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102// 删除节点后修复红黑树private void fixAfterDeletion(Entry&lt;K,V&gt; x) &#123; // 直到 x 不是根节点，且 x 的颜色是黑色 while (x != root &amp;&amp; colorOf(x) == BLACK) &#123; // 如果 x 是其父节点的左子节点 if (x == leftOf(parentOf(x))) &#123; // 获取 x 节点的兄弟节点 Entry&lt;K,V&gt; sib = rightOf(parentOf(x)); // 如果 sib 节点是红色 if (colorOf(sib) == RED) &#123; // 将 sib 节点设为黑色 setColor(sib, BLACK); // 将 x 的父节点设为红色 setColor(parentOf(x), RED); rotateLeft(parentOf(x)); // 再次将 sib 设为 x 的父节点的右子节点 sib = rightOf(parentOf(x)); &#125; // 如果 sib 的两个子节点都是黑色 if (colorOf(leftOf(sib)) == BLACK &amp;&amp; colorOf(rightOf(sib)) == BLACK) &#123; // 将 sib 设为红色 setColor(sib, RED); // 让 x 等于 x 的父节点 x = parentOf(x); &#125; else &#123; // 如果 sib 的只有右子节点是黑色 if (colorOf(rightOf(sib)) == BLACK) &#123; // 将 sib 的左子节点也设为黑色 setColor(leftOf(sib), BLACK); // 将 sib 设为红色 setColor(sib, RED); rotateRight(sib); sib = rightOf(parentOf(x)); &#125; // 设置 sib 的颜色与 x 的父节点的颜色相同 setColor(sib, colorOf(parentOf(x))); // 将 x 的父节点设为黑色 setColor(parentOf(x), BLACK); // 将 sib 的右子节点设为黑色 setColor(rightOf(sib), BLACK); rotateLeft(parentOf(x)); x = root; &#125; &#125; // 如果 x 是其父节点的右子节点 else &#123; // 获取 x 节点的兄弟节点 Entry&lt;K,V&gt; sib = leftOf(parentOf(x)); // 如果 sib 的颜色是红色 if (colorOf(sib) == RED) &#123; // 将 sib 的颜色设为黑色 setColor(sib, BLACK); // 将 sib 的父节点设为红色 setColor(parentOf(x), RED); rotateRight(parentOf(x)); sib = leftOf(parentOf(x)); &#125; // 如果 sib 的两个子节点都是黑色 if (colorOf(rightOf(sib)) == BLACK &amp;&amp; colorOf(leftOf(sib)) == BLACK) &#123; // 将 sib 设为红色 setColor(sib, RED); // 让 x 等于 x 的父节点 x = parentOf(x); &#125; else &#123; // 如果 sib 只有左子节点是黑色 if (colorOf(leftOf(sib)) == BLACK) &#123; // 将 sib 的右子节点也设为黑色 setColor(rightOf(sib), BLACK); // 将 sib 设为红色 setColor(sib, RED); rotateLeft(sib); sib = leftOf(parentOf(x)); &#125; // 将 sib 的颜色设为与 x 的父节点颜色相同 setColor(sib, colorOf(parentOf(x))); // 将 x 的父节点设为黑色 setColor(parentOf(x), BLACK); // 将 sib 的左子节点设为黑色 setColor(leftOf(sib), BLACK); rotateRight(parentOf(x)); x = root; &#125; &#125; &#125; setColor(x, BLACK); &#125; 检索节点当 TreeMap 根据 key 来取出 value 时，TreeMap 对应的方法如下：1234567public V get(Object key) &#123; // 根据指定 key 取出对应的 Entry Entry&gt;K,V&lt; p = getEntry(key); // 返回该 Entry 所包含的 value return (p==null ? null : p.value); &#125; 从上面程序的粗体字代码可以看出，get(Object key) 方法实质是由于 getEntry() 方法实现的，这个 getEntry() 方法的代码如下：1234567891011121314151617181920212223242526272829final Entry&lt;K,V&gt; getEntry(Object key) &#123; // 如果 comparator 不为 null，表明程序采用定制排序 if (comparator != null) // 调用 getEntryUsingComparator 方法来取出对应的 key return getEntryUsingComparator(key); // 如果 key 形参的值为 null，抛出 NullPointerException 异常 if (key == null) throw new NullPointerException(); // 将 key 强制类型转换为 Comparable 实例 Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; // 从树的根节点开始 Entry&lt;K,V&gt; p = root; while (p != null) &#123; // 拿 key 与当前节点的 key 进行比较 int cmp = k.compareTo(p.key); // 如果 key 小于当前节点的 key，向“左子树”搜索 if (cmp &lt; 0) p = p.left; // 如果 key 大于当前节点的 key，向“右子树”搜索 else if (cmp &gt; 0) p = p.right; // 不大于、不小于，就是找到了目标 Entry else return p; &#125; return null; &#125; 上面的 getEntry(Object obj) 方法也是充分利用排序二叉树的特征来搜索目标 Entry，程序依然从二叉树的根节点开始，如果被搜索节点大于当前节点，程序向“右子树”搜索；如果被搜索节点小于当前节点，程序向“左子树”搜索；如果相等，那就是找到了指定节点。 当 TreeMap 里的 comparator != null 即表明该 TreeMap 采用了定制排序，在采用定制排序的方式下，TreeMap 采用 getEntryUsingComparator(key) 方法来根据 key 获取 Entry。下面是该方法的代码：1234567891011121314151617181920212223242526final Entry&lt;K,V&gt; getEntryUsingComparator(Object key) &#123; K k = (K) key; // 获取该 TreeMap 的 comparator Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; // 从根节点开始 Entry&lt;K,V&gt; p = root; while (p != null) &#123; // 拿 key 与当前节点的 key 进行比较 int cmp = cpr.compare(k, p.key); // 如果 key 小于当前节点的 key，向“左子树”搜索 if (cmp &lt; 0) p = p.left; // 如果 key 大于当前节点的 key，向“右子树”搜索 else if (cmp &gt; 0) p = p.right; // 不大于、不小于，就是找到了目标 Entry else return p; &#125; &#125; return null; &#125; 其实 getEntry、getEntryUsingComparator 两个方法的实现思路完全类似，只是前者对自然排序的 TreeMap 获取有效，后者对定制排序的 TreeMap 有效。 通过上面源代码的分析不难看出，TreeMap 这个工具类的实现其实很简单。或者说：从内部结构来看，TreeMap 本质上就是一棵“红黑树”，而 TreeMap 的每个 Entry 就是该红黑树的一个节点。 参考 通过分析 JDK 源代码研究 TreeMap 红黑树算法实现 红黑树详细分析，看了都说好 红黑树的变色与旋转 红黑树插入删除过程 复习红黑树（二）–红黑树的删除 重温数据结构：深入理解红黑树]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试]]></title>
    <url>%2F%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[跳槽时时刻刻都在发生，但是我建议大家跳槽之前，先想清楚为什么要跳槽。切不可跟风，看到同事一个个都走了，自己也盲目的面试起来（期间也没有准备充分），到底是因为技术原因（影响自己的发展，偏移自己规划的轨迹），还是钱给少了，不受重视。 准备不充分的面试，完全是浪费时间，更是对自己的不负责（如果title很高，当我没说）。 今天给大家分享下chenssy在这次跳槽中整理的Java面试大纲，其中大部分都是面试过程中的面试题，可以对照这查漏补缺，当然了，这里所列的肯定不可能覆盖全部方式。 项目介绍大部分情况，这是一场面试的开门题，面试官问这个问题，主要是考察你的概述能力和全局视野。有的人经常抱怨自己每天在堆业务，但没有成长。事实上，很多情况下确实在堆业务，但并不是没有成长的。并非做中间件或者技术架构才是成长，例如我们的需求分析能力，沟通协作能力，产品思维能力，抽象建模能力等都是一个非常重要的硬实力。 好的，现在进入正文。 1、明确项目是做什么的 2、明确项目的价值。（为什么做这个项目，它解决了用户什么痛点，它带来什么价值？） 3、明确项目的功能。（这个项目涉及哪些功能？） 4、明确项目的技术。（这个项目用到哪些技术？） 5、明确个人在项目中的位置和作用。（你在这个项目的承担角色？） 6、明确项目的整体架构。 7、明确项目的优缺点,如果重新设计你会如何设计。 8、明确项目的亮点。（这个项目有什么亮点？） 9、明确技术成长。（你通过这个项目有哪些技术成长？） Java基础List 、 Set、Map 的区别List、Set、Map HashSet 是如何保证不重复的List、Set、Map HashMap 是线程安全的吗，为什么不是线程安全的（最好画图说明多线程环境下不安全）?List、Set、Map HashMap 的扩容过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 链表优化重hash的代码块 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; Java 8系列之重新认识HashMapHashMap原理-1.8 HashMap 1.7 与 1.8 的 区别，说明 1.8 做了哪些优化，如何优化的？ 引入了红黑树 扩容hash的优化，利用扩容后的位置的特性。 Java 8系列之重新认识HashMapJava源码分析：HashMap 1.8 相对于1.7 到底更新了什么？HashMap原理-1.8 final finally finalizefinal：用于修饰类、成员变量和成员方法。final修饰的类，不能被继承（String、StringBuilder、StringBuffer、Math，不可变类）；Final修饰的方法不能被重写，但是子类可以用父类中final修饰的方法；Final修饰的成员变量是不可变的，如果成员变量是基本数据类型，初始化之后成员变量的值不能被改变，如果成员变量是引用类型，那么它只能指向初始化时指向的那个对象，不能再指向别的对象，但是对象当中的内容是允许改变的。 finally：用于异常代码块执行完成之后执行，通常用于关闭资源 finalize：object类中的一个方法，Java虚拟机在垃圾回收之前会先调用垃圾对象的finalize方法用于使对象释放资源（如关闭连接、关闭文件），之后才进行垃圾回收，这个方法一般不会显示的调用，在垃圾回收时垃圾回收器会主动调用。并且，虚拟机并不承诺等待它允许结束，是为了避免其中一个执行缓慢，导致整个内存回收系统崩溃。 强引用 、软引用、 弱引用、虚引用 类型 生命周期 用途 强引用 不会被GC … SoftReference 直到内存不足时 缓存 WeakReference 下次GC 缓存（WeakHashMap） PhantomReference 下次GC 堆外内存管理 关于java内存泄露的总结–引用的类型：强引用，弱引用，软引用从面试题中看Java的Reference（引用） Java反射说说 Java 反射机制 深入分析Java方法反射的实现原理 Arrays.sort 实现原理和 Collection 实现原理LinkedHashMap的应用LinkedHashMap 能够做到按照插入顺序或者访问顺序进行迭代，这样在我们以后的开发中遇到相似的问题，才能想到用 LinkedHashMap 来解决，否则就算对其内部结构非常了解，不去使用也是没有什么用的。 List、Set、Map cloneable接口实现原理克隆规则：1、基本类型如果变量是基本类型，则拷贝其值，比如int、float等。2、 对象如果变量是一个实例对象，则拷贝其地址引用，也就是说新对象和原来对象是共用实例变量的。3、 String字符串若变量为String字符串，则拷贝其地址引用。但是在修改时，它会从字符串池中重新生成一个新的字符串，原有的对象保持不变。 使用：Object.java的clone()是一个native方法，当需要克隆时，子类实现Cloneable接口后，重写clone()，调用super.clone()。需要注意涉及到深、浅拷贝。 实现深克隆：1、先对对象进行序列化，紧接着马上反序列化出2、先调用super.clone()方法克隆出一个新对象来，然后在子类的clone()方法中手动给克隆出来的非基本数据类型（引用类型）赋值，比如ArrayList的clone()方法：3、在clone方法里面，递归克隆非基本类型的成员变量 1234567891011121314151617181920212223242526public class Administrator implements Cloneable &#123; private User user; private Boolean editable; public Administrator(User user, Boolean editable) &#123; this.user = user; this.editable = editable; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; Bean bean = (Bean) super.clone(); // 实现深克隆，需要User实现了Cloneable接口 bean.user = (ChildBean) bean.user.clone(); return bean; &#125; @Override public int hashCode() &#123; // 老规矩 &#125; @Override public boolean equals(Object obj) &#123; // 老规矩 &#125; // 老规矩&#125; Java中的clone()和Cloneable接口 Java创建对象的几种方式(1) 用new语句创建对象，这是最常见的创建对象的方法。(2) 运用反射手段,调用java.lang.Class或者java.lang.reflect.Constructor类的newInstance()实例方法。(3) 调用对象的clone()方法。(4) 运用反序列化手段，调用java.io.ObjectInputStream对象的 readObject()方法。 (1)和(2)都会明确的显式的调用构造函数 ；(3)是在内存上对已有对象的影印，所以不会调用构造函数 ；(4)是从文件中还原类的对象，也不会调用构造函数。 异常分类以及处理机制 Error是无法处理的异常，比如OutOfMemoryError，一般发生这种异常，JVM会选择终止程序。因此我们编写程序时不需要关心这类异常。 Exception，也就是我们经常见到的一些异常情况，这些异常是我们可以处理的异常，是所有异常类的父类。 unchecked exception（非受查异常），包括Error和RuntimeException，比如常见的NullPointerException、IndexOutOfBoundsException。对于RuntimeException，java编译器不要求必须进行异常捕获处理或者抛出声明，由程序员自行决定。 checked exception（受查异常），也称非运行时异常（运行时异常以外的异常就是非运行时异常），由代码能力之外的因素导致的运行时错误。java编译器强制程序员必须进行捕获处理，比如常见的有IOExeption和SQLException。如果不进行捕获或者抛出声明处理，编译都不会通过。 典型的RuntimeException包括NullPointerException、IndexOutOfBoundsException、IllegalArgumentException等。 典型的非RuntimeException包括IOException、SQLException等。 wait和sleep的区别wait：调用后，必须被通知才能重新运行，且释放锁资源。 sleep：睡眠一定时间后继续执行，且不释放锁资源。 首先，要记住这个差别，“sleep是Thread类的方法,wait是Object类中定义的方法”。尽管这两个方法都会影响线程的执行行为，但是本质上是有区别的。 Thread.sleep不会导致锁行为的改变，如果当前线程是拥有锁的，那么Thread.sleep不会让线程释放锁。如果能够帮助你记忆的话，可以简单认为和锁相关的方法都定义在Object类中，因此调用Thread.sleep是不会影响锁的相关行为。 Thread.sleep和Object.wait都会暂停当前的线程，对于CPU资源来说，不管是哪种方式暂停的线程，都表示它暂时不再需要CPU的执行时间。OS会将执行时间分配给其它线程。区别是，调用wait后，需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间。 线程的状态参考 Thread.State的定义。新创建的但是没有执行（还没有调用start())的线程处于“就绪”，或者说Thread.State.NEW状态。 Thread.State.BLOCKED（阻塞）表示线程正在获取锁时，因为锁不能获取到而被迫暂停执行下面的指令，一直等到这个锁被别的线程释放。BLOCKED状态下线程，OS调度机制需要决定下一个能够获取锁的线程是哪个，这种情况下，就是产生锁的争用，无论如何这都是很耗时的操作。 数组在内存中如何分配对象在堆上分配连续空间。 Java 并发synchronized 的实现原理以及锁优化？JVM基于进入和退出Monitor对象来实现方法同步和代码同步。使用monitorenter和monitorexit指令实现。 每个对象有一个监视器锁（monitor）； 偏向锁：使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点，没有字节码在执行）。 轻量级锁：轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁； 重量级锁。 volatile 的实现原理？通过lock前缀实现，底层是通过总线锁定和缓存锁定来实现。 Lock前缀指令会引起处理器缓存回写到内存。一个处理器的缓存回写到内存会导致其他处理器的缓存无效。 Java 的信号灯？控制并发线程数量。 通过AQS来实现的。 12345678910111213141516171819202122232425262728293031public class SemaphoreTest &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newCachedThreadPool(); final Semaphore sp = new Semaphore(3); for(int i=0;i&lt;10;i++)&#123; Runnable runnable = new Runnable()&#123; public void run()&#123; try &#123; sp.acquire(); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("线程" + Thread.currentThread().getName() + "进入，当前已有" + (3-sp.availablePermits()) + "个并发"); try &#123; Thread.sleep((long)(Math.random()*10000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("线程" + Thread.currentThread().getName() + "即将离开"); sp.release(); //下面代码有时候执行不准确，因为其没有和上面的代码合成原子单元 System.out.println("线程" + Thread.currentThread().getName() + "已离开，当前已有" + (3-sp.availablePermits()) + "个并发"); &#125; &#125;; service.execute(runnable); &#125; &#125;&#125; synchronized 在静态方法和普通方法的区别？静态方法和实例方法不是同一把锁 怎么实现所有线程在等待某个事件的发生才会去执行？CountDownLatch、CyclicBarrier CAS？CAS 有什么缺陷，如何解决？CompareAndSwap，不用加锁 存在ABA问题，通过添加版本号来区分（AtomicStampedReference）；循环时间开销大； synchronized 和 lock 有什么区别？ lock能够非阻塞获取锁、中断地获取锁、超时获取锁、更加灵活。 悲观锁与乐观锁 synchronized由jvm自动释放，lock需要手动释放 在资源竞争不是很激烈的情况下，Synchronized的性能要优于ReetrantLock，但是在资源竞争很激烈的情况下，Synchronized的性能会下降几十倍，但是ReetrantLock的性能能维持常态； Synchronized与Lock锁的区别 Hashtable 是怎么加锁的 ？synchronized HashMap 的并发问题？死循环导致CPU100%使用 HashMap的死循环 ConcurrenHashMap 介绍？1.8 中为什么要用红黑树？彻底看懂 so called 红黑树红黑树深入剖析及Java实现 AQS抽象队列同步器，AbstractQueueSynchronizer。 模板方法 volatile int 状态变量 CAS 同步队列（FIFO双向队列） 共享、独占获取同步状态 如何检测死锁？怎么预防死锁？检测： cpu使用率低 io使用率低 jstack 预防： 资源使用顺序 增加资源 超时退出资源 Java 内存模型？Java内存模型定义了多线程之间共享变量的可见性以及如何在需要的时候对共享变量进行同步。 Java内存模型定义了volatile和synchronized的行为，更重要的是保证了同步的java程序在所有的处理器架构下面都能正确的运行。 happens-before规则 重排序、内存屏障 如何保证多线程下 i++ 结果正确？synchronized、lock 线程池的种类，区别和使用场景？ newCachedThreadPool：适用于执行很多的短期异步任务的小程序，或者负载比较轻的服务器;是一个根据需要创建线程的线程池 newFixedThreadPool：FixedThreadPool适用于为了满足管理资源的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。 newSingleThreadExecutor：适用于需要保证顺序地执行各个任务，并且在任意时间点不会有多个线程在活动的场景。 newScheduledThreadPool：适用于需要在多个后台线程执行周期任务，同时为了满足资源管理需求需要限制后台线程数量的应用场景。 分析线程池的实现原理和线程的调度过程？worker从队列中不断取任务执行，当任务队列为空时，worker线程阻塞； 线程池如何调优，最大数目如何确认？取决于任务的类型，CPU密集型可以coreNum + 1；IO密集型可以2coreNum； ThreadLocal原理，用的时候需要注意什么？ThreadLocal CountDownLatch 和 CyclicBarrier 的用法，以及相互之间的差别?区别：CyclicBarrier可以重复使用，CountDownLatch只能使用一次。 LockSupport工具LockSupport Condition接口及其实现原理底层依赖LockSupport方法 condition Fork/Join框架的理解需要通过ForkJoinPool来提交任务。任务一般通过使用ForkJoinTask的子类来实现： RecursiveAction：用于没有返回结果的任务 RecursiveTask：用于有返回结果的任务 12ForkJoinPool forkJoinPool = newForkJoinPool();Future result = forkJoinPool.submit(task); 任务的切割: 12345678910111213// 分割任务task.fork();public final ForkJoinTask&lt;V&gt; fork() &#123; Thread t; if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) // ForkJoinPool.WorkQueue workQueue，workQueue是ForkJoinPool的全局变量 // 所有分割出来的任务都在一个queue中 ((ForkJoinWorkerThread)t).workQueue.push(this); else ForkJoinPool.common.externalPush(this); return this; &#125; 分段锁的原理,锁力度减小的思考八种阻塞队列以及各个阻塞队列的特性ArrayBlockingQueue ：由数组结构组成的有界阻塞队列。LinkedBlockingQueue ：由链表结构组成的有界阻塞队列。PriorityBlockingQueue ：支持优先级排序的无界阻塞队列。DelayQueue：使用优先级队列实现的无界阻塞队列。SynchronousQueue：不存储元素的阻塞队列。LinkedTransferQueue：链表结构组成的无界阻塞队列。LinkedBlockingDeque：链表结构组成的双向阻塞队列。 方法/处理方式 抛出异常 返回特殊值 一直阻塞 超时退出 插入 add(e) offer(e) put(e) offer(e, time, unit) 移除 remove() poll () take() poll(time, unit) 检查 element() peek() 不可用 不可用 如果是无界阻塞队列，队列不可能会出现满的情况，所以使用put或offer方法永远不会被阻塞，而且使用offer方法时，该方法永远返回rue。 实现： 通过Lock和Condition实现，插入市判断容量调用LockSupport的await或signal方法 JVM详细jvm内存模型jvm内存模型 讲讲什么情况下回出现内存溢出，内存泄漏？内存溢出：指程序申请内存时,没有足够的内存空间使用 内存泄漏：指程序申请了内存后(new),用完的内存没有释放(delete),一直被某个或某些实例所持有却不再被使用导致 GC 不能回收 https://www.jianshu.com/p/e97ed5d8a403关于java内存泄露的总结–引用的类型：强引用，弱引用，软引用 说说Java线程栈https://blog.csdn.net/hust_superman/article/details/39402087 JVM 年轻代到年老代的晋升过程的判断条件是什么呢？ 大对象直接进入老年代 存活一定时间的年轻代晋升老年代 同一年代的对象在monitor gc后，占用内存大于Survivor的二分之一，晋升老年代 JVM 出现 fullGC 很频繁，怎么去线上排查问题？ ​ 类加载为什么要使用双亲委派模式，有没有什么场景是打破了这个模式？http://www.cnblogs.com/lanxuezaipiao/p/4138511.html 解决基础类的统一问题 打破场景： 线程上下文类加载器（Thread Context Classloader） OSGI 类的实例化顺序https://blog.csdn.net/zd836614437/article/details/64126826 https://segmentfault.com/a/1190000004527951 JVM垃圾回收机制，何时触发MinorGC等操作Minor GC触发条件：当Eden区满时，触发Minor GC。 Full GC触发条件： （1）调用System.gc时，系统建议执行Full GC，但是不必然执行 （2）老年代空间不足 （3）方法区空间不足 （4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存 （5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 JVM 中一次完整的 GC 流程（从 ygc 到 fgc）是怎样的答：对象优先在Eden区中分配，若没有足够空间，Minor GC；大对象（需要大量连续内存空间）直接进入老年态；长期存活的对象进入老年态。如果对象在新生代出生并经过第一次MGC后仍然存活，年龄+1，若年龄超过一定限制（15），则被晋升到老年态。 https://blog.csdn.net/zd836614437/article/details/64126826 各种回收器，各自优缺点，重点CMS、G1 名称 优点 缺点 Serial client机器上、简单而高效 单线程；STW ParNew 多线程 STW Parallel Scavenge 时间可控 Serial Old 单线程；STW Parallel Old CMS 占用用户时间少；并发收集、低停顿 CPU资源非常敏感；无法处理浮动垃圾；空间碎片 G1 无空间碎片；低停顿；并发执行；支持大内存； 是的 CMS收集器和G1收集器优缺点g1 gc 各种回收算法 标记 - 清除 标记 - 整理 复制 分代收集算法 OOM错误，stackoverflow错误，permgen space错误https://my.oschina.net/liting/blog/476918 JVM 之 OopMap 和 RememberedSetOopMap：记录了从栈到堆的引用关系，以避免全栈扫描，加快枚举根节点的速度。它的另外一个更根本的作用是，可以帮助 HotSpot 实现准确式 GC。 RememberSet：记录老年代对象引用新生代对象。 SpringBeanFactory 和 FactoryBean？BeanFactory: BeanFactory，以Factory结尾，表示它是一个工厂类(接口)，用于管理Bean的一个工厂。在Spring中，BeanFactory是IOC容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。 Spring为我们提供了许多易用的BeanFactory实现，XmlBeanFactory就是常用的一个，该实现将以XML方式描述组成应用的对象及对象间的依赖关系。XmlBeanFactory类将持有此XML配置元数据，并用它来构建一个完全可配置的系统或应用。 123456789// No.1Resource resource = new FileSystemResource("beans.xml");BeanFactory factory = new XmlBeanFactory(resource);// No.2ClassPathResource resource = new ClassPathResource("beans.xml");BeanFactory factory = new XmlBeanFactory(resource);// No.3ApplicationContext context = new ClassPathXmlApplicationContext(new String[] &#123;"applicationContext.xml", "applicationContext-part2.xml"&#125;);BeanFactory factory = (BeanFactory) context; FactoryBean: 实现 FactoryBean 的类表明此类也是一个Bean，类型为工厂Bean（Spring中共有两种bean，一种为普通bean，另一种则为工厂bean）。顾名思义，它也是用来管理Bean的，而它本身由spring管理。 FactoryBean管理的bean实际上也是由spring进行配置、实例化、管理，因此由FactoryBean管理的bean不能再次配置到spring配置文件中（xml、java类配置、注解均不可以），否则会报异常。 Spring IOC 的理解，其初始化过程？12ApplicationContext appContext = new ClassPathXmlApplicationContext("cjj/models/beans.xml");Person p = (Person)appContext.getBean("person"); 上面代码中，在创建ApplicationContext实例对象过程中会创建一个spring容器，该容器会读取配置文件”cjj/models/beans.xml”,并统一管理由该文件中定义好的所有bean实例对象，如果要获取某个bean实例，使用getBean方法就行了。例如我们只需要将Person提前配置在beans.xml文件中（可以理解为注入），之后我们可以不需使用new Person()的方式创建实例，而是通过容器来获取Person实例，这就相当于将Person的控制权交由spring容器了，差不多这就是控制反转的概念。 Spring中有两个主要的容器系列： 实现BeanFactory接口的简单容器； 实现ApplicationContext接口的高级容器。ApplicationContext比较复杂，它不但继承了BeanFactory的大部分属性，还继承其它可扩展接口，扩展的了许多高级的属性。 初始化过程： Resource定位（Bean的定义文件定位） 将Resource定位好的资源载入到BeanDefinition 将BeanDefiniton注册到容器中 容器初始化的时候会预先对单例和非延迟加载的对象进行预先初始化。其他的都是延迟加载是在第一次调用getBean 的时候被创建。 第一步 Resource定位可以通过先获取resource，再获取beanFactory 12Resource resource = new FileSystemResource("beans.xml");BeanFactory factory = new XmlBeanFactory(resource); FileSystemResource：以文件的绝对路径方式进行访问资源，效果类似于Java中的File; ClassPathResourcee：以类路径的方式访问资源，效果类似于this.getClass().getResource(“/“).getPath(); ServletContextResource：web应用根目录的方式访问资源，效果类似于request.getServletContext().getRealPath(“”); UrlResource：访问网络资源的实现类。例如file: http: ftp:等前缀的资源对象; ByteArrayResource: 访问字节数组资源的实现类。 也可以直接创建applicationContext对象： 12345678910111213public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; //super方法为容器设置好Bean资源加载器 //该方法最终会调用到AbstractApplicationContext的无参构造方法 //这里会默认设置解析路径的模式为Ant-style super(parent); //设置Bean定义资源文件的路径 setConfigLocations(configLocations); if (refresh) &#123; //调用容器的refresh，载入BeanDefinition的入口 refresh(); &#125;&#125; 注：ApplicationContext的所有实现类都实现RecourceLoader接口，因此可以直接调用getResource（参数）获取Resoure对象。不同的ApplicatonContext实现类使用getResource方法取得的资源类型不同，例如：FileSystemXmlApplicationContext.getResource获取的就是FileSystemResource实例；ClassPathXmlApplicationContext.gerResource获取的就是ClassPathResource实例；XmlWebApplicationContext.getResource获取的就是ServletContextResource实例，另外像不需要通过xml直接使用注解@Configuation方式加载资源的AnnotationConfigApplicationContext等等。 第二步 通过返回的resource对象，进行BeanDefinition的载入总之，BeanDefinition相当于一个数据结构，这个数据结构的生成过程是根据定位的resource资源对象中的bean而来的，这些bean在Spirng IoC容器内部表示成了的BeanDefintion这样的数据结构，IoC容器对bean的管理和依赖注入的实现都是通过操作BeanDefinition来进行的。 1.构造BeanFactory时，首先调用的是BeanDefinitionReader类型的reader属性的loadBeanDefinitions()方法，是整个资源加载的切入点。 封装资源文件：当进入BeanDefinitionReader后首先对参数Resource进行EncodedResource类进行封装 获取输入流：从Resource中获取InputStream并构造InputSource 通过构造器的InputSource实例和Resource实例继续调用loadBeanDefinitions. 2.loadBeanDefinition调用doLoadBeanDefinitons方法，完成以下三个方法 对XML文档的验证模式 用DocumentLoader处理资源文件，生成Document 根据返回的Document信息注册bean信息 第三步，将BeanDefiniton注册到容器中最终Bean配置会被解析成BeanDefinition并与beanName,Alias一同封装到BeanDefinitionHolder中,之后beanFactory.registerBeanDefinition(beanName, bdHolder.getBeanDefinition())，注册到DefaultListableBeanFactory.beanDefinitionMap中。之后客户端如果要获取Bean对象，Spring容器会根据注册的BeanDefinition信息进行实例化。 参考1 参考2 BeanFactory 和 ApplicationContext？ApplicationContext继承BeanFactory，添加了一些属性和方法。 Spring Bean 的生命周期，如何被管理的？https://www.jianshu.com/p/3944792a5fff Spring Bean 的加载过程是怎样的？https://segmentfault.com/a/1190000012887776 http://www.cnblogs.com/xrq730/p/6285358.html 如果要你实现Spring AOP，请问怎么实现？如果要你实现Spring IOC，你会注意哪些问题？Spring 是如何管理事务的，事务管理机制？ 编程式事务管理 TransactionDefinition PlatformTransactionManager TransactionStatus 声明式事务管理(AOP和IOC) DataSource TransactionManager https://blog.csdn.net/justloveyou_/article/details/73733278 Spring 的不同事务传播行为有哪些，干什么用的？浅析Spring事务传播行为 Spring中事务的隔离级别[MySQL事务隔离级别和Spring事务关系介绍 Spring 中用到了那些设计模式？https://www.cnblogs.com/yuefan/p/3763898.html http://www.uml.org.cn/j2ee/201301074.asp 设计模式之创建型模式 Spring MVC 的工作原理？SpringMVC工作原理 Spring 循环注入的原理？Spring AOP的理解，各个术语，他们是怎么相互工作的？Spring 如何保证 Controller 并发的安全？https://blog.csdn.net/hejingyuan6/article/details/50363647 http://www.cnblogs.com/duanxz/p/5051916.html NettyBIO、NIO和AIONetty 的各大组件【死磕Netty】—–Netty的核心组件 Netty的线程模型Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(一)Netty概述 TCP 粘包/拆包的原因及解决方法TCP粘包，拆包及解决方法Netty概述 了解哪几种序列化协议？包括使用场景和如何去选择影响序列化性能的关键因素：1、序列化后的码流大小（网络带宽的占用）；2、序列化的性能（CPU资源占用）；3、是否支持跨语言（异构系统的对接和开发语言切换）。 1、json2、xml3、Protobuf4、Avro5、Thrift Netty概述 Netty的零拷贝实现Netty的零拷贝体现在三个方面： Netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才写入Socket中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。 Netty提供了组合Buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个Buffer那样方便的对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。 Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。 netty相关概念 Netty的高性能表现在哪些方面1、并发高nio、reactor模型2、传输快zero copy3、封装好api简单 Netty入门教程——认识Netty 分布式相关Dubbo的底层实现原理和机制描述一个服务从发布到被消费的详细过程分布式系统怎么做服务治理接口的幂等性的概念消息中间件如何解决消息丢失问题Dubbo的服务请求失败怎么处理重连机制会不会造成错误对分布式事务的理解如何实现负载均衡，有哪些算法可以实现？Zookeeper的用途，选举的原理是什么？数据的垂直拆分水平拆分。zookeeper原理和适用场景zookeeper watch机制redis/zk节点宕机如何处理分布式集群下如何做到唯一序列号如何做一个分布式锁用过哪些MQ，怎么用的，和其他mq比较有什么优缺点，MQ的连接是线程安全的吗MQ系统的数据如何保证不丢失列举出你能想到的数据库分库分表策略；分库分表后，如何解决全表查询的问题zookeeper的选举策略全局ID数据库mysql分页有什么优化https://blog.csdn.net/bingduanlbd/article/details/51767850 https://my.oschina.net/No5stranger/blog/158202 悲观锁、乐观锁悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。 MySQL 乐观锁与悲观锁 深入理解乐观锁与悲观锁 组合索引，最左原则mysql索引及查询优化 mysql 的表锁、行锁mysql 性能优化1、建索引2、查询优化3、数据类型（比如用ENUM代替VARCHAR等） mysql索引及查询优化 mysql的索引分类：B+，hash；什么情况用什么索引MySQL索引背后的数据结构及算法原理 事务的特性和隔离级别 原子性 一致性 持久性 隔离性 Serializable（串行化）：可避免脏读、不可重复读、幻读的发生。（级别最高） Repeatable-read（可重复读）：可避免脏读、不可重复读的发生。 Read-committed（读已提交）：可避免脏读的发生。 Read-uncommitted（读未提交）：最低级别，任何情况都无法保证。（级别最低） https://blog.csdn.net/lamp_yang_3533/article/details/79344736 http://blog.sina.com.cn/s/blog_8020e4110101bfc6.html RedisRedis用过哪些数据数据，以及Redis底层怎么实现Redis缓存穿透，缓存雪崩redis缓存 如何使用Redis来实现分布式锁 setNX、getSET、get redlock Redis的并发竞争问题如何解决Redis的并发通过队列模式，编程串行模式执行 客户端实现： synchronized redis服务端实现： setNX锁 watch + 事务 Redis持久化的几种方式，优缺点是什么，怎么实现的持久化 Redis的缓存失效策略Redis集群，高可用，原理Redis缓存分片Redis分区实现原理 Redis的数据淘汰策略Redis数据淘汰机制 原文 原文]]></content>
  </entry>
  <entry>
    <title><![CDATA[List、Set、Map]]></title>
    <url>%2Fjava%2Fdatastructure%2FListSetMap%2F</url>
    <content type="text"><![CDATA[List，Set都是继承自Collection接口 List 元素有放入顺序； 元素可重复； 可以插入多个null元素 ； 常用的实现类有 ArrayList、LinkedList 和 Vector。ArrayList 最为流行，它提供了使用索引的随意访问，而 LinkedList 则对于经常需要从 List 中添加或删除元素的场合更为合适。 Set 元素无放入顺序（注意：元素虽然无放入顺序，但是元素在set中的位置是有该元素的HashCode决定的，其位置其实是固定的） 元素不可重复 只允许一个 null 元素； TreeSet通过 Comparator 或者 Comparable 维护了一个排序顺序 ； Set 接口最流行的几个实现类是 HashSet、LinkedHashSet 以及 TreeSet。最流行的是基于 HashMap 实现的 HashSet；TreeSet 还实现了 SortedSet 接口，因此 TreeSet 是一个根据其 compare() 和 compareTo() 的定义进行排序的有序容器。 HashSet通过HashMap实现123public HashSet() &#123; map = new HashMap&lt;&gt;();&#125; LinkedHashSet通过LinkedHashMap实现123public LinkedHashSet() &#123; super(16, .75f, true);&#125; 123HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; TreeSet基于TreeMap实现，构造函数中调用TreeMap的构造函数123456789101112131415161718192021TreeSet(NavigableMap&lt;E,Object&gt; m) &#123; this.m = m; &#125; public TreeSet() &#123; // 无参数构造函数 this(new TreeMap&lt;E,Object&gt;()); &#125; public TreeSet(Comparator&lt;? super E&gt; comparator) &#123; // 包含比较器的构造函数 this(new TreeMap&lt;&gt;(comparator)); &#125; public TreeSet(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); &#125; public TreeSet(SortedSet&lt;E&gt; s) &#123; this(s.comparator()); addAll(s); &#125; Map 不是collection的子接口或者实现类，Map是一个接口； TreeMap 也通过 Comparator 或者 Comparable 维护了一个排序顺序。 Map 里你可以拥有随意个 null 值但最多只能有一个 null 键 Map 接口最流行的几个实现类是 HashMap、LinkedHashMap、Hashtable 和 TreeMap。（HashMap、TreeMap最常用） HashMap1.8的变化 引入了红黑树 扩容hash的优化，利用扩容后的位置的特性。 Java 8系列之重新认识HashMapJava源码分析：HashMap 1.8 相对于1.7 到底更新了什么？HashMap原理-1.8 put12345678910111213141516171819202122232425262728293031323334353637383940414243444546final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) // table为null时，初始化 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) // 表示没有i位置上没有节点，new一个节点 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 找到目标节点 e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key // 找到目标节点并替换原来的值 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e);// 调用子类实现的方法 return oldValue; &#125; &#125; ++modCount;// 标识修改HashMap的次数 if (++size &gt; threshold) resize();// 扩容 afterNodeInsertion(evict);// 调用子类实现的方法 return null;&#125; getget实际上是调用getNode方法：12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode)// 从红黑树上取 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123;// 在链表中取 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 扩容过程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 链表优化重hash的代码块 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;`` Java 8系列之重新认识HashMapHashMap原理-1.8 死锁HashMap的死循环 LinkedHashMapLinkedHashMap 能够做到按照插入顺序或者访问顺序进行迭代，这样在我们以后的开发中遇到相似的问题，才能想到用 LinkedHashMap 来解决，否则就算对其内部结构非常了解，不去使用也是没有什么用的。 put123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; newNode实际上调用的是子类重写的方法123456789101112131415161718Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); linkNodeLast(p); return p;&#125;// 新节点放入末尾，并且是双向的private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125;&#125; afterNodeAccess 和 afterNodeInsertion 也是子类重写的方法1234567891011121314151617181920212223242526272829303132void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // 当accessOrder为true时，move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125;&#125;void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125; foreach遍历时，是通过前后的指针来取出来的，所以是有序的12345678910public void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; if (action == null) throw new NullPointerException(); int mc = modCount; // 根据指针的关系 for (LinkedHashMap.Entry&lt;K,V&gt; e = head; e != null; e = e.after) action.accept(e.key, e.value); if (modCount != mc) throw new ConcurrentModificationException();&#125; TreeMaphttp://shmilyaw-hotmail-com.iteye.com/blog/1836431https://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html彻底看懂 so called 红黑树 使用场景 如果你经常会使用索引来对容器中的元素进行访问，那么 List 是你的正确的选择。如果你已经知道索引了的话，那么 List 的实现类比如 ArrayList 可以提供更快速的访问,如果经常添加删除元素的，那么肯定要选择LinkedList。 如果你想容器中的元素能够按照它们插入的次序进行有序存储，那么还是 List，因为 List 是一个有序容器，它按照插入顺序进行存储。 如果你想保证插入元素的唯一性，也就是你不想有重复值的出现，那么可以选择一个 Set 的实现类，比如 HashSet、LinkedHashSet 或者 TreeSet。所有 Set 的实现类都遵循了统一约束比如唯一性，而且还提供了额外的特性比如 TreeSet 还是一个 SortedSet，所有存储于 TreeSet 中的元素可以使用 Java 里的 Comparator 或者 Comparable 进行排序。LinkedHashSet 也按照元素的插入顺序对它们进行存储。 如果你以键和值的形式进行数据存储那么 Map 是你正确的选择。你可以根据你的后续需要从 Hashtable、HashMap、TreeMap 中进行选择。 注：以上源码基于jdk1.8]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm太慢， 淘宝npm镜像使用方法]]></title>
    <url>%2Fnpm%2F</url>
    <content type="text"><![CDATA[临时使用1npm --registry https://registry.npm.taobao.org install express 持久使用1npm config set registry https://registry.npm.taobao.org 配置后可通过下面方式来验证是否成功 npm config get registry npm info express 通过cnpm使用1npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm install express 原文]]></content>
      <categories>
        <category>nodejs</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap]]></title>
    <url>%2Fjava%2Fdatastructure%2FConcurrentHashMap%2F</url>
    <content type="text"><![CDATA[putgetresize]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最佳实践]]></title>
    <url>%2F%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[1234// 不允许调用方法public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; 123// 空指针校验if (key == null) throw new NullPointerException();]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[算法]]></title>
    <url>%2F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序Timsort原理介绍Timsort排序算法]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[收纳]]></title>
    <url>%2F%E6%94%B6%E7%BA%B3%2F</url>
    <content type="text"><![CDATA[不换大衣橱，简单3步解决衣物收纳难题（附叠衣服技巧图） 衣柜如何收纳，能更简洁而且不容易乱？]]></content>
  </entry>
  <entry>
    <title><![CDATA[索引]]></title>
    <url>%2Fmysql%2F%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[简单介绍一下MYSQL的索引分类，并给出几个常见问题，大家自己去探索加深理解，权当抛砖引玉了。 从数据结构角度1、B+树索引2、hash索引3、FULLTEXT索引（InnoDB引擎5.7以后支持）4、R-Tree索引（用于对GIS数据类型创建SPATIAL索引）问题：这些索引的区别跟用途在哪？B+树相比hash的优点在哪？ 从物理存储角度1、聚簇索引（clustered index）2、非聚簇索引（non-clustered index）问题：实现方式有什么差异？ 从逻辑角度1、主键索引2、单列索引3、多列索引4、唯一索引问题：多列索引有什么命中规则？这几种索引对加锁有什么影响？ https://blog.csdn.net/wuxing26jiayou/article/details/76596174]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>index</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql合集]]></title>
    <url>%2Fmysql%2Fmysql%E5%90%88%E9%9B%86%2F</url>
    <content type="text"><![CDATA[limit优化Mysql优化实践（分页优化） 事务MySQL事务隔离级别和Spring事务关系介绍 锁和索引MySQL 加锁处理分析Innodb 中 RR 隔离级别能否防止幻读？MySQL的InnoDB的幻读问题Clustered and Secondary IndexesSQL中的where条件，在数据库中提取与应用浅析 MySQL学习之——锁(行锁、表锁、页锁、乐观锁、悲观锁等) MySQL 索引及查询优化总结 MySQL索引背后的数据结构及算法原理 干货：mysql索引的数据结构 InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。 这里还可能存在另外一个问题，虽然我们对method_name 使用了唯一索引，并且显示使用for update来使用行级锁。但是，MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。 mysql分布式锁]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2Fdesign-pattern%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[创建新模式简单工厂首先将需要创建的各种不同对象（例如各种不同的 Chart 对象）的相关代码封装到不同的类中，这些类称为具体产品类，而将它们公共的代码进行抽象和提取后封装在一个抽象产品类中，每一个具体产品类都是抽象产品类的子类；然后提供一个工厂类用于创建各种产品，在工厂类中提供一个创建产品的工厂方法，该方法可以根据所传入的参数不同创建不同的具体产品对象；客户端只需调用工厂类的工厂方法并传入相应的参数即可得到一个产品对象。]]></content>
  </entry>
  <entry>
    <title><![CDATA[如果看得懂，本篇价值100万]]></title>
    <url>%2Finvest%2F%E9%A3%98%E4%BB%99%2F%E5%A6%82%E6%9E%9C%E7%9C%8B%E5%BE%97%E6%87%82%EF%BC%8C%E6%9C%AC%E7%AF%87%E4%BB%B7%E5%80%BC100%E4%B8%87%2F</url>
    <content type="text"><![CDATA[大周期择时模式依赖于大级别波动，如果没有大波动或者周期太久，就没有大收益。 价投模式依赖于深研，如果没有深研，就容易踩坑或者卖飞。 烟蒂模式依赖于风险偏好不断修正，如果资金越涨越抱团，抄底就很快就没子弹了。 做热点打板模式依赖于傻子多，如果没有傻子，就没人搏傻。 做趋势依赖于主线判断，如果判断错误，就容易两边打脸。 做套利依赖于没人发现套利空间，如果没有套利空间，就没有办法获利。 飘仙尽量不根据大周期对仓位进行显著调节，对企业不深研，不完全捡烟蒂，不参与热门股炒作，不过分判断主线，不专门研究套利，去除以上干扰因子，打造“去依赖”的投资体系，致力于做到吹吹牛、装装逼就把钱挣了。 如果看得懂，本篇价值100万]]></content>
      <categories>
        <category>invest</category>
      </categories>
      <tags>
        <tag>飘仙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[去年下半年以来的两极分化，是A股估值体系的第三次革命性变化]]></title>
    <url>%2Finvest%2F%E9%A3%98%E4%BB%99%2F%E6%8A%95%E8%B5%84%E4%B8%89%E4%B8%A4%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[2016年下半年以来的两极分化，陆续有多种逻辑作为解释，从国家队逻辑、到大消费逻辑、大周期逻辑、白马逻辑，一个个刚好蒙对的逻辑逐渐不适用，真正的主线逻辑终于越来越清晰了。 说白了，去年下半年以来的两极分化，是A股估值体系的第三次革命性变化——暨给予行业龙头竞争性溢价。 历史上，估值体系的革命性变化都伴随着投资者结构的变化。 最早A股是纯散户市，全民看K线时代，完全没有估值体系可言，只有庄家和跟庄，越垃圾的股涨的越多，越好的股反而没人碰。 到了2005年之后，公募基金获得了巨大发展，估值体系出现了第一次革命性变化，也就是开始看业绩了。公募基金的风格是厌恶风险、分散投资、不断填补估值洼地，虽然市场整体仍然呈现齐涨齐跌现象，但是价值投资理念成为一股清流，价值股逐渐出现涨能跟住，跌能顶住的现象。 2010年之后，独立的职业投资人和私募基金数量剧增，他们的风险偏好比公募基金凶悍很多，往往喜欢抱团取暖，恰逢上市公司市值管理风气日盛，外延式收购蛇吞象实现跨越式发展的上市公司层出不穷，所以，此时估值体系出现了第二次革命性变化，也就是给予小盘股成长性溢价。 2016年之后，国际投资者通过港股通持续入场，恰逢全球牛市的大环境，国际投资者持续不断的买入大市值的行业龙头，大市值股票持续不断的挣钱效应终于摘掉了国内投资者的有色眼镜，国内投资者纷纷发现，大市值的行业龙头们业绩增速丝毫不比中小公司慢，甚至竞争力在自我强化，在各自行业逐渐形成寡头垄断，因此估值体系终于出现了第三次革命性变化，也就是给予行业龙头竞争性溢价。 直至当前，行业龙头的竞争性溢价终于得到了全市场的认可，新的投资理念将逐渐成为未来相当长一段时间的指导思想。 现在的问题是，各行业的龙头都高高在上，一旦出现了新行业龙头被证实，市场就会像狼群一样扑过去，例如京东方。所以，以后择股怎么择，就点到为止了。]]></content>
      <categories>
        <category>invest</category>
      </categories>
      <tags>
        <tag>飘仙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm内存模型]]></title>
    <url>%2Fjava%2Fjvm%2Fjvm%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[内存模型 （1）线程私有区： 程序计数器，记录正在执行的虚拟机字节码的地址； 虚拟机栈：方法执行的内存区，每个方法执行时会在虚拟机栈中创建栈帧； 本地方法栈：虚拟机的Native方法执行的内存区； （2）线程共享区： Java堆：对象分配内存的区域； 方法区：存放类信息、常量、静态变量、编译器编译后的代码等数据； 常量池：存放编译器生成的各种字面量和符号引用，是方法区的一部分。 详细模型 程序计数器PC程序计数器PC，当前线程所执行的字节码行号指示器。每个线程都有自己计数器，是私有内存空间，该区域是整个内存中较小的一块。 当线程正在执行一个Java方法时，PC计数器记录的是正在执行的虚拟机字节码的地址；当线程正在执行的一个Native方法时，PC计数器则为空（Undefined）。 虚拟机栈虚拟机栈，生命周期与线程相同，是Java方法执行的内存模型。每个方法(不包含native方法)执行的同时都会创建一个栈帧结构，方法执行过程，对应着虚拟机栈的入栈到出栈的过程。 栈帧(Stack Frame)结构 栈帧是用于支持虚拟机进行方法执行的数据结构，是属性运行时数据区的虚拟机站的栈元素。见上图， 栈帧包括： 局部变量表 (locals大小，编译期确定)，一组变量存储空间， 容量以slot为最小单位。 操作栈(stack大小，编译期确定)，操作栈元素的数据类型必须与字节码指令序列严格匹配 动态连接， 指向运行时常量池中该栈帧所属方法的引用，为了 动态连接使用。 前面的解析过程其实是静态解析； 对于运行期转化为直接引用，称为动态解析。 方法返回地址 正常退出，执行引擎遇到方法返回的字节码，将返回值传递给调用者 异常退出，遇到Exception,并且方法未捕捉异常，那么不会有任何返回值。 额外附加信息，虚拟机规范没有明确规定，由具体虚拟机实现。 因此，一个栈帧的大小不会受到 异常(Exception) Java虚拟机规范规定该区域有两种异常： StackOverFlowError：当线程请求栈深度超出虚拟机栈所允许的深度时抛出 OutOfMemoryError：当Java虚拟机动态扩展到无法申请足够内存时抛出 123456789101112131415161718192021222324// 栈溢出测试源码package com.paddx.test.memory;/** * Created by root on 2/28/17. */public class StackErrorMock &#123; private static int index = 1; public void call() &#123; index++; call(); &#125; public static void main(String[] args) &#123; StackErrorMock mock = new StackErrorMock(); try &#123; mock.call(); &#125; catch(Throwable e) &#123; System.out.println("Stack deep: " + index); e.printStackTrace(); &#125; &#125;&#125; 运行三次，可以看出每次栈的深度都是不一样的，输出结果如下： 本地方法栈本地方法栈则为虚拟机使用到的Native方法提供内存空间，而前面讲的虚拟机栈式为Java方法提供内存空间。有些虚拟机的实现直接把本地方法栈和虚拟机栈合二为一，比如非常典型的Sun HotSpot虚拟机。 异常(Exception)：Java虚拟机规范规定该区域可抛出StackOverFlowError和OutOfMemoryError。 Java堆Java堆，是Java虚拟机管理的最大的一块内存，也是GC的主战场，里面存放的是几乎所有的对象实例和数组数据。JIT编译器有栈上分配、标量替换等优化技术的实现导致部分对象实例数据不存在Java堆，而是栈内存。 从内存回收角度，Java堆被分为新生代和老年代；这样划分的好处是为了更快的回收内存； 从内存分配角度，Java堆可以划分出线程私有的分配缓冲区(Thread Local Allocation Buffer,TLAB)；这样划分的好处是为了更快的分配内存； 对象创建的过程是在堆上分配着实例对象，那么对象实例的具体结构如下： 对于填充数据不是一定存在的，仅仅是为了字节对齐。HotSpot VM的自动内存管理要求对象起始地址必须是8字节的整数倍。对象头本身是8的倍数，当对象的实例数据不是8的倍数，便需要填充数据来保证8字节的对齐。该功能类似于高速缓存行的对齐。 另外，关于在堆上内存分配是并发进行的，虚拟机采用CAS加失败重试保证原子操作，或者是采用每个线程预先分配TLAB内存. 异常(Exception)：Java虚拟机规范规定该区域可抛出OutOfMemoryError。 下面我们简单的模拟一个堆内存溢出的情况： 12345678910111213141516171819202122232425package com.paddx.test.memory;import java.util.ArrayList;import java.util.List;/** * Created by root on 2/28/17. */public class HeapOomMock &#123; public static void main(String[] args) &#123; List&lt;byte[]&gt; list = new ArrayList&lt;byte[]&gt;(); int i = 0; boolean flag = true; while(flag) &#123; try &#123; i++; list.add(new byte[1024 * 1024]); // 每次增加1M大小的数组对象 &#125;catch(Throwable e) &#123; e.printStackTrace(); flag = false; System.out.println("Count = " + i); // 记录运行的次数 &#125; &#125; &#125;&#125; 首先配置运行时虚拟机的启动参数： 然后运行代码，输出结果如下： 注意，这里我们指定了堆内存的大小为16M，所以这个地方显示的Count=13(这个数字不是固定的)，至于为什么会是13或其他数字，需要根据GC日志来判断。 方法区方法区主要存放的是已被虚拟机加载的类信息、常量、静态变量、编译器编译后的代码等数据。GC在该区域出现的比较少。 异常(Exception)：Java虚拟机规范规定该区域可抛出OutOfMemoryError。 运行时常量池运行时常量池也是方法区的一部分，用于存放编译器生成的各种字面量和符号引用。运行时常量池除了编译期产生的Class文件的常量池，还可以在运行期间，将新的常量加入常量池，比较常见的是String类的intern()方法。 字面量：与Java语言层面的常量概念相近，包含文本字符串、声明为final的常量值等。 符号引用：编译语言层面的概念，包括以下3类： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 但是该区域不会抛出OutOfMemoryError异常。 jdk 1.8中的改进PermGen永久代绝大部分Java程序员应该都见过“java.lang.OutOfMemoryError: PremGen space”异常。这里的“PermGen space”其实指的就是方法区。不过方法区和“PermGen space”又有着本质的区别。前者是JVM的规范，而后者则是JVM规范的一种实现，并且只有HotSpot才有“PermGen space”，而对于其他类型的虚拟机，如JRockit(Oracle)、J9(IBM)并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。最典型的场景就是，在JSP页面比较多的情况，容易出现永久代内存溢出。我们现在通过动态生成类来模拟“PermGen space”的内存溢出： 12345678910111213141516171819202122232425package com.paddx.test.memory;import java.io.File;import java.net.URL;import java.net.URLClassLoader;import java.util.ArrayList;import java.util.List;public class PermGenOomMock &#123; public static void main(String[] args) &#123; URL url = null; List&lt;ClassLoader&gt; classLoaderList = new ArrayList&lt;ClassLoader&gt;(); try &#123; url = new File("/tmp").toURI().toURL(); URL[] urls = &#123;url&#125;; while(true) &#123; ClassLoader loader = new URLClassLoader(urls); classLoaderList.add(loader); loader.loadClass("com.paddx.test.memory.Test"); &#125; &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 123package com.paddx.test.memory; public class Test &#123;&#125; 运行结果如下： 本例中使用的JDK版本是1.7，指定的PermGen区的大小为8M。通过每次生成不同URLClassLoader对象加载Test类，从而生成不同的类对象，这样就能看到我们熟悉的“java.lang.OutOfMemoryError: PermGen space”异常了。这里之所以采用JDK 1.7，是因为在JDK 1.8中，HotSpot已经没有“PermGen space”这个区间了，取而代之是一个叫做Metaspace(元空间)的东西。下面我们就来看看Metaspace与PermGen space的区别。 Metaspace(元空间)其实，移除永久代的工作从JDK 1.7就开始了。JDK 1.7中，存储在永久代的部分数据就已经转移到Java Heap或者Native Heap。但永久代仍存在于JDK 1.7中，并没有完全移除，譬如符号引用(Symbols)转移到了native heap；字面量(interned strings)转移到了Java heap；类的静态变量(class statics)转移到了Java heap。我们可以通过一段程序来比较JDK 1.6、JDK 1.7与JDK 1.8的区别，以字符串常量为例： 12345678910111213141516package com.paddx.test.memory;import java.util.ArrayList;import java.util.List;public class StringOomMock &#123; static String base = "string"; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; String str = base + base; base = str; list.add(str.intern()); &#125; &#125;&#125; 这段程序以2的指数级不断的生成新的字符串，这样可以比较快速的消耗内存。我们通过JDK 1.6、JDK 1.7和JDK 1.8分别运行： JDK 1.6的运行结果： JDK 1.7的运行结果： JDK 1.8的运行结果： 从上述结果可以看出，JDK 1.6下，会出现“PermGen space”的内存溢出，而在JDK 1.7和JDK 1.8中，会出现堆内存溢出，并且JDK 1.8中参数PermSize和MaxPermSize已经失效。因此，可以大致验证JDK 1.7和JDK 1.8中将字符串常量由永久代转移到堆中，并且JDK 1.8中已经不存在永久代的结论。现在我们来看一看元空间到底是一个什么东西？ JDK1.8对JVM架构的改造将类元数据放到本地内存中，另外，将常量池和静态变量放到Java堆里。HotSpot VM将会为类的元数据明确分配和释放本地内存。在这种架构下，类元信息就突破了原来-XX:MaxPermSize的限制，现在可以使用更多的本地内存。这样就从一定程度上解决了原来在运行时生成大量类造成经常Full GC问题，如运行时使用反射、代理等。所以升级以后Java堆空间可能会增加。 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间的最大区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但可以通过以下参数指定元空间的大小： -XX:MetaspaceSize，初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对改值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值。 -XX:MaxMetaspaceSize，最大空间，默认是没有限制的。 除了上面的两个指定大小的选项外，还有两个与GC相关的属性： -XX:MinMetaspaceFreeRatio，在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集。 -XX:MaxMetaspaceFreeRatio，在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集。 现在我们在JDK 1.8重新运行一下上面第二部分(PermGen(永久代))的代码，不过这次不再指定PermSize和MaxPermSize。而是制定MetaspaceSize和MaxMetaspaceSize的大小。输出结果如下： 从输出结果，我们可以看出，这次不再出现永久代溢出，而是出现元空间的溢出。 对象分配规则 对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。 大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。 长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，直到达到阀值对象进入老年区。 动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。 空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。 如何通过参数来控制个各个内存区域参考此文章：JVM（2）：JVM内存结构 参考 http://gityuan.com/2016/01/09/java-memory/ http://blog.csdn.net/universe_ant/article/details/58585854 Java —— 运行时栈帧结构]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC]]></title>
    <url>%2Fjava%2Fjvm%2FGC%2F</url>
    <content type="text"><![CDATA[Minor GC触发条件：当Eden区满时，触发Minor GC。 Full GC触发条件： （1）调用System.gc时，系统建议执行Full GC，但是不必然执行 （2）老年代空间不足 （3）方法区空间不足 （4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存 （5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 Jvm怎么判断对象可以回收了 对象没有引用 作用域发生未捕获异常 程序在作用域正常执行完毕 程序执行了System.exit() 程序发生意外终止（被杀进程等） gc算法 计数器算法 难以解决对象之间循环引用的问题 可达性分析算法在Java语言中，GC Roots包括： 虚拟机栈中引用的对象（本地变量表） 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中引用的对象（Native对象） 可达性算法中不可到达的对象需要经历2次标记过程： 1、第一次标记并进行一次筛选。 筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize方法，或者finzlize方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”，对象被回收。 需要执行finalize方法的对象呗放到F-Queue中 2、第二次标记 在GC前执行F-Queue中的finalize方法，如果还是不可到达，则再次标记，之后会被收集。 方法区（Hotspot中的永久代）的回收条件非常苛刻，只有同时满足以下三个条件才会被回收！ 所有实例被回收 加载该类的ClassLoader被回收 Class对象无法通过任何途径访问(包括反射) 即使满足了上面3个条件，也不一定必然回收。HotSpot提供参数来控制对类的回收。 在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 垃圾收集算法1、标记-清除算法 标记-清除算法采用从根集合进行扫描，对存活的对象对象标记，标记完毕后，再扫描整个空间中未被标记的对象，进行回收，如上图所示。 标记-清除算法不需要进行对象的移动，并且仅对不存活的对象进行处理，在存活对象比较多的情况下极为高效，但由于标记-清除算法直接回收不存活的对象，因此会造成内存碎片！ 2、复制算法 复制算法采用从根集合扫描，并将存活对象复制到一块新的，没有使用过的空间中，这种算法当控件存活的对象比较少时，极为高效，但是带来的成本是需要一块内存交换空间用于进行对象的移动。也就是我们前面提到的s0 s1等空间。 当回首时，将Eden和Survivor中还存活的对象一次性复制到另一块Survivor空间中，最后清理Eden和Survivor。HotSpot默认Eden和Survivor的大小比为8 : 1。当Survivor空间不足，需要老年代进行担保。 3、标记-整理算法 整理算法采用标记-清除算法一样的方式进行对象的标记，但在清除时不同，在回收不存活的对象占用的空间后，会将所有的存活对象往左端空闲空间移动，并更新对应的指针。标记-整理算法是在标记-清除算法的基础上，又进行了对象的移动，因此成本更高，但是却解决了内存碎片的问题。 我们知道，JVM为了优化内存的回收，进行了分代回收的方式，对于新生代内存的回收（minor GC）主要采用复制算法，对于老年代的回首采用“标记-清理”或“标记-整理”算法。下图展示了minor GC的执行过程。 安全点详解 垃圾收集器 新生代 老年代 Serial Serial Old Serial CMS ParNew Serial Old ParNew CMS Parralell Scavenge Serial Old Parralell Scavenge Parralell Old Serial收集器 串行收集器是一个单线程收集器，当JVM需要进行垃圾回收的时候，需要中断所有的用户线程，知道它回收结束为止，因此又号称“Stop The World” 的垃圾回收器。注意，JVM中文名称为java虚拟机，因此它就像一台虚拟的电脑一样在工作，而其中的每一个线程就被认为是JVM的一个处理器，因此大家看到图中的CPU0、CPU1实际为用户的线程，而不是真正机器的CPU，大家不要误解哦。 串行回收方式适合低端机器，是Client模式下的默认收集器，对CPU和内存的消耗不高，适合用户交互比较少，后台任务较多的系统。 Serial收集器默认新旧生代的回收器搭配为Serial+SerialOld ParNew收集器ParNew收集器其实就是多线程版本的Serial收集器，其运行示意图如下 同样有Stop The World的问题，他是多CPU模式下的首选回收器（该回收器在单CPU的环境下回收效率远远低于Serial收集器，所以一定要注意场景哦），也是Server模式下的默认收集器。 Parallel ScavengeParallelScavenge又被称为是吞吐量优先的收集器，器运行示意图如下 ParallelScavenge所提到的吞吐量=程序运行时间/(JVM执行回收的时间+程序运行时间),假设程序运行了100分钟，JVM的垃圾回收占用1分钟，那么吞吐量就是99%。在当今网络告诉发达的今天，良好的响应速度是提升用户体验的一个重要指标，多核并行云计算的发展要求程序尽可能的使用CPU和内存资源，尽快的计算出最终结果，因此在交互不多的云端，比较适合使用该回收器。 ParallelOldParallelOld是老生代并行收集器的一种，使用标记整理算法、是老生代吞吐量优先的一个收集器。这个收集器是JDK1.6之后刚引入的一款收集器，我们看之前那个图之间的关联关系可以看到，早期没有ParallelOld之前，吞吐量优先的收集器老生代只能使用串行回收收集器，大大的拖累了吞吐量优先的性能，自从JDK1.6之后，才能真正做到较高效率的吞吐量优先。其运行示意图如下 SerialOldSerialOld是旧生代Client模式下的默认收集器，单线程执行；在JDK1.6之前也是ParallelScvenge回收新生代模式下旧生代的默认收集器，同时也是并发收集器CMS回收失败后的备用收集器。其运行示意图如下 CMSCMS又称响应时间优先(最短回收停顿)的回收器，使用并发模式回收垃圾，使用标记-清除算法，CMS对CPU是非常敏感的，它的回收线程数=（CPU+3）/4，因此当CPU是2核的时候，回收线程将占用的CPU资源的50%，而当CPU核心数为4时仅占用25%。他的运行示意图如下 CMS模式主要分为4个过程 初始标记：仅仅标记一下GC Roots能直接关联到的对象，速度很快，需要中断所有用户线程 并发标记：进行GC Roots Tracing的过程 重新标记：为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分的标记记录 并发清除：清除操作 初始标记和重新标记仍然需要 stop the world。 缺点： 1、对CPU资源非常敏感。 2、在并发标记阶段，用户线程和标记线程并发执行，而在这个过程中，随着内存引用关系的变化，可能会发生原来标记的对象被释放，进而引发新的垃圾，因此可能会产生一系列的浮动垃圾，不能被回收。 CMS 为了确保能够扫描到所有的对象，避免在InitialMarking 中还有未标识到的对象，采用的方法为找到标记了的对象，并将这些对象放入Stack 中，扫描时寻找此对象依赖的对象，如果依赖的对象的地址在其之前，则将此对象进行标记，并同时放入Stack 中，如依赖的对象地址在其之后，则仅标记该对象。 在进行ConcurrentMarking 时minor GC 也可能会同时进行，这个时候很容易造成旧生代对象引用关系改变，CMS 为了应对这样的并发现象，提供了一个Mod UnionTable 来进行记录，在这个Mod Union Table中记录每次minor GC 后修改了的Card 的信息。这也是ParallelScavenge不能和CMS一起使用的原因。 CMS产生浮动垃圾的情况请见如下示意图 在运行回收过后，c就变成了浮动垃圾。 由于CMS会产生浮动垃圾，当回收过后，浮动垃圾如果产生过多，同时因为使用标记-清除算法会产生碎片，可能会导致回收过后的连续空间仍然不能容纳新生代移动过来或者新创建的大资源，因此会导致CMS回收失败，进而触发另外一次FULL GC，而这时候则采用SerialOld进行二次回收。 同时CMS因为可能产生浮动垃圾，而CMS在执行回收的同时新生代也有可能在进行回收操作，为了保证旧生代能够存放新生代转移过来的数据，CMS在旧生代内存到达全部容量的68%就触发了CMS的回收！ 3、大量空间碎片的产生 GarbageFirst（G1）g1 gc 回收策略1、优先在Edon上分配对象 对于新生代和旧生代，JVM可使用很多种垃圾回收器进行垃圾回收，下图展示了不同生代不通垃圾回收器，其中两个回收器之间有连线表示这两个回收器可以同时使用。 而这些垃圾回收器又分为串行回收方式、并行回收方式合并发回收方式执行，分别运用于不同的场景。如下图所示 2、大对象直接进入老生代 3、年长者(长期存活对象)进入老生代 4、群体效应(大批中年对象进入老生代) 5、担保GC(担保minorGC) 担保GC就是担保minorGC能够满足当前的存储空间，而无需触发老生代的回收，由于大部分对象都是朝生夕死的，因此，在实际开发中这种很起效，但是也有可能会发生担保失败的情况，当担保失败的时候会触发FullGC，但是失败毕竟是少数，因此这种一般是很划算的 Partial GC：并不收集整个GC堆的模式 Young GC：只收集young gen的GC Old GC：只收集old gen的GC。只有CMS的concurrent collection是这个模式 Mixed GC：收集整个young gen以及部分old gen的GC。只有G1有这个模式 Full GC：收集整个堆，包括young gen、old gen、perm gen（如果存在的话）等所有部分的模式。 Full GC定义是相对明确的，就是针对整个新生代、老生代、元空间（metaspace，java8以上版本取代perm gen）的全局范围的GC； Minor GC和Major GC是俗称，在Hotspot JVM实现的Serial GC, Parallel GC, CMS, G1 GC中大致可以对应到某个Young GC和Old GC算法组合； 最重要是搞明白上述Hotspot JVM实现中几种GC算法组合到底包含了什么。 Serial GC算法：Serial Young GC ＋ Serial Old GC （敲黑板！敲黑板！敲黑板！实际上它是全局范围的Full GC）； Parallel GC算法：Parallel Young GC ＋ 非并行的PS MarkSweep GC / 并行的Parallel Old GC（敲黑板！敲黑板！敲黑板！这俩实际上也是全局范围的Full GC），选PS MarkSweep GC 还是 Parallel Old GC 由参数UseParallelOldGC来控制； CMS算法：ParNew（Young）GC + CMS（Old）GC （piggyback on ParNew的结果／老生代存活下来的object只做记录，不做compaction）＋ Full GC for CMS算法（应对核心的CMS GC某些时候的不赶趟，开销很大）； G1 GC：Young GC + mixed GC（新生代，再加上部分老生代）＋ Full GC for G1 GC算法（应对G1 GC算法某些时候的不赶趟，开销很大）； 搞清楚了上面这些组合，我们再来看看各类GC算法的触发条件。简单说，触发条件就是某GC算法对应区域满了，或是预测快满了。比如， 各种Young GC的触发原因都是eden区满了； Serial Old GC／PS MarkSweep GC／Parallel Old GC的触发则是在要执行Young GC时候预测其promote的object的总size超过老生代剩余size； CMS GC的initial marking的触发条件是老生代使用比率超过某值； G1 GC的initial marking的触发条件是Heap使用比率超过某值，跟4.3 heuristics 类似； Full GC for CMS算法和Full GC for G1 GC算法的触发原因很明显，就是4.3 和 4.4 的fancy算法不赶趟了，只能全局范围大搞一次GC了（相信我，这很慢！这很慢！这很慢！）；5 题主说的 “Full GC会先触发一次Minor GC” － 指的应该是 （说错了，我删了） PS MarkSweep GC／Parallel Old GC（Full GC）之前会跑一次Parallel Young GC；原因就是减轻Full GC 的负担。哇～整个picture 是有点乱，希望我整理的还算清楚：） 对象分配规则 对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。 大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。 长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，直到达到阀值对象进入老年区。 动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。 空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。 如何通过参数来控制个各个内存区域参考此文章：JVM（2）：JVM内存结构]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>gc</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[没事看看]]></title>
    <url>%2Flinks%2F</url>
    <content type="text"><![CDATA[Sql ParseTiDB SQL Parser 的实现 Fork/Joinjdk1.8-ForkJoin框架剖析 数据结构红黑树红黑树深入剖析及Java实现红黑树并没有我们想象的那么难(上) 红黑树详细分析，看了都说好 红黑树的变色与旋转 http://shmilyaw-hotmail-com.iteye.com/blog/1836431https://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html javaCollection衍生类源码分析 年底啦，java后台面试题整理 JVM 之 OopMap 和 RememberedSet找出栈上的指针/引用VM博客 https://www.zhihu.com/question/60949531/answer/182115799 ThreadLocalThreadLocal内存泄漏详解ThreadLocal详解ThreadLocal与WeakReference 创业三个步骤，帮你找到合适的创业想法 聊天高情商的人都知道如何聊天聊天的两种能力 投资指数https://xueqiu.com/4776750571/57394021https://xueqiu.com/4776750571/58965236 分级A手把手玩转分级A（上）手把手玩转分级A（中）手把手玩转分级A（下） 可转债转债投资入门（一）：什么是可转债转债投资入门（二）：转债投资四要素 书籍村上春树epub合集https://bbs.feng.com/read-htm-tid-11180611.html]]></content>
      <categories>
        <category>interesting</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[各种概念]]></title>
    <url>%2Fshit%2F%E7%83%82%E8%BD%A6%E7%9A%84%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[IaaS：就是台服务器。 PaaS：就是Tomcat加MySQL。 SaaS：就是三千块一套的加个Logo就能开业的电商网站。 BaaS：Backend as a Service]]></content>
      <categories>
        <category>shit</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Executor框架]]></title>
    <url>%2Fjava%2FExecutor%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[简介Executor两级调用模型 Executor的结构和成员 Executor框架的使用 ThreadPoolExecutorThreadPoolExecutor执行execute： 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（需要获取全局锁）。 如果运行的线程等于或多余corePoolSize，则将任务加入BlockingQueue 如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（需要获取全局锁）。 如果创建新线程将使当前运行的线程超过maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。 FixedThreadPoolFixedThreadPool适用于为了满足管理资源的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 其corePoolSize和maximumPoolSize都被设为nThreads的值。当线程池中的线程数大于corePoolSize时，keepAliveTime为多余的空闲线程等待新任务的最长时间，超过这个时间后多余的线程将被终止。具体在FixedThreadPool的执行过程如下： 如果当前运行的线程数少于corePoolSize，就创建新的线程执行任务 在线程池如果当前运行的线程数等于corePoolSize时，将任务加入到LinkedBlockingQueue等待执行 线程执行完1中的任务后，会在循环中反复从LinkedBlockingQueue获取任务来执行 由于LinkedBlockingQueue使用的无界队列，所以线程池中线程数不会超过corePoolSize，因此不断加入线程池中的任务将被执行，因为不会马上被执行的任务都加入到LinkedBlockingQueue等待了。 SingleThreadExecutorSingleThreadExecutor适用于需要保证顺序地执行各个任务，并且在任意时间点不会有多个线程在活动的场景。 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; corePoolSize和maximumPoolSize都为1，且工作队列为无界队列，所以，当启动了一个线程后，以后所有的工作直接加入工作队列中。 CachedThreadPoolCachedThreadPool是大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者负载比较轻的服务器;是一个根据需要创建线程的线程池 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; CachedThreadPool的corePoolSize为0，maximumPoolSize为Integer.MAX_VALUE，keepAliveTime为60L，意味着多余的空闲线程等待新任务的执行时间为60秒。CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列（SynchronousQueue是一个没有容量的阻塞队列，每个插入操作必须等待另一个线程的对应移除操作），但是CachedThreadPool的maximumPool是无界的。这就意味着如果线程的提交速度高于线程的处理速度，CachedThreadPool会不断创建线程，极端情况是因为创建线程过多耗尽CPU和内存资源。 ScheduledThreadPoolExecutor使用的DelayedWorkQueue是一个无界队列，所以maximumPoolSize参数无效。创建一个支持定时及周期性的任务执行的线程池，多数情况下可用来替代Timer类。ScheduledThreadPoolExecutor适用于需要在多个后台线程执行周期任务，同时为了满足资源管理需求需要限制后台线程数量的应用场景。 ScheduledThreadPoolExecutor123456789101112131415161718public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;public ScheduledThreadPoolExecutor(int corePoolSize) &#123; // 使用的DelayedWorkQueue是一个无界队列，所以maximumPoolSize参数无效。 super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; SingleThreadScheduledExecutor12345678910public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1));&#125;public ScheduledThreadPoolExecutor(int corePoolSize) &#123; // 使用的DelayedWorkQueue是一个无界队列 super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125; DelayedWorkQueueDelayedWorkQueue是一个基于堆的数据结构，类似于DelayQueue和PriorityQueue。在执行定时任务的时候，每个任务的执行时间都不同，所以DelayedWorkQueue的工作就是按照执行时间的升序来排列，执行时间距离当前时间越近的任务在队列的前面（注意：这里的顺序并不是绝对的，堆中的排序只保证了子节点的下次执行时间要比父节点的下次执行时间要大，而叶子节点之间并不一定是顺序的，下文中会说明）。 可见，DelayedWorkQueue是一个基于最小堆结构的队列。堆结构可以使用数组表示，可以转换成如下的数组： 在这种结构中，可以发现有如下特性： 假设，索引值从0开始，子节点的索引值为k，父节点的索引值为p，则： 一个节点的左子节点的索引为：k = p * 2 + 1； 一个节点的右子节点的索引为：k = (p + 1) * 2； 一个节点的父节点的索引为：p = (k - 1) / 2。 offer既然是阻塞队列，入队的操作如add和put方法都调用了offer方法，下面查看一下offer方法：12345678910111213141516171819202122232425262728293031public boolean offer(Runnable x) &#123; if (x == null) throw new NullPointerException(); RunnableScheduledFuture&lt;?&gt; e = (RunnableScheduledFuture&lt;?&gt;)x; final ReentrantLock lock = this.lock; lock.lock(); try &#123; int i = size; // queue是一个RunnableScheduledFuture类型的数组，如果容量不够需要扩容 if (i &gt;= queue.length) grow(); size = i + 1; // i == 0 说明堆中还没有数据 if (i == 0) &#123; queue[0] = e; setIndex(e, 0); &#125; else &#123; // i != 0 时，需要对堆进行重新排序 siftUp(i, e); &#125; // 如果传入的任务已经是队列的第一个节点了，这时available需要发出信号 if (queue[0] == e) &#123; // leader设置为null为了使在take方法中的线程在通过available.signal();后会执行available.awaitNanos(delay); leader = null; available.signal(); &#125; &#125; finally &#123; lock.unlock(); &#125; return true;&#125; siftUp1234567891011121314151617181920// 基于二叉树的实现private void siftUp(int k, RunnableScheduledFuture&lt;?&gt; key) &#123; while (k &gt; 0) &#123; // 找到父节点的索引 int parent = (k - 1) &gt;&gt;&gt; 1; // 获取父节点 RunnableScheduledFuture&lt;?&gt; e = queue[parent]; // 如果key节点的执行时间大于父节点的执行时间，不需要再排序了 if (key.compareTo(e) &gt;= 0) break; // 如果key.compareTo(e) &lt; 0，说明key节点的执行时间小于父节点的执行时间，需要把父节点移到后面 queue[k] = e; // 设置索引为k setIndex(e, k); k = parent; &#125; // key设置为排序后的位置中 queue[k] = key; setIndex(key, k);&#125; 代码很好理解，就是循环的根据key节点与它的父节点来判断，如果key节点的执行时间小于父节点，则将两个节点交换，使执行时间靠前的节点排列在队列的前面。 假设新入队的节点的延迟时间（调用getDelay()方法获得）是5，执行过程如下： 先将新的节点添加到数组的尾部，这时新节点的索引k为7： 计算新父节点的索引：parent = (k - 1) &gt;&gt;&gt; 1，parent = 3，那么queue[3]的时间间隔值为8，因为 5 &lt; 8 ，将执行queue[7] = queue[3]： 这时将k设置为3，继续循环，再次计算parent为1，queue[1]的时间间隔为3，因为 5 &gt; 3 ，这时退出循环，最终k为3： 可见，每次新增节点时，只是根据父节点来判断，而不会影响兄弟节点。 另外，setIndex方法只是设置了ScheduledFutureTask中的heapIndex属性：1234private void setIndex(RunnableScheduledFuture&lt;?&gt; f, int idx) &#123; if (f instanceof ScheduledFutureTask) ((ScheduledFutureTask)f).heapIndex = idx;&#125; take方法12345678910111213141516171819202122232425262728293031323334353637383940public RunnableScheduledFuture&lt;?&gt; take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; RunnableScheduledFuture&lt;?&gt; first = queue[0]; if (first == null) available.await(); else &#123; // 计算当前时间到执行时间的时间间隔 long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) return finishPoll(first); first = null; // don't retain ref while waiting // leader不为空，阻塞线程 if (leader != null) available.await(); else &#123; // leader为空，则把leader设置为当前线程， Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; // 阻塞到执行时间 available.awaitNanos(delay); &#125; finally &#123; // 设置leader = null，让其他线程执行available.awaitNanos(delay); if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; // 如果leader不为空，则说明leader的线程正在执行available.awaitNanos(delay); // 如果queue[0] == null，说明队列为空 if (leader == null &amp;&amp; queue[0] != null) available.signal(); lock.unlock(); &#125;&#125; take方法是什么时候调用的呢？在深入理解Java线程池：ThreadPoolExecutor中，介绍了getTask方法，工作线程会循环地从workQueue中取任务。但定时任务却不同，因为如果一旦getTask方法取出了任务就开始执行了，而这时可能还没有到执行的时间，所以在take方法中，要保证只有在到指定的执行时间的时候任务才可以被取走。 再来说一下leader的作用，这里的leader是为了减少不必要的定时等待，当一个线程成为leader时，它只等待下一个节点的时间间隔，但其它线程无限期等待。 leader线程必须在从take（）或poll（）返回之前signal其它线程，除非其他线程成为了leader。 举例来说，如果没有leader，那么在执行take时，都要执行available.awaitNanos(delay)，假设当前线程执行了该段代码，这时还没有signal，第二个线程也执行了该段代码，则第二个线程也要被阻塞。多个这时执行该段代码是没有作用的，因为只能有一个线程会从take中返回queue[0]（因为有lock），其他线程这时再返回for循环执行时取的queue[0]，已经不是之前的queue[0]了，然后又要继续阻塞。 所以，为了不让多个线程频繁的做无用的定时等待，这里增加了leader，如果leader不为空，则说明队列中第一个节点已经在等待出队，这时其它的线程会一直阻塞，减少了无用的阻塞（注意，在finally中调用了signal()来唤醒一个线程，而不是signalAll()）。 finishPoll1234567891011121314private RunnableScheduledFuture&lt;?&gt; finishPoll(RunnableScheduledFuture&lt;?&gt; f) &#123; // 数组长度-1 int s = --size; // 取出最后一个节点 RunnableScheduledFuture&lt;?&gt; x = queue[s]; // 删除最后一个元素 queue[s] = null; // 长度不为0，则从第一个元素开始排序，目的是通过排序最后一个元素，来替换第一个节点 if (s != 0) // 用最有一个元素替换第一个元素，引起二叉树重新平衡，进而删除出第一个元素 siftDown(0, x); setIndex(f, -1); return f;&#125; remove类似finishPoll：1234567891011121314151617181920212223242526// 替换指定位置的元素，即重新平衡二叉树进而移除元素public boolean remove(Object x) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; int i = indexOf(x); if (i &lt; 0) return false; setIndex(queue[i], -1); int s = --size; RunnableScheduledFuture&lt;?&gt; replacement = queue[s];// 取最后一个元素进行替换 queue[s] = null; if (s != i) &#123; siftDown(i, replacement);// 对i位置进行替换 if (queue[i] == replacement) // 如果queue[i] == replacement，说明i是叶子节点 // 如果是这种情况，不能保证子节点的下次执行时间比父节点的大 // 这时需要进行一次向上调整 siftUp(i, replacement); &#125; return true; &#125; finally &#123; lock.unlock(); &#125;&#125; siftDown出队列时，调用siftDown：123456789101112131415161718192021222324252627// 指定位置元素的值设为k，并进行比较、下移；可用于替换指定位置的元素private void siftDown(int k, RunnableScheduledFuture&lt;?&gt; key) &#123; // 根据二叉树的特性，数组长度除以2，表示取有子节点的索引 int half = size &gt;&gt;&gt; 1; // 判断索引为k的节点是否有子节点 while (k &lt; half) &#123; // 左子节点的索引 int child = (k &lt;&lt; 1) + 1; RunnableScheduledFuture&lt;?&gt; c = queue[child]; // 右子节点的索引 int right = child + 1; // 如果有右子节点并且左子节点的时间间隔大于右子节点，取时间间隔最小的节点 if (right &lt; size &amp;&amp; c.compareTo(queue[right]) &gt; 0) c = queue[child = right]; // 如果key的时间间隔小于等于c的时间间隔，跳出循环 if (key.compareTo(c) &lt;= 0) break; // 将字节点上移 queue[k] = c; setIndex(c, k); // 设置索引 k = child; &#125; // 将key放入索引为k的位置 queue[k] = key; setIndex(key, k);&#125; FutureTaskjdk1.6基于AQS来实现的，从jdk1.7开始是基于volatile来实现的。 123public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt;// 由于实现了Runnable接口，所以可作为任务public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 另外，使用线程池submit的task，实际上被包裹成FutureTask：12345678910public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125; Constructor123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * The run state of this task, initially NEW. The run state * transitions to a terminal state only in methods set, * setException, and cancel. During completion, state may take on * transient values of COMPLETING (while outcome is being set) or * INTERRUPTING (only while interrupting the runner to satisfy a * cancel(true)). Transitions from these intermediate to final * states use cheaper ordered/lazy writes because values are unique * and cannot be further modified. * * Possible state transitions: * NEW -&gt; COMPLETING -&gt; NORMAL * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL * NEW -&gt; CANCELLED * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED */// 基于volatile来实现private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1; // 在set、setException中，会预先置为COMPLETINGprivate static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6;public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125;protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion(); &#125;&#125;protected void setException(Throwable t) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = t; UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state finishCompletion(); &#125;&#125; run123456789101112131415161718192021222324252627282930313233343536373839public void run() &#123; // 1. 状态如果不是NEW，说明任务或者已经执行过，或者已经被取消，直接返回 // 2. 状态如果是NEW，则尝试把当前执行线程保存在runner字段中 // 如果赋值失败则直接返回 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; // 3. 执行任务 result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; // 4. 任务异常 setException(ex); &#125; if (ran) // 4. 任务正常执行完毕 set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; // 5. 如果任务被中断，执行中断处理 if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; run()方法首先会 判断当前任务的state是否等于NEW,如果不为NEW则说明任务或者已经执行过，或者已经被取消，直接返回。 如果状态为NEW则接着会通过unsafe类把任务执行线程引用CAS的保存在runner字段中，如果保存失败，则直接返回。 执行任务。 如果任务执行发生异常，则调用setException()方法保存异常信息。setException()方法如下： get1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); // 任务未完成时，其他线程调用get将被阻塞 return report(s);&#125;private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; // 1. 判断阻塞线程是否被中断,如果被中断则在等待队 // 列中删除该节点并抛出InterruptedException异常 if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; // 2. 获取当前状态，如果状态大于COMPLETING // 说明任务已经结束(要么正常结束，要么异常结束，要么被取消) // 则把thread显示置空，并返回结果 int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; // 3. 如果状态处于中间状态COMPLETING // 表示任务已经结束但是任务执行线程还没来得及给outcome赋值 // 这个时候让出执行权让其他线程优先执行 else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) // 4. 如果等待节点为空，则构造一个等待节点 q = new WaitNode(); else if (!queued) // 5. 如果还没有入队列，则把当前节点加入waiters首节点并替换原来waiters queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; // 如果需要等待特定时间，则先计算要等待的时间 // 如果已经超时，则删除对应节点并返回对应的状态 nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; // 6. 阻塞等待特定时间 LockSupport.parkNanos(this, nanos); &#125; else // 6. 阻塞等待直到被其他线程唤醒 LockSupport.park(this); &#125;&#125; awaitDone()中有个死循环，每一次循环都会 判断调用get()的线程是否被其他线程中断，如果是的话则在等待队列中删除对应节点然后抛出InterruptedException异常。 获取任务当前状态，如果当前任务状态大于COMPLETING则表示任务执行完成，则把thread字段置null并返回结果。 如果任务处于COMPLETING状态，则表示任务已经处理完成(正常执行完成或者执行出现异常)，但是执行结果或者异常原因还没有保存到outcome字段中。这个时候调用线程让出执行权让其他线程优先执行。 如果等待节点为空，则构造一个等待节点WaitNode。 如果第四步中新建的节点还没如队列，则CAS的把该节点加入waiters队列的首节点。 阻塞等待。 假设当前state=NEW且waiters为NULL,也就是说还没有任何一个线程调用get()获取执行结果，这个时候有两个线程threadA和threadB先后调用get()来获取执行结果。再假设这两个线程在加入阻塞队列进行阻塞等待之前任务都没有执行完成且threadA和threadB都没有被中断的情况下(因为如果threadA和threadB在进行阻塞等待结果之前任务就执行完成或线程本身被中断的话，awaitDone()就执行结束返回了)，执行过程是这样的，以threadA为例: 第一轮for循环，执行的逻辑是q == null,所以这时候会新建一个节点q。第一轮循环结束。 第二轮for循环，执行的逻辑是!queue，这个时候会把第一轮循环中生成的节点的netx指针指向waiters，然后CAS的把节点q替换waiters。也就是把新生成的节点添加到waiters链表的首节点。如果替换成功，queued=true。第二轮循环结束。 第三轮for循环，进行阻塞等待。要么阻塞特定时间，要么一直阻塞知道被其他线程唤醒。 cancel(boolean)1234567891011121314151617181920212223public boolean cancel(boolean mayInterruptIfRunning) &#123; // 1. 如果任务已经结束，则直接返回false if (state != NEW) return false; // 2. 如果需要中断任务执行线程 if (mayInterruptIfRunning) &#123; // 2.1. 把任务状态从NEW转化到INTERRUPTING if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, INTERRUPTING)) return false; Thread t = runner; // 2.2. 中断任务执行线程 if (t != null) t.interrupt(); // 2.3. 修改状态为INTERRUPTED UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); // final state &#125; // 3. 如果不需要中断任务执行线程，则直接把状态从NEW转化为CANCELLED else if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, CANCELLED)) return false; // 4. finishCompletion(); return true;&#125; cancel()方法会做下面几件事: 判断任务当前执行状态，如果任务状态不为NEW，则说明任务或者已经执行完成，或者执行异常，不能被取消，直接返回false表示执行失败。 判断需要中断任务执行线程，则把任务状态从NEW转化到INTERRUPTING。这是个中间状态。中断任务执行线程。修改任务状态为INTERRUPTED。这个转换过程对应上图中的四。 如果不需要中断任务执行线程，直接把任务状态从NEW转化为CANCELLED。如果转化失败则返回false表示取消失败。这个转换过程对应上图中的四。 调用finishCompletion()。 当调用cancel(true)方法的时候，实际执行还是Thread.interrupt()方法，而interrupt()方法只是设置中断标志位，如果被中断的线程处于sleep()、wait()或者join()逻辑中则会抛出InterruptedException异常。 finishCompletion()根据前面的分析，不管是任务执行异常还是任务正常执行完毕，或者取消任务，最后都会调用finishCompletion()方法，该方法实现如下:123456789101112131415161718192021222324private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; done(); callable = null; // to reduce footprint&#125; 这个方法的实现比较简单，依次遍历waiters链表，唤醒节点中的线程，然后把callable置空。被唤醒的线程会各自从awaitDone()方法中的LockSupport.park*()阻塞中返回，然后会进行新一轮的循环。在新一轮的循环中会返回执行结果(或者更确切的说是返回任务的状态)。]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java中的线程池]]></title>
    <url>%2Fjava%2FJava%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[实现原理ThreadPoolExecutor执行execute： 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（需要获取全局锁）。 如果运行的线程等于或多余corePoolSize，则将任务加入BlockingQueue 如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（需要获取全局锁）。 如果创建新线程将使当前运行的线程超过maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。 线程池的使用创建123456public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler); workQueue：任务队列(ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、PriorityBlockingQueue)maximumPoolSize: 如果使用了无界的任务队列这个参数就没哟什么效果RejectedExecutionHandler： 饱和策略 提交任务execute： 无返回值sumbit：有返回值1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125;/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;&#125;/** * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125; 通过线程池submit的任务，最终都被包裹成FutureTask，并且FutureTask实现了Runnable接口。在调用execute方法后，将任务添加到工作队列中。 关闭线程池(shutdown、shutdownNow)原理：遍历线程池中的工作线程，逐个调用线程的interrupt方法来终端，所以无法响应中断的任务可能永远无法终止。区别：shutdown将线程池状态设为SHUTDOWN，然后中断所有没在执行的任务；shutdownNow首先将线程池的状态设为STOP，然后尝试停止所有正在执行或暂停任务的线程，并返回等待执行任务的列表。 合理配置线程池任务特性 性质：CPU密集型任务、IO密集型任务、混合型任务 优先级：高中低 执行时间： 长、短 依赖性：依赖其他资源，入数据库连接 CPU密集型任务应配置尽可能小的线程，如配置coreNum + 1个线程的线程池。IO密集型应配置尽可能多的线程，如2coreNum，由于不是一直在执行任务。混合型的任务，如何可以拆分，将其拆分为一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量。如果这两个执行时间相差太大，则没必要进行分解。可以通过Runtime.getRuntime().availableProcessors()来获取当前设备的CPU个数。建议使用有界队列，防止撑爆内存，拖垮系统，影响其他的任务。 线程池的监控通过自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任务执行前、后和线程池给关闭前执行一些代码来进行监控。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发容器和框架]]></title>
    <url>%2Fjava%2FJava%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E5%92%8C%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[主要介绍ConcurrentHashMap、ConcurrentLinkedQueue、阻塞队列、Fork/Join框架 ConcurrentHashMapConcurrentLinkedQueue阻塞队列 阻塞队列是一个支持两个附加操作的队列。这两个附加的操作支持阻塞地插入和移除方法。 支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。 支持阻塞地移除方法：意思是当队列空时，获取元素的线程会等待队列变空。 接口方法12345678910111213141516171819202122232425public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; &#123; boolean add(E e); boolean offer(E e); void put(E e) throws InterruptedException; boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException; E take() throws InterruptedException; E poll(long timeout, TimeUnit unit) throws InterruptedException; int remainingCapacity(); boolean remove(Object o); public boolean contains(Object o); int drainTo(Collection&lt;? super E&gt; c); int drainTo(Collection&lt;? super E&gt; c, int maxElements);&#125; 方法/处理方式 抛出异常 返回特殊值 一直阻塞 超时退出 插入 add(e) offer(e) put(e) offer(e, time, unit) 移除 remove() poll () take() poll(time, unit) 检查 element() peek() 不可用 不可用 实现原理使用通知模式实现。以ArrayBlockingQueue为例：123456789101112131415161718192021222324252627282930313233/** Main lock guarding all access */final ReentrantLock lock;/** Condition for waiting takes */private final Condition notEmpty;/** Condition for waiting puts */private final Condition notFull;public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125;public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; 队列 ArrayBlockingQueue LinkedBlockingQueue PriorityBlockingQueue DelayQueue DelayedWorkQueue SynchronousQueue LinkedTransferQueue LinkedBlockingDeque https://javadoop.com/post/java-concurrent-queue Fork/Join框架]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发工具类]]></title>
    <url>%2Fjava%2FJava%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[CountDownLatch依赖于AbstractQueuedSynchronizer实现的共享同步器 123456789101112131415161718192021222324252627private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125;&#125; await12345678910111213141516public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;// 当state不等于0，返回-1，则加入等待队列中protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; countDown1234567891011121314151617181920212223public void countDown() &#123; sync.releaseShared(1);&#125;public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared();// 唤醒等待节点 return true; &#125; return false;&#125;protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; 实例12345678910111213141516171819202122232425262728293031323334353637383940public class Test &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(2); new Thread()&#123; public void run() &#123; try &#123; System.out.println("子线程"+Thread.currentThread().getName()+"正在执行"); Thread.sleep(3000); System.out.println("子线程"+Thread.currentThread().getName()+"执行完毕"); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; try &#123; System.out.println("子线程"+Thread.currentThread().getName()+"正在执行"); Thread.sleep(3000); System.out.println("子线程"+Thread.currentThread().getName()+"执行完毕"); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); try &#123; System.out.println("等待2个子线程执行完毕..."); latch.await(); System.out.println("2个子线程已经执行完毕"); System.out.println("继续执行主线程"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; CyclicBarrier利用ReentrantLock和Condition，来阻塞调用await方法的线程。当满足一定条件，自动唤醒所有的线程。1234/** The lock for guarding barrier entry */private final ReentrantLock lock = new ReentrantLock();/** Condition to wait on until tripped */private final Condition trip = lock.newCondition(); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen &#125;&#125;/** * Main barrier code, covering the various policies. */private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; final Generation g = generation; if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; breakBarrier(); throw new InterruptedException(); &#125; int index = --count; if (index == 0) &#123; // tripped，当最后一个线程调用await时，唤醒所有线程 boolean ranAction = false; try &#123; final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; nextGeneration(); return 0; &#125; finally &#123; if (!ranAction) breakBarrier();// 唤醒所有线程 &#125; &#125; // loop until tripped, broken, interrupted, or timed out for (;;) &#123; try &#123; if (!timed) trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // "belong" to subsequent execution. Thread.currentThread().interrupt(); &#125; &#125; if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125;private void breakBarrier() &#123; generation.broken = true; count = parties; trip.signalAll();// 唤醒所有线程&#125; 实例1234567891011121314151617181920212223242526public class CyclicBarrierTest &#123; static CyclicBarrier c = new CyclicBarrier(2); public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; c.await(); &#125; catch (Exception e) &#123; &#125; System.out.println(1); &#125; &#125;).start(); try &#123; c.await(); &#125; catch (Exception e) &#123; &#125; System.out.println(2); &#125;&#125; CountDownLatch和CyclicBarrier的区别 CountDownLatch只能用一次，CyclicBarrier可以使用reset()方法重置。 … Semaphore 用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。 semapthore依赖于AbstractQueuedSynchronizer实现的同步器。可以用来做流量控制。123456Semaphore s = new Semaphore(10);s.acquire();......s.release(); 实例12345678910111213141516171819202122232425262728293031public class SemaphoreTest &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newCachedThreadPool(); final Semaphore sp = new Semaphore(3); for (int i = 0; i &lt; 10; i++) &#123; Runnable runnable = new Runnable() &#123; public void run() &#123; try &#123; sp.acquire(); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("线程" + Thread.currentThread().getName() + "进入，当前已有" + (3 - sp.availablePermits()) + "个并发"); try &#123; Thread.sleep((long) (Math.random() * 10000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("线程" + Thread.currentThread().getName() + "即将离开"); sp.release(); //下面代码有时候执行不准确，因为其没有和上面的代码合成原子单元 System.out.println("线程" + Thread.currentThread().getName() + "已离开，当前已有" + (3 - sp.availablePermits()) + "个并发"); &#125; &#125;; service.execute(runnable); &#125; &#125;&#125; Exchanger 用于线程间的数据交换。它提供一个同步点，两个线程可以交换彼此数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.concurrent.Exchanger;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/**` * @author joyo * @date 2018/3/15 */public class ExchangerTest &#123; private static final Exchanger&lt;String&gt; exgr = new Exchanger&lt;&gt;(); private static ExecutorService threadPool = Executors.newFixedThreadPool(2); public static void main(String[] args) &#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; String A = "银行流水A"; exgr.exchange(A); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); threadPool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; String B = "银行流水A"; String A = exgr.exchange(B); System.out.println("A和B数据是否一致：" + A.equals(B) + ", A录入的是：" + A + "， B录入的是:" + B); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); threadPool.shutdown(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁]]></title>
    <url>%2Fjava%2F%E9%94%81%2F</url>
    <content type="text"><![CDATA[Lock1234567Lock lock = new ReentrantLock();lock.lock();try&#123; ...&#125;finally&#123; lock.unlock();&#125; 1、灵活2、尝试非阻塞地获取锁123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; 3、能被中断地获取锁1234// 中断获取的一部分，parkAndCheckInterrupt 调用的是LockSupport.park(this); LockSupport 具有中断返回的特性。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); 4、能超时获取锁1lock.tryLock(1, TimeUnit.SECONDS); 5、独占或共享的方式 队列同步器 模板方法 volatile int 状态变量 CAS 同步队列（FIFO双向队列） 共享、独占获取同步状态 123456// overrideprotected boolean tryAcquire(int arg)protected boolean tryRelease(int arg)protected int tryAcquireShared(int arg)protected boolean tryReleaseShared(int arg)protected boolean isHeldExclusively() 1234// 可用方法getState()setState(int newState)compareAndSetState(int expect, int update) 123456789101112131415// 提供的模板方法// 独占、超时void acquire(int arg)void acquireInterruptibly(int arg)boolean tryAcquireNanos(int arg, long nanos)// 共享、超时void acquireShared(int arg)void acquireSharedInterruptibly(int arg)boolean tryAcquireSharedNanos(int arg)boolean release(int arg)boolean releaseShared(int arg)Collection&lt;Thread&gt; getQueuedThreads() 独占式获取1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public final void acquire(long arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;//同步队列：含有头尾节点的 FIFO 的双向队列private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; // 快速尝试一次添加尾节点，如果失败则通过enq(node)循环加入 node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 快速尝试失败后 enq(node); return node;&#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125;// 自旋，通过判断前驱pred 是否为head节点，来获取同步状态final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 进入wait状态 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;// 将前驱pred 的状态设为SIGNAL 后，返回trueprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 释放12345678910111213141516171819202122232425262728293031323334353637public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125;private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; // s 为空或者s 的状态为CANCEL 时，从尾到头找到第一个正常状态的节点s if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 共享式获取12345678910111213141516171819202122232425262728293031323334public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; // 类似于acquireQueued，开始自旋 boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; // p 节点非head 节点时，进入wait 状态，等待后续前驱节点的唤醒 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 释放1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared();// 多线程释放，需要通过CAS来保证 return true; &#125; return false;&#125; 独占式 共享式 超时获取 同步队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; /** * Performs &#123;@link Lock#lock&#125;. The main reason for subclassing * is to allow fast path for nonfair version. */ abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125; protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; protected final boolean isHeldExclusively() &#123; // While we must in general read state before owner, // we don't need to do so to check if current thread is owner return getExclusiveOwnerThread() == Thread.currentThread(); &#125; final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // Methods relayed from outer class final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; final boolean isLocked() &#123; return getState() != 0; &#125; /** * Reconstitutes the instance from a stream (that is, deserializes it). */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125;&#125; ReentrantLockAQS的唤醒机制是从队列中取出head节点的下一个节点来唤醒。咋一看，好像公平锁和非公平锁的实现逻辑是一样的。其实，非公平锁在唤醒下一个节点后，释放锁的节点或者新加入线程会和被唤醒的节点同时来竞争锁，并且释放锁的节点很大几率是成功的，所以不是FIFO，即非公平锁。而公平锁，由于在获取的时候添加了判断hasQueuedPredecessors()，即使当前新线程并没有在队列中，也会生成一个新的节点插入队尾，并不会和唤醒节点竞争。因此是严格FIFO。 获取锁非公平锁12345678910111213141516171819202122232425262728293031323334353637final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125;// AQS模板方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;// 子类重写的方法protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125; final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;// 支持可重入 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 公平锁12345678910111213141516171819202122232425262728293031final void lock() &#123; acquire(1);&#125;// AQS模板方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;// 子类重写的方法protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;// 支持可重入 int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 释放锁1234567891011121314151617181920212223public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; // fair and nofair is sameprotected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; ReentrantReadWriteLock通过按位切割使用，在一个整型变量上维护多种状态。高16位表示读。低16位表示写。 写锁的获取与释放12345678910111213141516171819202122232425262728293031protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error("Maximum lock count exceeded"); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true;&#125; 存在读锁时，不能获取写锁。 读锁的获取与释放123456789101112131415161718192021222324252627282930313233343536373839404142protected final int tryAcquireShared(int unused) &#123; /* * Walkthrough: * 1. If write lock held by another thread, fail. * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 写锁没有被其他线程获取或者被自己获取，则获取读锁成功；否则失败。 锁降级 拥有写锁，再获取读锁，随后释放写锁的过程。 LockSupport1234void park()void parkNanos(long nanos)void parkUntil(long deadline)void unpark(Thread thread) LockSupport.part()方法是响应中断地，当线程中断后，会从park方法返回执行后续逻辑，所以，LockSupport中的对中断地响应可以灵活控制。1234567891011121314151617181920212223242526272829/** * @author joyo * @date 2018/4/16 */public class LockSupportInterruptTest &#123; public static void main(String[] args) throws InterruptedException &#123; ReentrantLock lock = new ReentrantLock(); Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; lock.lock(); try &#123; LockSupport.park(); System.out.println("come back here"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;); thread.start(); Thread.sleep(2000); thread.interrupt(); &#125;&#125; 最终输出结果：come back here，而不是打印异常栈。 而Object.wait()方法并没有这个特性，会直接抛出中断异常。 Condition condition包含一个等待队列，有收尾节点组成。 await：生成节点放入等待队列 signal：将节点从等待队列中放入到sync中的同步队列末尾，等待后续竞争锁，恢复执行。唤醒时，是从头结点开始一个一个唤醒的。 ConditionObject是AQS的内部类，当唤醒Condition等待队列的节点时，会加入到AQS的同步队列的尾巴。 1234567public final void await()public final long awaitNanos(long nanosTimeout)public final boolean awaitUntil(Date deadline)public final boolean await(long time, TimeUnit unit)public final void signal()public final void signalAll() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// 队头、队尾private transient Node firstWaiter;private transient Node lastWaiter;public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125;// 新增等待节点，放入队尾private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125;public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125;private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; // 将节点从等待队列移到同步队列末尾 (first = firstWaiter) != null);&#125;final boolean transferForSignal(Node node) &#123; /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ Node p = enq(node);// 将节点放入sync中的同步队列 int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程基础]]></title>
    <url>%2Fjava%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[线程的状态 名称 说明 NEW 初始状态，线程被构建，但还没有调用start()方法 RUNNABLE 运行状态，java线程将操作系统中的就绪和运行统称为运行中 BLOCKED 阻塞状态，表示线程阻塞于锁 WAITING 等待状态，当前线程需要等待其他线程做出一些特定动作（通知或中断） TIME_WAITING 超时等待状态，不同于WAITING，它可以在指定的时间自行返回的 TERMINATED 终止状态 Daemon线程线程默认不是daemon线程，需要setDaemon(true)。daemon线程的finally方法，不一定有机会执行。 启动和终止suspend()、resume()和stop()suspend方法在调用后，线程不会释放已经占有的资源，而是占用资源进入睡眠状态。同样，stop方法在中介一个线程时不会保证线程的资源正常释放，通常是没有给予线程完成资源释放工作的机会。 进程间通信volatile和synchronized的方式通过共享变量的方式 等待/通知机制wait/notify(notifyAll)指线程A调用了对象O的wait方法进入等待状态，而线程B通过调用对象O的notify或者notifyAll方法来唤醒A线程，A线程从wait方法返回继续执行。 调用waie、notify、notifyAll方法时，需要先对调用对象加锁 调用wait后，释放锁。线程状态由running变为waiting notify、notifyAll释放所之后，wait的线程才能获取锁。 调用notify、notifyAll后，等待线程从等待队列中移到同步队列中，被移动的线程的状态由WATING变为BLOCKED 使用方式： Thread.join 线程池 数据库连接池 LockSupport Condition(await、signal、signalAll) AbstractQueuedSynchronizer ReentrantLock CountDownLatch … ThreadLocal线程应用实例等待超时模式123456long future = System.currentTimeMillis() + mills;long remaining = mills;while(remaining &gt; 0)&#123; wait(remaing); remaining = future - System.currentTimeMillis();&#125; 线程池123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141package com.iforfee.common.thread;import java.util.ArrayList;import java.util.Collections;import java.util.LinkedList;import java.util.List;import java.util.concurrent.atomic.AtomicLong;/** * @author joyo * @date 2018/3/14 */public class DefaultThreadPool&lt;Job extends Runnable&gt; implements ThreadPool&lt;Job&gt; &#123; private static final int MAX_WORKER_NUMBERS = 10; private static final int DEFAULT_WORKER_NUMBERS = 5; private static final int MIN_WORKER_NUMBERS = 1; private final LinkedList&lt;Job&gt; jobs = new LinkedList&lt;Job&gt;(); private final List&lt;Worker&gt; workers = Collections.synchronizedList(new ArrayList&lt;Worker&gt;()); private int workerNum = DEFAULT_WORKER_NUMBERS; private AtomicLong threadNum = new AtomicLong(); public DefaultThreadPool() &#123; initializeWokers(DEFAULT_WORKER_NUMBERS); &#125; public DefaultThreadPool(int num) &#123; workerNum = num &gt; MAX_WORKER_NUMBERS ? MAX_WORKER_NUMBERS : num &lt; MIN_WORKER_NUMBERS ? MIN_WORKER_NUMBERS : num; initializeWokers(workerNum); &#125; @Override public void execute(Job job) &#123; if (job != null) &#123; synchronized (jobs) &#123; jobs.addLast(job); jobs.notify(); &#125; &#125; &#125; @Override public void shutdown() &#123; workers.forEach(job -&gt; job.shutdown()); &#125; @Override public void addWorkers(int num) &#123; synchronized (jobs) &#123; if (num + this.workerNum &gt; MAX_WORKER_NUMBERS) &#123; num = MAX_WORKER_NUMBERS - this.workerNum; &#125; initializeWokers(num); this.workerNum += num; &#125; &#125; @Override public void removeWorker(int num) &#123; synchronized (jobs) &#123; if (num &gt;= this.workerNum) &#123; throw new IllegalArgumentException(&quot;beyond workerNum&quot;); &#125; int count = 0; while (count &lt; num) &#123; Worker worker = workers.get(count); if (workers.remove(worker)) &#123; worker.shutdown(); count++; &#125; this.workerNum -= count; &#125; &#125; &#125; @Override public int getJobSize() &#123; return jobs.size(); &#125; private void initializeWokers(int num) &#123; for (int i = 0; i &lt; num; i++) &#123; Worker worker = new Worker(); workers.add(worker); Thread thread = new Thread(worker, &quot;ThreadPool-Worker-&quot; + threadNum.incrementAndGet()); thread.start(); &#125; &#125; class Worker implements Runnable &#123; private volatile boolean running = true; @Override public void run() &#123; while (running) &#123; Job job = null; synchronized (jobs) &#123; while (jobs.isEmpty()) &#123; try &#123; jobs.wait(); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); return; &#125; &#125; job = jobs.removeFirst(); &#125; if (job != null) &#123; try &#123; job.run(); &#125; catch (Exception ex) &#123; //ignore exception from job &#125; &#125; &#125; &#125; public void shutdown() &#123; running = false; &#125; &#125;&#125;interface ThreadPool&lt;Job extends Runnable&gt; &#123; void execute(Job job); void shutdown(); void addWorkers(int num); void removeWorker(int num); int getJobSize();&#125; 数据库连接池web服务器]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文竹养育]]></title>
    <url>%2Ftree%2Fwenzhu%2F</url>
    <content type="text"><![CDATA[常见叶子发黄的原因 【文竹小枝发黄但不脱离】是因为盆土硬实，通气差根系的活力减退。所以要疏松盆土表面 【文竹叶尖枯黄或脱落】主要是浇水少，盆土偏干。应保持盆土湿润，并经常向植株喷洒水分，摆放在空气湿度大的地方。 【文竹枝梢颜色暗黄或呈黄绿色】是因强光照射或浇水过多所致。应将其移至荫蔽处或是有窗帘的窗边，避免强光直接照射，同时注意浇水不要太多。]]></content>
  </entry>
  <entry>
    <title><![CDATA[安全驾驶]]></title>
    <url>%2Fcommon-sense%2F%E5%AE%89%E5%85%A8%E9%A9%BE%E9%A9%B6%2F</url>
    <content type="text"><![CDATA[驾驶安全最关键的是在极端情况下的车辆控制，包括爆胎、雪天车辆打滑的情况。只有保证自己在极端情况下，具有控制车辆的能力，才能称得上是一个合格的驾驶者。 坐姿刹车 刹车速度（km/h） 刹车距离（m） 20 1 40 5 80 25 车辆速度过大时（100km/h），这个时候急转就是go die。先刹车到车辆极限速度，保证安全后再进行躲避，否则宁愿直接装上去。 握姿3、9点握法 电子控制系统 VSA、ESP等通过对个别轮胎进行点刹等操作来控制车辆 电子系统不能改变转弯极限 安全距离 2秒守则 刹车时，注意前后是否有大车 大车的挂车，可能会横过来，注意保持距离 湿滑路面如何急刹 ABS：一脚刹车 无ABS： 刹车、缓脚 如何转弯 前驱车：降速后带油门过弯 后驱车：降速后惯性过弯 如何起步 2档/L档/S档起步 换路面起步 推头understeer造成原因： 速度过快 弯中刹车 速度过快 缓松油门（突然松油门、降档都会讲车辆重心前移，导致失去抓地力） 稍回方向 弯中刹车 释放刹车 稍回方向 甩尾oversteer：造成原因： 弯中轰油门 弯中刹车 不踩刹车，完全失控可以刹车 想侧滑方向同步转动方向盘 避免惊慌和纠正过度 雪天驾驶 漂移的方式 甩尾漂移 推头漂移 重心漂移 手刹漂移]]></content>
      <tags>
        <tag>drive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java内存模型]]></title>
    <url>%2Fjava%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[JMMJava内存模型定义了多线程之间共享变量的可见性以及如何在需要的时候对共享变量进行同步。 Java内存模型定义了volatile和synchronized的行为，更重要的是保证了同步的java程序在所有的处理器架构下面都能正确的运行。 并发编程模型的两个关键问题线程之间如何通信和同步。 如何通信 共享内存 消息传递 如何同步 显式 隐式 在共享内存并发模型中，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接受之前，因此同步是隐式进行的。 JMM的抽象结构线程之间的共享变量存储在主内存，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。 happens-beforehappens-before规则是JMM为了保证程序的正确结果。 重排序为了提高性能，需要对指令进行重排序。重排序分类： 编译器 处理器 指令级并行重排序 内存系统重排序 happens-beforehappens-before是JMM最核心的概念。 一个happens-before规则对应于一个或多个编译器和处理器重排序规则。 定义 1.如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 2.两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须按照happens-before关系执行的顺序来执行。 定义1是JMM对程序员的承诺；定义2是JMM对编译器和处理器重排序的约束原则。 happens-before和as-if-serial是一回事，都有两重意思。从程序员的角度来说，好像是顺序执行的，但是只要不破坏结果，处理器和编译器怎么优化都可以 as-is-serial语义保证单线程内程序的执行结果不变，happens-before语义保证正确同步的多线程程序执行结果不变。 as-is-serial语义给程序员一个幻境：单线程程序是按照程序的顺序来执行的。happens-before关系给编写正确同步的程序员一个幻境：正确同步的多线程程序是按照happens-before指定的顺序来执行的。 happens-before规则 程序顺序规则 监视器锁规则 volatile变量规则 传递性 start()规则：如果线程A执行操作ThreatB.start()，那么A线程的ThreadB.start()操作happens-before于B线程中的任意操作。 join()规则：线程A执行ThreadB.join()并成功返回，那么线程B中任意操作happens-before于线程A从ThreadB.join()操作成功返回。 重排序 happens-before依赖于重排序的实现。一个happens-before对应多个重排序。 1. 数据依赖性数据依赖的操作不可重排序 2. as-if-serial语义不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器和处理器不会对存在数据依赖的操作重排序 顺序一致性内存模型顺序一致行内存模型是一个理论参考模型，在设计的时候，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参照 特性 JMM对正确同步的多线程程序的内存一致性做了如下保证：如果程序是正确同步的，程序的执行将具有顺序一致性。即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。 一个线程中的所有操作必须按照程序的顺序来执行，即不进行重排序 （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。 volatile的内存语义特性 可见性 原子性 内存语义 当写一个volatile变量时，JMM会把线程对应的本地内存中的共享变量值刷新到主内存。 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来从主内存中读取共享变量。 如何实现 在指令序列中插入内存屏障来禁止特定类型的处理器排序。 比如storestore屏障可以保证volatile之前的普通写操作，在volatile变量写入之前，被刷新到主内存。 JSR-33为什么要增强volatile的语义 为了提供一种比锁更轻量级的线程之间通信的机制。 在JSR—33之前，普通变量和volatile可以重排序，会导致普通变量没有写入刷新到主内存。 锁的内存语义内存语义 当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到内存中。 当线程获取锁时，JMM会把该线程对应的本地内存置为无效。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jmm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git基本操作]]></title>
    <url>%2Fgit%2F</url>
    <content type="text"><![CDATA[创建一个叫做“feature_x”的分支，并切换过去：1git checkout -b feature_x，(git checkout -b feature_x origin/master 在远程origin/master的分支基础上，创建feature_x分支) 切换回主分支：1git checkout master 再把新建的分支删掉：1git branch -d feature_x 除非你将分支推送到远端仓库，不然该分支就是 不为他人所见的：1git push origin &lt;branch&gt; 替换本地改动12git checkout -- &lt;filename&gt;此命令会使用 HEAD 中的最新内容替换掉你的工作目录中的文件。已添加到缓存区的改动，以及新文件，都不受影响。 丢弃本地改动和提交12git fetch origingit reset --hard origin/master]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Aggregation Template]]></title>
    <url>%2FAggregation-Template%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;range&quot;: &#123; &quot;start&quot;: &#123; &quot;gte&quot;: 1506009600000 &#125; &#125; &#125; ] &#125; &#125;, &quot;aggs&quot;: &#123; &quot;stat_over_time&quot;: &#123; &quot;date_histogram&quot;: &#123; &quot;field&quot;: &quot;start&quot;, &quot;interval&quot;: &quot;week&quot;, &quot;offset&quot;: &quot;-8h&quot; &#125;, &quot;aggs&quot;: &#123; &quot;terms_over_name&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;service&quot;, &quot;size&quot;: 1, &quot;order&quot;: &#123; &quot;sum_over_count&quot;: &quot;desc&quot; &#125; &#125;, &quot;aggs&quot;: &#123; &quot;sum_over_count&quot;: &#123; &quot;sum&quot;: &#123; &quot;field&quot;: &quot;times&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>aggregation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在sum aggregation，进行过滤]]></title>
    <url>%2Ffilter-after-sum-aggregation%2F</url>
    <content type="text"><![CDATA[Bucket Selector AggregationNote: The bucket_selector aggregation, like all pipeline aggregations, executions after all other sibling aggregations. This means that using the bucket_selector aggregation to filter the returned buckets in the response does not save on execution time running the aggregations.对sum的结果进行过滤123456789101112131415161718192021222324252627282930313233343536373839404142434445GET stat/service/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;range&quot;: &#123; &quot;start&quot;: &#123; &quot;gte&quot;: 1505975853000 &#125; &#125; &#125;, &#123; &quot;range&quot;: &#123; &quot;end&quot;: &#123; &quot;lte&quot;: 1506062253000 &#125; &#125; &#125; ] &#125; &#125;, &quot;aggs&quot;: &#123; &quot;sd&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;service&quot;, &quot;size&quot;: 10 &#125;, &quot;aggs&quot;: &#123; &quot;ds&quot;: &#123; &quot;sum&quot;: &#123; &quot;field&quot;: &quot;times&quot; &#125; &#125;, &quot;sales_bucket_filter&quot;: &#123; &quot;bucket_selector&quot;: &#123; &quot;buckets_path&quot;: &#123; &quot;totalSales&quot;: &quot;ds&quot; &#125;, &quot;script&quot;: &quot;params.totalSales &gt; 1&quot; &#125; &#125; &#125; &#125; &#125;&#125; Date Histogram AggregationDates are represented in elasticsearch internally as long values.]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop shuffle]]></title>
    <url>%2Fhadoop%20shuffle%2F</url>
    <content type="text"><![CDATA[提交的任务，经过map后（形成key/value对，还包括partition，partition表示为map片段分配对应的reducer）存入内存缓冲区，并做了一些预排序。 当缓存大小超过限制（默认：分配的内存的80%），开始进行spill spill会进行sort，会在partitions之间进行排序以及对相同的partition里面的元素进行排序。 spill时，默认将元素组成&lt;key, value-list&gt;的形式（简单的将values放到一起），如果定义了conbiner的话，会对values进行操作，如何在word count中，会将value相加。 map阶段结束时，会将所有的spills， merge为一个，并通知jobtracker。 reducer通过联系jobstracker，知道某个map的任务完成了，进而将map结果复制过来。相同的key的map，会传到同一个reducer。 将不同的map结果，进行merge，如果有conbiner也会执行。 将合并后的结果，作为输入传给reducer。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue]]></title>
    <url>%2Fvue%2F</url>
    <content type="text"><![CDATA[如果在实例创建之后添加新的属性到实例上，它不会触发视图更新。我们将在后面详细讨论响应系统。 1234&lt;!-- 完整语法 --&gt;&lt;a v-bind:href=&quot;url&quot;&gt;&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a :href=&quot;url&quot;&gt;&lt;/a&gt; 1234&lt;!-- 完整语法 --&gt;&lt;a v-on:click=&quot;doSomething&quot;&gt;&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a @click=&quot;doSomething&quot;&gt;&lt;/a&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
</search>
